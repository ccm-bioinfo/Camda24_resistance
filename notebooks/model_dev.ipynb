{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/ravikalia/Code/local-playground/.venv/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/ravikalia/Code/local-playground/.venv/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/ravikalia/Code/local-playground/.venv/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/ravikalia/Code/local-playground/.venv/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ravikalia/Code/local-playground/.venv/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.12.4 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "def mic_transform(mic_values):\n",
    "    log_mic = np.log2(mic_values)\n",
    "    rounded_mic = np.round(log_mic).clip(-7, 7)\n",
    "    return rounded_mic\n",
    "\n",
    "mic_transformer = FunctionTransformer(mic_transform)\n",
    "\n",
    "\n",
    "\n",
    "def apply_smote_for_multioutput(\n",
    "    X: pd.DataFrame, \n",
    "    y_mic: np.ndarray, \n",
    "    y_phenotype: np.ndarray, \n",
    "    preprocessor: ColumnTransformer, \n",
    "    label_encoder_mic: LabelEncoder, \n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Applies SMOTE to resample X and multi-output targets (y_mic and y_phenotype).\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): Features.\n",
    "        y_mic (np.ndarray): Encoded mic target.\n",
    "        y_phenotype (np.ndarray): Encoded phenotype target.\n",
    "        preprocessor (ColumnTransformer): Preprocessing pipeline for X.\n",
    "        label_encoder_mic (LabelEncoder): Label encoder for mic.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Resampled X and y as (X_resampled, y_resampled) with y_resampled split into columns.\n",
    "    \"\"\"\n",
    "    # Combine `y_mic` and `y_phenotype` into a single target for SMOTE\n",
    "    y_combined = np.array([f\"{mic}_{phenotype}\" for mic, phenotype in zip(y_mic, y_phenotype)])\n",
    "\n",
    "    # Apply SMOTE to resample\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_combined_resampled = smote.fit_resample(preprocessor.fit_transform(X), y_combined)\n",
    "\n",
    "    # Split `y_combined_resampled` back into separate `mic` and `phenotype` labels\n",
    "    y_mic_resampled = [int(label.split(\"_\")[0]) for label in y_combined_resampled]\n",
    "    y_phenotype_resampled = [int(label.split(\"_\")[1]) for label in y_combined_resampled]\n",
    "\n",
    "    # Convert back to original format if encoded\n",
    "    y_mic_resampled = label_encoder_mic.inverse_transform(y_mic_resampled)\n",
    "    y_phenotype_resampled = label_encoder_phenotype.inverse_transform(y_phenotype_resampled)\n",
    "\n",
    "    # Create the final resampled target array with two columns\n",
    "    y_resampled = np.column_stack([y_mic_resampled, y_phenotype_resampled])\n",
    "\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def train_classifiers_with_multioutput(df, mic_as_continuous=True):\n",
    "    \"\"\"\n",
    "    Function to train KNN, RandomForest, and SVM classifiers for multi-output prediction (predicting both mic and phenotype),\n",
    "    and combine them using StackingClassifier with a neural network as the meta-model.\n",
    "    \n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels (mic and phenotype).\n",
    "        \n",
    "    Returns:\n",
    "        metrics_df: DataFrame containing precision, recall, F1 score, and accuracy for each fold.\n",
    "    \"\"\"\n",
    "    # Separate features and labels\n",
    "    X = df.drop(columns=['mic', 'phenotype', 'antibiotic'])\n",
    "    y_mic = df['mic']\n",
    "    y_phenotype = df['phenotype']\n",
    "\n",
    "    # Apply log2 transformation to 'mic'\n",
    "    y_mic_transformed = mic_transformer.fit_transform(y_mic.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "    if not mic_as_continuous:\n",
    "        # Encode 'mic' using LabelEncoder\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_mic_transformed = label_encoder.fit_transform(y_mic_transformed)\n",
    "\n",
    "    # Detect binary and multiclass features in X\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]\n",
    "\n",
    "    # Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # Create base models\n",
    "    rf_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "\n",
    "    svm_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', SVC(random_state=42, probability=True))\n",
    "    ])\n",
    "\n",
    "    knn_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    # Meta-classifier: neural network\n",
    "    meta_classifier = MLPClassifier(random_state=42)\n",
    "\n",
    "    # StackingClassifier: combines base models\n",
    "    stacking_model = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', rf_model),\n",
    "            ('svm', svm_model),\n",
    "            ('knn', knn_model)\n",
    "        ],\n",
    "        final_estimator=meta_classifier,\n",
    "        cv=StratifiedKFold(n_splits=5)\n",
    "    )\n",
    "\n",
    "    # Hyperparameter tuning for base models and meta-model\n",
    "    param_grid = {\n",
    "        'rf__classifier__n_estimators': randint(50, 200),\n",
    "        'rf__classifier__max_depth': randint(3, 10),\n",
    "        'svm__classifier__C': uniform(0.1, 10),\n",
    "        'svm__classifier__gamma': ['scale', 'auto'],\n",
    "        'knn__classifier__n_neighbors': randint(3, 20),\n",
    "        'final_estimator__hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "        'final_estimator__alpha': uniform(0.0001, 0.01)\n",
    "    }\n",
    "\n",
    "    # MultiOutputClassifier to handle multi-output prediction\n",
    "    multioutput_model = MultiOutputClassifier(stacking_model)\n",
    "\n",
    "    # Combine both mic and phenotype into a single target array\n",
    "    y_combined = np.column_stack([y_mic_transformed, y_phenotype])\n",
    "\n",
    "    # Apply SMOTE for oversampling\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(preprocessor.fit_transform(X), y_combined)\n",
    "\n",
    "    # Nested cross-validation\n",
    "    outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Hyperparameter tuning with RandomizedSearchCV\n",
    "    search = RandomizedSearchCV(multioutput_model, param_distributions=param_grid, n_iter=50, cv=inner_cv, random_state=42, n_jobs=-1)\n",
    "\n",
    "    # Custom scorer for multi-output metrics\n",
    "    def multioutput_metrics(estimator, X, y):\n",
    "        y_pred = estimator.predict(X)\n",
    "        precision_mic = precision_score(y[:, 0], y_pred[:, 0], average='weighted')\n",
    "        recall_mic = recall_score(y[:, 0], y_pred[:, 0], average='weighted')\n",
    "        f1_mic = f1_score(y[:, 0], y_pred[:, 0], average='weighted')\n",
    "        accuracy_mic = accuracy_score(y[:, 0], y_pred[:, 0])\n",
    "        \n",
    "        precision_phenotype = precision_score(y[:, 1], y_pred[:, 1], average='weighted')\n",
    "        recall_phenotype = recall_score(y[:, 1], y_pred[:, 1], average='weighted')\n",
    "        f1_phenotype = f1_score(y[:, 1], y_pred[:, 1], average='weighted')\n",
    "        accuracy_phenotype = accuracy_score(y[:, 1], y_pred[:, 1])\n",
    "        \n",
    "        return {\n",
    "            'precision_mic': precision_mic,\n",
    "            'recall_mic': recall_mic,\n",
    "            'f1_mic': f1_mic,\n",
    "            'accuracy_mic': accuracy_mic,\n",
    "            'precision_phenotype': precision_phenotype,\n",
    "            'recall_phenotype': recall_phenotype,\n",
    "            'f1_phenotype': f1_phenotype,\n",
    "            'accuracy_phenotype': accuracy_phenotype\n",
    "        }\n",
    "\n",
    "    # Perform nested cross-validation and collect metrics\n",
    "    metrics_list = []\n",
    "    for train_idx, test_idx in outer_cv.split(X_resampled, y_resampled[:, 1]):\n",
    "        X_train, X_test = X_resampled[train_idx], X_resampled[test_idx]\n",
    "        y_train, y_test = y_resampled[train_idx], y_resampled[test_idx]\n",
    "        \n",
    "        search.fit(X_train, y_train)\n",
    "        best_model = search.best_estimator_\n",
    "        \n",
    "        metrics = multioutput_metrics(best_model, X_test, y_test)\n",
    "        metrics_list.append(metrics)\n",
    "\n",
    "    # Convert metrics to DataFrame and write to CSV\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    metrics_df.to_csv('model_metrics.csv', index=False)\n",
    "\n",
    "    return metrics_df\n",
    "\n",
    "# Example usage\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "# metrics_df = train_classifiers_with_multioutput(df)\n",
    "# print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p9/vwq0gfs15vb07tg6xw1r14180000gn/T/ipykernel_86365/594667173.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('./../../DataSets/group-2/data/combined_antibiotic_resistance.tsv', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./../../DataSets/group-2/data/combined_antibiotic_resistance.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antibiotic</th>\n",
       "      <th>accession</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>mic</th>\n",
       "      <th>3005053</th>\n",
       "      <th>3000830</th>\n",
       "      <th>3003838</th>\n",
       "      <th>3000508</th>\n",
       "      <th>...</th>\n",
       "      <th>3007751-D87Y</th>\n",
       "      <th>3003926-D87Y</th>\n",
       "      <th>3003709-G46S</th>\n",
       "      <th>3004851-A39T</th>\n",
       "      <th>3004832-A501P</th>\n",
       "      <th>3003381-R20H</th>\n",
       "      <th>3003926-S83I</th>\n",
       "      <th>3003381-G121D</th>\n",
       "      <th>3004832-T483S</th>\n",
       "      <th>3004832-A311V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_002947415</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_002947845</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_002948925</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_002996805</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_003006035</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 881 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  antibiotic      accession          genus    species  phenotype  mic  \\\n",
       "0  meropenem  GCA_002947415  Acinetobacter  baumannii  Resistant  8.0   \n",
       "1  meropenem  GCA_002947845  Acinetobacter  baumannii  Resistant  8.0   \n",
       "2  meropenem  GCA_002948925  Acinetobacter  baumannii  Resistant  8.0   \n",
       "3  meropenem  GCA_002996805  Acinetobacter  baumannii  Resistant  8.0   \n",
       "4  meropenem  GCA_003006035  Acinetobacter  baumannii  Resistant  8.0   \n",
       "\n",
       "   3005053  3000830  3003838  3000508  ...  3007751-D87Y  3003926-D87Y  \\\n",
       "0      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "1      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "2      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "3      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "4      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "\n",
       "   3003709-G46S  3004851-A39T  3004832-A501P  3003381-R20H  3003926-S83I  \\\n",
       "0           0.0           0.0            0.0           0.0           0.0   \n",
       "1           0.0           0.0            0.0           0.0           0.0   \n",
       "2           0.0           0.0            0.0           0.0           0.0   \n",
       "3           0.0           0.0            0.0           0.0           0.0   \n",
       "4           0.0           0.0            0.0           0.0           0.0   \n",
       "\n",
       "   3003381-G121D  3004832-T483S  3004832-A311V  \n",
       "0            0.0            0.0            0.0  \n",
       "1            0.0            0.0            0.0  \n",
       "2            0.0            0.0            0.0  \n",
       "3            0.0            0.0            0.0  \n",
       "4            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 881 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count         7772\n",
       "unique           8\n",
       "top       enterica\n",
       "freq          2841\n",
       "Name: species, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['species'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species\n",
       "enterica       2841\n",
       "pneumoniae     2638\n",
       "aeruginosa      652\n",
       "jejuni          547\n",
       "coli            480\n",
       "gonorrhoeae     277\n",
       "baumannii       269\n",
       "cloacae          68\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p9/vwq0gfs15vb07tg6xw1r14180000gn/T/ipykernel_86365/760119788.py:37: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path, sep='\\t')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_classifiers_with_multioutput\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./../../DataSets/group-2/data/combined_antibiotic_resistance.tsv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 111\u001b[0m, in \u001b[0;36mtrain_classifiers_with_multioutput\u001b[0;34m(df_path, mic_as_continuous)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# Apply SMOTE for oversampling\u001b[39;00m\n\u001b[1;32m    110\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m \u001b[43msmote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_combined\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Nested cross-validation\u001b[39;00m\n\u001b[1;32m    114\u001b[0m outer_cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m~/Code/local-playground/.venv/lib/python3.11/site-packages/imblearn/base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/local-playground/.venv/lib/python3.11/site-packages/imblearn/base.py:104\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_resample\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m     84\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m        The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[1;32m    106\u001b[0m     X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n",
      "File \u001b[0;32m~/Code/local-playground/.venv/lib/python3.11/site-packages/sklearn/utils/multiclass.py:211\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_classification_targets\u001b[39m(y):\n\u001b[1;32m    200\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Ensure that target y is of a non-regression type.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m    Only the following target types (as defined in type_of_target) are allowed:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m        Target values.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    218\u001b[0m     ]:\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    220\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m         )\n",
      "File \u001b[0;32m~/Code/local-playground/.venv/lib/python3.11/site-packages/sklearn/utils/multiclass.py:314\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse_pandas:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseSeries\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseArray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_multilabel\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# DeprecationWarning will be replaced by ValueError, see NEP 34\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# https://numpy.org/neps/nep-0034-infer-dtype-is-object.html\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;66;03m# We therefore catch both deprecation (NumPy < 1.24) warning and\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# value error (NumPy >= 1.24).\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/local-playground/.venv/lib/python3.11/site-packages/sklearn/utils/multiclass.py:191\u001b[0m, in \u001b[0;36mis_multilabel\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;28mlen\u001b[39m(y\u001b[38;5;241m.\u001b[39mdata) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (labels\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (labels\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m labels))\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (y\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbiu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m _is_integral_float(labels))  \u001b[38;5;66;03m# bool, int, uint\u001b[39;00m\n\u001b[1;32m    189\u001b[0m     )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    194\u001b[0m         xp\u001b[38;5;241m.\u001b[39misdtype(y\u001b[38;5;241m.\u001b[39mdtype, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigned integer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsigned integer\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _is_integral_float(labels)\n\u001b[1;32m    196\u001b[0m     )\n",
      "File \u001b[0;32m~/Code/local-playground/.venv/lib/python3.11/site-packages/sklearn/utils/_array_api.py:407\u001b[0m, in \u001b[0;36m_NumPyAPIWrapper.unique_values\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/local-playground/.venv/lib/python3.11/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/local-playground/.venv/lib/python3.11/site-packages/numpy/lib/arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     ar\u001b[38;5;241m.\u001b[39msort()\n\u001b[1;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[1;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "train_classifiers_with_multioutput(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
