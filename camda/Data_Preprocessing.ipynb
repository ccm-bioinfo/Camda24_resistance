{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56c70cb9-0815-445d-83bf-a45bfcf9096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e66c2c7-83c7-4571-9513-63469ca5031c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/TDA/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3552: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accession</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>mic</th>\n",
       "      <th>3000535</th>\n",
       "      <th>3005091</th>\n",
       "      <th>3000833</th>\n",
       "      <th>3003665</th>\n",
       "      <th>3007433</th>\n",
       "      <th>...</th>\n",
       "      <th>3003285-S531G</th>\n",
       "      <th>3007051-I572F</th>\n",
       "      <th>3007051-I837V</th>\n",
       "      <th>3003294-D105E</th>\n",
       "      <th>3003394-S66P</th>\n",
       "      <th>3005106-A352E</th>\n",
       "      <th>3003937-N514H</th>\n",
       "      <th>3003937-L546V</th>\n",
       "      <th>3003304-E540V</th>\n",
       "      <th>3003304-E504V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRR3138666</td>\n",
       "      <td>Campylobacter</td>\n",
       "      <td>jejuni</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.12</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRR3138667</td>\n",
       "      <td>Campylobacter</td>\n",
       "      <td>jejuni</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.06</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRR3138668</td>\n",
       "      <td>Campylobacter</td>\n",
       "      <td>jejuni</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.06</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRR3138669</td>\n",
       "      <td>Campylobacter</td>\n",
       "      <td>jejuni</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.06</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRR3138670</td>\n",
       "      <td>Campylobacter</td>\n",
       "      <td>jejuni</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.06</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5570 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    accession          genus species    phenotype   mic  3000535  3005091  \\\n",
       "0  SRR3138666  Campylobacter  jejuni  Susceptible  0.12     19.0     10.0   \n",
       "1  SRR3138667  Campylobacter  jejuni  Susceptible  0.06     19.0      6.0   \n",
       "2  SRR3138668  Campylobacter  jejuni  Susceptible  0.06     16.0      7.0   \n",
       "3  SRR3138669  Campylobacter  jejuni  Susceptible  0.06     16.0      7.0   \n",
       "4  SRR3138670  Campylobacter  jejuni  Susceptible  0.06     20.0      8.0   \n",
       "\n",
       "   3000833  3003665  3007433  ...  3003285-S531G  3007051-I572F  \\\n",
       "0      4.0      3.0      3.0  ...            0.0            0.0   \n",
       "1      7.0      4.0      4.0  ...            0.0            0.0   \n",
       "2      5.0      3.0      3.0  ...            0.0            0.0   \n",
       "3      5.0      3.0      3.0  ...            0.0            0.0   \n",
       "4      6.0      4.0      4.0  ...            0.0            0.0   \n",
       "\n",
       "   3007051-I837V  3003294-D105E  3003394-S66P  3005106-A352E  3003937-N514H  \\\n",
       "0            0.0            0.0           0.0            0.0            0.0   \n",
       "1            0.0            0.0           0.0            0.0            0.0   \n",
       "2            0.0            0.0           0.0            0.0            0.0   \n",
       "3            0.0            0.0           0.0            0.0            0.0   \n",
       "4            0.0            0.0           0.0            0.0            0.0   \n",
       "\n",
       "   3003937-L546V  3003304-E540V  3003304-E504V  \n",
       "0            0.0            0.0            0.0  \n",
       "1            0.0            0.0            0.0  \n",
       "2            0.0            0.0            0.0  \n",
       "3            0.0            0.0            0.0  \n",
       "4            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 5570 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "file_path = '/home/jupyter-user5/Camda24_resistance/DataSets/ResistanceCiprofloxacinLoose.tsv.gz'\n",
    "df = pd.read_csv(file_path, sep='\\t', compression='gzip')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d9b92e8-5076-4d6a-b9cb-82b99a5e215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir características numéricas y categóricas (ajusta estos nombres a las columnas del nuevo archivo)\n",
    "numerical_features = ['mic'] + [col for col in df.columns if col.startswith('300')]\n",
    "categorical_features = ['genus', 'species']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f5bfa6f-6844-426c-8254-5212f6db3dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el preprocesador para imputación y estandarización de características numéricas, y codificación One-Hot para categóricas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='mean')),  # Imputar con la media\n",
    "            ('scaler', StandardScaler())  # Estandarización\n",
    "        ]), numerical_features),\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),  # Imputar con la moda\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore'))  # Codificación One-Hot\n",
    "        ]), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d069dec5-2962-4733-be8c-3d78bd7acd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Imputación de etiquetas (phenotype) si faltan valores\n",
    "y = df['phenotype']\n",
    "missing_labels = y.isnull().sum()\n",
    "\n",
    "if missing_labels > 0:\n",
    "    label_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    y_imputed = label_imputer.fit_transform(y.values.reshape(-1, 1)).ravel()\n",
    "else:\n",
    "    y_imputed = y.values\n",
    "\n",
    "# Codificación de etiquetas en formato numérico\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_imputed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22ecc13a-e6b5-49de-ad7a-4e557ce8056f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/TDA/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/TDA/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/TDA/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accession'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/TDA/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mcol_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/TDA/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accession'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1724694/1247789518.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Aplicar el pipeline a los datos (excluyendo phenotype y accession)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'phenotype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accession'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_processed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/TDA/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/TDA/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_transformers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_column_callables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/TDA/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_validate_column_callables\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mall_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mtransformer_to_input_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_column_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/TDA/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A given column is not a column of the dataframe\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcolumn_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "# Crear el pipeline final que incluye el preprocesamiento de características\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# Aplicar el pipeline a los datos (excluyendo phenotype y accession)\n",
    "X = df.drop(columns=['phenotype', 'accession'])\n",
    "X_processed = pipeline.fit_transform(X)\n",
    "\n",
    "# Mostrar las dimensiones finales de los datos transformados\n",
    "print(X_processed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db142391-49e0-43f6-b19a-ea134c294302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Aplicar el pipeline a los datos procesados\n",
    "X_processed = pipeline.fit_transform(X)\n",
    "\n",
    "# Ver las primeras filas de las etiquetas codificadas\n",
    "print(y_encoded[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65101e4b-2fd5-40cc-986f-ee07cae14cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20d07b46-cb4a-40cb-bc30-886afd7ff79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phenotype    1063\n",
      "mic          1063\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contar los valores faltantes por cada columna\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Mostrar sólo las columnas con valores faltantes\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e47b3beb-f573-40b5-822e-d35d1a4789a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3881, 5574)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Separar las características (X) y las etiquetas (y)\n",
    "X = df.drop(columns=['phenotype', 'accession'])  # Excluir las etiquetas y columnas irrelevantes\n",
    "y = df['phenotype']  # Etiquetas\n",
    "\n",
    "# Definir las características numéricas y categóricas\n",
    "numerical_features = ['mic'] + [col for col in df.columns if col.startswith('300')]\n",
    "categorical_features = ['genus', 'species']\n",
    "\n",
    "# Crear el pipeline de preprocesamiento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Imputar 'mic' con la media\n",
    "        ('num', SimpleImputer(strategy='mean'), numerical_features),\n",
    "        \n",
    "        # Imputar categóricas con la moda y hacer OneHotEncoding\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Imputación de la etiqueta 'phenotype' con la clase más frecuente\n",
    "label_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Aplicar imputación a las etiquetas (y)\n",
    "y_imputed = label_imputer.fit_transform(y.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Codificar las etiquetas imputadas en formato numérico si es necesario\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_imputed)\n",
    "\n",
    "# Aplicar el pipeline a las características (X)\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Mostrar la forma de los datos procesados\n",
    "print(X_processed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1dfe022-be34-4599-9bf1-3e650b30d1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores faltantes en X procesado: 0\n",
      "Valores faltantes en las etiquetas imputadas: 0\n"
     ]
    }
   ],
   "source": [
    "# Validar que los valores faltantes fueron correctamente imputados\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Valores faltantes en X procesado: {np.isnan(X_processed).sum()}\")\n",
    "print(f\"Valores faltantes en las etiquetas imputadas: {np.isnan(y_encoded).sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60b22e86-8205-4a4c-951f-dba1a1a3a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14b31266-e877-45f6-b130-d254dc6c376f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características categóricas identificadas: Index(['accession', 'genus', 'species', 'phenotype'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Verificar los tipos de datos para identificar columnas categóricas\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "print(\"Características categóricas identificadas:\", categorical_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "240fe229-3d40-43b3-ac2f-8aeb00013082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3881, 5574)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Características categóricas identificadas\n",
    "categorical_features = ['genus', 'species']  # Excluimos 'accession' y 'phenotype'\n",
    "\n",
    "# Crear el pipeline de preprocesamiento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Imputar y escalar las características numéricas\n",
    "        ('num', SimpleImputer(strategy='mean'), numerical_features),\n",
    "        \n",
    "        # Codificación One-Hot para las características categóricas 'genus' y 'species'\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Crear el pipeline final\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# Aplicar el pipeline a las características (X) excluyendo 'accession' y 'phenotype'\n",
    "X = df.drop(columns=['phenotype', 'accession'])\n",
    "X_processed = pipeline.fit_transform(X)\n",
    "\n",
    "# Mostrar las dimensiones de los datos transformados\n",
    "print(X_processed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81e15eac-9d38-4a8b-8b29-b0035728b6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0     1     2     3     4     5     6     7     8     9     ...  5564  \\\n",
      "0  0.12  19.0  10.0   4.0   3.0   3.0   6.0   1.0   1.0   9.0  ...   0.0   \n",
      "1  0.06  19.0   6.0   7.0   4.0   4.0   4.0   1.0   1.0  13.0  ...   0.0   \n",
      "2  0.06  16.0   7.0   5.0   3.0   3.0   5.0   2.0   0.0   6.0  ...   0.0   \n",
      "3  0.06  16.0   7.0   5.0   3.0   3.0   5.0   1.0   0.0   6.0  ...   0.0   \n",
      "4  0.06  20.0   8.0   6.0   4.0   4.0   5.0   2.0   1.0   9.0  ...   0.0   \n",
      "\n",
      "   5565  5566  5567  5568  5569  5570  5571  5572  5573  \n",
      "0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n",
      "1   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n",
      "2   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n",
      "3   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n",
      "4   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n",
      "\n",
      "[5 rows x 5574 columns]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas del conjunto procesado\n",
    "import pandas as pd\n",
    "print(pd.DataFrame(X_processed).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb573acc-154f-425c-92eb-f645ce891821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#se identificaron las columnas categóricas y aplicado One-Hot Encoding a las variables genus y species. La columna accession fue excluida, y la columna phenotype fue manejada como una etiqueta en pasos previos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ae3128f-4e97-4742-be16-a42e66c1c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#La razón por la que el número de columnas ha crecido tanto es porque el proceso de One-Hot Encoding transforma cada categoría en una columna separada (binaria), lo que genera un aumento significativo en el número de columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04bea9e6-bcdd-4f2e-b6f8-6961f04921b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## hay etiquetas faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a3c088d-1bd7-438c-9c13-7bad66aefe6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas faltantes en 'phenotype': 1063\n"
     ]
    }
   ],
   "source": [
    "missing_labels = df['phenotype'].isnull().sum()\n",
    "print(f\"Etiquetas faltantes en 'phenotype': {missing_labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6818c7b7-9e1c-404e-985e-61cf6ba2faa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imputar las etiquetas faltantes con la clase más frecuente\n",
    "label_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df['phenotype_imputed'] = label_imputer.fit_transform(df[['phenotype']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e61ac1e-0e7f-4a25-9fcb-ee4a08d1d4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: phenotype_encoded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Codificar las etiquetas (phenotype) en formato numérico\n",
    "label_encoder = LabelEncoder()\n",
    "df['phenotype_encoded'] = label_encoder.fit_transform(df['phenotype_imputed'])\n",
    "print(df['phenotype_encoded'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aebba8e8-1e99-4932-98a4-f89982a9e475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Pipeline para imputar etiquetas faltantes\n",
    "label_imputation_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))  # Imputar etiquetas faltantes\n",
    "])\n",
    "\n",
    "# Aplicar el pipeline de imputación de etiquetas\n",
    "y_imputed = label_imputation_pipeline.fit_transform(df[['phenotype']])\n",
    "\n",
    "# Codificar las etiquetas fuera del pipeline\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_imputed.ravel())  # .ravel() convierte la matriz en un vector\n",
    "\n",
    "# Verificar el resultado de la codificación de etiquetas\n",
    "print(y_encoded[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42e039db-67a6-4a48-8b18-4f352cd725db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas faltantes después de la imputación: 0\n",
      "Etiquetas codificadas: [1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Verificar si hay etiquetas faltantes después de la imputación\n",
    "print(f\"Etiquetas faltantes después de la imputación: {pd.isnull(y_encoded).sum()}\")\n",
    "\n",
    "# Ver las primeras etiquetas codificadas\n",
    "print(\"Etiquetas codificadas:\", y_encoded[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7589fde-8d4e-4a11-94e8-de5d10805e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características transformadas: (3881, 3890)\n",
      "Etiquetas codificadas: [1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Separar las características \n",
    "categorical_features = ['accession', 'genus', 'species']\n",
    "numerical_features = ['mic']  # mic es un ejemplo, agrega las que correspondan\n",
    "\n",
    "# Definir los pasos del preprocesamiento de características\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='mean'), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Definir el pipeline para el preprocesamiento completo \n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # Imputación y codificación de características\n",
    "])\n",
    "\n",
    "# Aplicar el pipeline\n",
    "X = df.drop(columns=['phenotype'])  # Excluir las etiquetas\n",
    "X_processed = pipeline.fit_transform(X)\n",
    "\n",
    "# Imputación de etiquetas faltantes\n",
    "label_imputer = SimpleImputer(strategy='most_frequent')\n",
    "y_imputed = label_imputer.fit_transform(df[['phenotype']])\n",
    "\n",
    "# Codificación de etiquetas\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_imputed.ravel())  # Codificar etiquetas\n",
    "print(f\"Características transformadas: {X_processed.shape}\")\n",
    "print(f\"Etiquetas codificadas: {y_encoded[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0b2a659-27bb-41e6-be46-29ecf96907ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  SimpleImputer para rellenar los valores faltantes en las características numéricas y categóricas.\n",
    "#  OneHotEncoder para convertir las características categóricas en variables binarias.\n",
    "#  se usa SimpleImputer con la estrategia de \"más frecuente\" para rellenar las etiquetas faltantes.\n",
    "#  Después de la imputación, codificamos las etiquetas usando LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21d78f8e-2ef9-41c9-9e97-411db27100b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de X_train procesado: (3104, 3113)\n",
      "Tamaño de X_test procesado: (777, 3113)\n",
      "Ejemplo de etiquetas codificadas: [1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "X = df.drop(columns=['phenotype'])  # Excluyendo la columna de etiquetas\n",
    "y = df['phenotype']  # Etiquetas\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "categorical_features = ['accession', 'genus', 'species']\n",
    "numerical_features = ['mic']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='mean'), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "\n",
    "X_train_processed = pipeline.fit_transform(X_train)\n",
    "X_test_processed = pipeline.transform(X_test)  # Aplicar transformaciones a los datos de prueba\n",
    "\n",
    "\n",
    "# Imputar etiquetas faltantes\n",
    "label_imputer = SimpleImputer(strategy='most_frequent')\n",
    "y_train_imputed = label_imputer.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "y_test_imputed = label_imputer.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Codificar etiquetas\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train_imputed)\n",
    "y_test_encoded = label_encoder.transform(y_test_imputed)\n",
    "\n",
    "# Verificar el resultado\n",
    "print(f\"Tamaño de X_train procesado: {X_train_processed.shape}\")\n",
    "print(f\"Tamaño de X_test procesado: {X_test_processed.shape}\")\n",
    "print(f\"Ejemplo de etiquetas codificadas: {y_train_encoded[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a648c42-7837-48cd-a6af-9fe5e0e821fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDA",
   "language": "python",
   "name": "tda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
