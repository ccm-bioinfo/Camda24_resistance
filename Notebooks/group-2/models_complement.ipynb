{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a67742-9e2c-4dec-843b-d1738fbfff61",
   "metadata": {},
   "source": [
    "# Random Forest (Reproducible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6840f1f2-d9d0-4ec9-8c77-3d8a8bdb961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7447a125-d90f-4f11-8cd9-46041666050e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3881681/3163463394.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "filepath = '/home/jupyter-user5/Camda24_resistance/DataSets/group-2/data/combined_antibiotic_resistance.tsv'\n",
    "df = pd.read_csv(filepath, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7d888a-b924-4d6c-a692-0b32211e88f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antibiotic</th>\n",
       "      <th>accession</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>mic</th>\n",
       "      <th>3005053</th>\n",
       "      <th>3000830</th>\n",
       "      <th>3003838</th>\n",
       "      <th>3000508</th>\n",
       "      <th>...</th>\n",
       "      <th>3007751-D87Y</th>\n",
       "      <th>3003926-D87Y</th>\n",
       "      <th>3003709-G46S</th>\n",
       "      <th>3004851-A39T</th>\n",
       "      <th>3004832-A501P</th>\n",
       "      <th>3003381-R20H</th>\n",
       "      <th>3003926-S83I</th>\n",
       "      <th>3003381-G121D</th>\n",
       "      <th>3004832-T483S</th>\n",
       "      <th>3004832-A311V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_002947415</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_002947845</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_002948925</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_002996805</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_003006035</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 881 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  antibiotic      accession          genus    species  phenotype  mic  \\\n",
       "0  meropenem  GCA_002947415  Acinetobacter  baumannii  Resistant  8.0   \n",
       "1  meropenem  GCA_002947845  Acinetobacter  baumannii  Resistant  8.0   \n",
       "2  meropenem  GCA_002948925  Acinetobacter  baumannii  Resistant  8.0   \n",
       "3  meropenem  GCA_002996805  Acinetobacter  baumannii  Resistant  8.0   \n",
       "4  meropenem  GCA_003006035  Acinetobacter  baumannii  Resistant  8.0   \n",
       "\n",
       "   3005053  3000830  3003838  3000508  ...  3007751-D87Y  3003926-D87Y  \\\n",
       "0      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "1      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "2      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "3      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "4      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "\n",
       "   3003709-G46S  3004851-A39T  3004832-A501P  3003381-R20H  3003926-S83I  \\\n",
       "0           0.0           0.0            0.0           0.0           0.0   \n",
       "1           0.0           0.0            0.0           0.0           0.0   \n",
       "2           0.0           0.0            0.0           0.0           0.0   \n",
       "3           0.0           0.0            0.0           0.0           0.0   \n",
       "4           0.0           0.0            0.0           0.0           0.0   \n",
       "\n",
       "   3003381-G121D  3004832-T483S  3004832-A311V  \n",
       "0            0.0            0.0            0.0  \n",
       "1            0.0            0.0            0.0  \n",
       "2            0.0            0.0            0.0  \n",
       "3            0.0            0.0            0.0  \n",
       "4            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 881 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeabe508-c873-4581-a01c-732c5247a7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8814554c-0b19-448d-912d-9d4aeb1d546a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5952, 881)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "281b54ae-fb31-4548-a9af-713217a401fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antibiotic</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>mic</th>\n",
       "      <th>3005053</th>\n",
       "      <th>3000830</th>\n",
       "      <th>3003838</th>\n",
       "      <th>3000508</th>\n",
       "      <th>3003890</th>\n",
       "      <th>...</th>\n",
       "      <th>3007751-D87Y</th>\n",
       "      <th>3003926-D87Y</th>\n",
       "      <th>3003709-G46S</th>\n",
       "      <th>3004851-A39T</th>\n",
       "      <th>3004832-A501P</th>\n",
       "      <th>3003381-R20H</th>\n",
       "      <th>3003926-S83I</th>\n",
       "      <th>3003381-G121D</th>\n",
       "      <th>3004832-T483S</th>\n",
       "      <th>3004832-A311V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 880 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  antibiotic          genus    species  phenotype  mic  3005053  3000830  \\\n",
       "0  meropenem  Acinetobacter  baumannii  Resistant  8.0      0.0      0.0   \n",
       "1  meropenem  Acinetobacter  baumannii  Resistant  8.0      0.0      0.0   \n",
       "2  meropenem  Acinetobacter  baumannii  Resistant  8.0      0.0      0.0   \n",
       "3  meropenem  Acinetobacter  baumannii  Resistant  8.0      0.0      0.0   \n",
       "4  meropenem  Acinetobacter  baumannii  Resistant  8.0      0.0      0.0   \n",
       "\n",
       "   3003838  3000508  3003890  ...  3007751-D87Y  3003926-D87Y  3003709-G46S  \\\n",
       "0      0.0      0.0      0.0  ...           0.0           0.0           0.0   \n",
       "1      0.0      0.0      0.0  ...           0.0           0.0           0.0   \n",
       "2      0.0      0.0      0.0  ...           0.0           0.0           0.0   \n",
       "3      0.0      0.0      0.0  ...           0.0           0.0           0.0   \n",
       "4      0.0      0.0      0.0  ...           0.0           0.0           0.0   \n",
       "\n",
       "   3004851-A39T  3004832-A501P  3003381-R20H  3003926-S83I  3003381-G121D  \\\n",
       "0           0.0            0.0           0.0           0.0            0.0   \n",
       "1           0.0            0.0           0.0           0.0            0.0   \n",
       "2           0.0            0.0           0.0           0.0            0.0   \n",
       "3           0.0            0.0           0.0           0.0            0.0   \n",
       "4           0.0            0.0           0.0           0.0            0.0   \n",
       "\n",
       "   3004832-T483S  3004832-A311V  \n",
       "0            0.0            0.0  \n",
       "1            0.0            0.0  \n",
       "2            0.0            0.0  \n",
       "3            0.0            0.0  \n",
       "4            0.0            0.0  \n",
       "\n",
       "[5 rows x 880 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('accession', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cee850b6-8a29-40c4-ac25-43a72b68ff47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5952, 880)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e66fce5c-a6fa-4629-b584-2694b1097373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(df):\n",
    "    \"\"\"\n",
    "    Function to train a random forest classifier on the 'mic' column of the dataframe.\n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        model: Trained RandomForestClassifier model.\n",
    "        f1: F1 score of the model on test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic',\"antibiotic\"])  # Drop label columns\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Encode 'mic' (target) using LabelEncoder (since it's multiclass)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Detect binary and multiclass features\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    # Binary columns don't need much processing, multiclass columns need one-hot encoding\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns Con handle_unknown='ignore', el codificador ignorará las categorías desconocidas y no producirá un error durante la predicción.\n",
    "        ], remainder='passthrough')  # Any remaining columns are passed through (if any)\n",
    "\n",
    "    # 5. Create a pipeline that first applies preprocessing, then trains a random forest\n",
    "    model_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "\n",
    "    # 6. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 7. Train the model\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # 8. Make predictions and calculate the F1 score\n",
    "    y_pred = model_pipeline.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')  # Use 'weighted' for multiclass F1\n",
    "\n",
    "    return model_pipeline, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dfbe903-b776-42cb-bc47-2ebc4137309e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model: Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['3000830', '3000206',\n",
      "                                                   '3006880', '3000676',\n",
      "                                                   '3003576', '3001216',\n",
      "                                                   '3000237', '3003548',\n",
      "                                                   '3001889', '3003652',\n",
      "                                                   '3003899', '3006228',\n",
      "                                                   '3003900', '3006881',\n",
      "                                                   '3001866', '3003479',\n",
      "                                                   '3000166', '3002540',\n",
      "                                                   '3006878', '3006874',\n",
      "                                                   '3000168', '3004290',\n",
      "                                                   '3006875', '30070...\n",
      "                                                  ['genus', 'species',\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier', RandomForestClassifier(random_state=42))])\n",
      "F1 score: 0.7135263475674756\n"
     ]
    }
   ],
   "source": [
    "model, f1 = train_random_forest(df)\n",
    "print(f'Trained model: {model}')\n",
    "print(f'F1 score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd7b17c-4713-455e-abfc-e81cfb800f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "887bde1f-3a0b-446f-905b-a8a35d872056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models: {'RandomForest': Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['3000830', '3000206',\n",
      "                                                   '3006880', '3000676',\n",
      "                                                   '3003576', '3001216',\n",
      "                                                   '3000237', '3003548',\n",
      "                                                   '3001889', '3003652',\n",
      "                                                   '3003899', '3006228',\n",
      "                                                   '3003900', '3006881',\n",
      "                                                   '3001866', '3003479',\n",
      "                                                   '3000166', '3002540',\n",
      "                                                   '3006878', '3006874',\n",
      "                                                   '3000168', '3004290',\n",
      "                                                   '3006875', '30070...\n",
      "                                                  ['genus', 'species',\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier', RandomForestClassifier(random_state=42))]), 'SVM': Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['3000830', '3000206',\n",
      "                                                   '3006880', '3000676',\n",
      "                                                   '3003576', '3001216',\n",
      "                                                   '3000237', '3003548',\n",
      "                                                   '3001889', '3003652',\n",
      "                                                   '3003899', '3006228',\n",
      "                                                   '3003900', '3006881',\n",
      "                                                   '3001866', '3003479',\n",
      "                                                   '3000166', '3002540',\n",
      "                                                   '3006878', '3006874',\n",
      "                                                   '3000168', '3004290',\n",
      "                                                   '3006875', '30070...\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['genus', 'species',\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier', SVC(random_state=42))]), 'KNN': Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['3000830', '3000206',\n",
      "                                                   '3006880', '3000676',\n",
      "                                                   '3003576', '3001216',\n",
      "                                                   '3000237', '3003548',\n",
      "                                                   '3001889', '3003652',\n",
      "                                                   '3003899', '3006228',\n",
      "                                                   '3003900', '3006881',\n",
      "                                                   '3001866', '3003479',\n",
      "                                                   '3000166', '3002540',\n",
      "                                                   '3006878', '3006874',\n",
      "                                                   '3000168', '3004290',\n",
      "                                                   '3006875', '30070...\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['genus', 'species',\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier', KNeighborsClassifier())])}\n",
      "F1 scores: {'RandomForest': 0.7135263475674756, 'SVM': 0.6034210105056049, 'KNN': 0.6694039285905631}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def train_classifiers(df):\n",
    "    \"\"\"\n",
    "    Function to train RandomForest, SVM, and KNN classifiers on the 'mic' column of the dataframe.\n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        models: Dictionary containing trained models for each classifier.\n",
    "        f1_scores: Dictionary containing F1 scores for each classifier on test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic', \"antibiotic\"])  # Drop label columns\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Encode 'mic' (target) using LabelEncoder (since it's multiclass)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Detect binary and multiclass features\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    # Binary columns don't need much processing, multiclass columns need one-hot encoding\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough')  # Any remaining columns are passed through (if any)\n",
    "\n",
    "    # 5. Create pipelines for different classifiers\n",
    "    rf_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    svm_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', SVC(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    knn_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    # 6. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 7. Train models and calculate F1 scores\n",
    "    models = {}\n",
    "    f1_scores = {}\n",
    "\n",
    "    # Random Forest\n",
    "    rf_pipeline.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_pipeline.predict(X_test)\n",
    "    f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "    models['RandomForest'] = rf_pipeline\n",
    "    f1_scores['RandomForest'] = f1_rf\n",
    "\n",
    "    # SVM\n",
    "    svm_pipeline.fit(X_train, y_train)\n",
    "    y_pred_svm = svm_pipeline.predict(X_test)\n",
    "    f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "    models['SVM'] = svm_pipeline\n",
    "    f1_scores['SVM'] = f1_svm\n",
    "\n",
    "    # KNN\n",
    "    knn_pipeline.fit(X_train, y_train)\n",
    "    y_pred_knn = knn_pipeline.predict(X_test)\n",
    "    f1_knn = f1_score(y_test, y_pred_knn, average='weighted')\n",
    "    models['KNN'] = knn_pipeline\n",
    "    f1_scores['KNN'] = f1_knn\n",
    "\n",
    "    return models, f1_scores\n",
    "\n",
    "# Entrenar los modelos\n",
    "models, f1_scores = train_classifiers(df)\n",
    "print(f'Trained models: {models}')\n",
    "print(f'F1 scores: {f1_scores}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b90dc20-8f17-4c7b-848b-034e107bb5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 81 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n27 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/pipeline.py\", line 476, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 363, in fit\n    X, y = self._validate_data(\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1273, in check_X_y\n    X = check_array(\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1007, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/_array_api.py\", line 746, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'meropenem'\n\n--------------------------------------------------------------------------------\n54 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/pipeline.py\", line 476, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 363, in fit\n    X, y = self._validate_data(\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1273, in check_X_y\n    X = check_array(\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1007, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/_array_api.py\", line 746, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'ciprofloxacin'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 110\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_models, f1_scores\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# Entrenar los modelos con ajuste de hiperparámetros\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m best_models, f1_scores \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_classifiers_with_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest models: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_models\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1 scores: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_scores\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 87\u001b[0m, in \u001b[0;36mtrain_classifiers_with_tuning\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     84\u001b[0m f1_scores \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Random Forest\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m \u001b[43mrf_grid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m y_pred_rf \u001b[38;5;241m=\u001b[39m rf_grid\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     89\u001b[0m f1_rf \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_pred_rf, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_search.py:968\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    962\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    963\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    964\u001b[0m     )\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 968\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    972\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1543\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1542\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1543\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_search.py:945\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    940\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    941\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    943\u001b[0m     )\n\u001b[0;32m--> 945\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 81 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n27 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/pipeline.py\", line 476, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 363, in fit\n    X, y = self._validate_data(\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1273, in check_X_y\n    X = check_array(\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1007, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/_array_api.py\", line 746, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'meropenem'\n\n--------------------------------------------------------------------------------\n54 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/pipeline.py\", line 476, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 363, in fit\n    X, y = self._validate_data(\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1273, in check_X_y\n    X = check_array(\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1007, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/_array_api.py\", line 746, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'ciprofloxacin'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def train_classifiers_with_tuning(df):\n",
    "    \"\"\"\n",
    "    Function to train RandomForest, SVM, and KNN classifiers with hyperparameter tuning on the 'mic' column.\n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        best_models: Dictionary containing the best tuned models for each classifier.\n",
    "        f1_scores: Dictionary containing F1 scores for each best-tuned classifier on test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic'])  # Drop label columns \"antibiotic\"\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Encode 'mic' (target) using LabelEncoder (since it's multiclass)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Detect binary and multiclass features\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # 5. Define parameter grids for hyperparameter tuning\n",
    "    param_grid_rf = {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "\n",
    "    param_grid_svm = {\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__kernel': ['linear', 'rbf'],\n",
    "        'classifier__gamma': ['scale', 'auto']\n",
    "    }\n",
    "\n",
    "    param_grid_knn = {\n",
    "        'classifier__n_neighbors': [3, 5, 7],\n",
    "        'classifier__weights': ['uniform', 'distance']\n",
    "    }\n",
    "\n",
    "    # 6. Create pipelines for different classifiers\n",
    "    rf_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    svm_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', SVC(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    knn_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    # 7. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 8. Hyperparameter tuning with GridSearchCV\n",
    "    rf_grid = GridSearchCV(rf_pipeline, param_grid_rf, cv=3, scoring='f1_weighted')\n",
    "    svm_grid = GridSearchCV(svm_pipeline, param_grid_svm, cv=3, scoring='f1_weighted')\n",
    "    knn_grid = GridSearchCV(knn_pipeline, param_grid_knn, cv=3, scoring='f1_weighted')\n",
    "\n",
    "    # 9. Train models with best parameters and calculate F1 scores\n",
    "    best_models = {}\n",
    "    f1_scores = {}\n",
    "\n",
    "    # Random Forest\n",
    "    rf_grid.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_grid.predict(X_test)\n",
    "    f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "    best_models['RandomForest'] = rf_grid.best_estimator_\n",
    "    f1_scores['RandomForest'] = f1_rf\n",
    "\n",
    "    # SVM\n",
    "    svm_grid.fit(X_train, y_train)\n",
    "    y_pred_svm = svm_grid.predict(X_test)\n",
    "    f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "    best_models['SVM'] = svm_grid.best_estimator_\n",
    "    f1_scores['SVM'] = f1_svm\n",
    "\n",
    "    # KNN\n",
    "    knn_grid.fit(X_train, y_train)\n",
    "    y_pred_knn = knn_grid.predict(X_test)\n",
    "    f1_knn = f1_score(y_test, y_pred_knn, average='weighted')\n",
    "    best_models['KNN'] = knn_grid.best_estimator_\n",
    "    f1_scores['KNN'] = f1_knn\n",
    "\n",
    "    return best_models, f1_scores\n",
    "\n",
    "# Entrenar los modelos con ajuste de hiperparámetros\n",
    "best_models, f1_scores = train_classifiers_with_tuning(df)\n",
    "print(f'Best models: {best_models}')\n",
    "print(f'F1 scores: {f1_scores}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf5ea3cd-db8f-4b4a-a658-b95173c4630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros para RandomForestClassifier: Ajusta el número de árboles, la profundidad máxima y el número mínimo de muestras para dividir un nodo.\n",
    "# Parámetros para SVC: Ajusta el parámetro de regularización C, el kernel y el parámetro gamma.\n",
    "# Parámetros para KNeighborsClassifier: Ajusta el número de vecinos y el tipo de ponderación para los vecinos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75b8846d-1b97-4b7d-8365-6dc609b32df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(df):\n",
    "    \"\"\"\n",
    "    Function to train a random forest classifier on the 'mic' column of the dataframe.\n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        model: Trained RandomForestClassifier model.\n",
    "        f1: F1 score of the model on test data.\n",
    "        \n",
    "    Notes:\n",
    "        The 'antibiotic' column is encoded as:\n",
    "            - 0: meropenem\n",
    "            - 1: ciprofloxacin\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert 'antibiotic' column to binary values\n",
    "    df['antibiotic'] = df['antibiotic'].map({'meropenem': 0, 'ciprofloxacin': 1})\n",
    "    \n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic', 'antibiotic'])  # Drop label columns\n",
    "    #X = df.drop(columns=['phenotype', 'mic'])  # Drop label columns\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Encode 'mic' (target) using LabelEncoder (since it's multiclass)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Detect binary and multiclass features\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # 5. Create a pipeline that first applies preprocessing, then trains a random forest\n",
    "    model_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "\n",
    "    # 6. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 7. Train the model\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # 8. Make predictions and calculate the F1 score\n",
    "    y_pred = model_pipeline.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')  # Use 'weighted' for multiclass F1\n",
    "\n",
    "    return model_pipeline, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f895500-0c65-4af2-a1ea-8a60e3d9e0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model: Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['3000830', '3000206',\n",
      "                                                   '3006880', '3000676',\n",
      "                                                   '3003576', '3001216',\n",
      "                                                   '3000237', '3003548',\n",
      "                                                   '3001889', '3003652',\n",
      "                                                   '3003899', '3006228',\n",
      "                                                   '3003900', '3006881',\n",
      "                                                   '3001866', '3003479',\n",
      "                                                   '3000166', '3002540',\n",
      "                                                   '3006878', '3006874',\n",
      "                                                   '3000168', '3004290',\n",
      "                                                   '3006875', '30070...\n",
      "                                                  ['genus', 'species',\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier', RandomForestClassifier(random_state=42))])\n",
      "F1 score: 0.7135263475674756\n"
     ]
    }
   ],
   "source": [
    "model, f1 = train_random_forest(df)\n",
    "print(f'Trained model: {model}')\n",
    "print(f'F1 score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a534783d-0139-49c2-8921-13a90b7ac4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593a1ce3-1f5b-4d6f-9e4a-0c2aeaf415fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def train_classifiers_with_tuning(df):\n",
    "    \"\"\"\n",
    "    Function to train RandomForest, SVM, and KNN classifiers with hyperparameter tuning on the 'mic' column.\n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        best_models: Dictionary containing the best tuned models for each classifier.\n",
    "        f1_scores: Dictionary containing F1 scores for each best-tuned classifier on test data.\n",
    "        \n",
    "    Notes:\n",
    "        The 'antibiotic' column is encoded as:\n",
    "            - 0: meropenem\n",
    "            - 1: ciprofloxacin\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert 'antibiotic' column to binary values\n",
    "    df['antibiotic'] = df['antibiotic'].map({'meropenem': 0, 'ciprofloxacin': 1})\n",
    "    \n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic'])  # Drop label columns but keep 'antibiotic'\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Encode 'mic' (target) using LabelEncoder (since it's multiclass)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Detect binary and multiclass features\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # 5. Define parameter grids for hyperparameter tuning\n",
    "    param_grid_rf = {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "\n",
    "    param_grid_svm = {\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__kernel': ['linear', 'rbf'],\n",
    "        'classifier__gamma': ['scale', 'auto']\n",
    "    }\n",
    "\n",
    "    param_grid_knn = {\n",
    "        'classifier__n_neighbors': [3, 5, 7],\n",
    "        'classifier__weights': ['uniform', 'distance']\n",
    "    }\n",
    "\n",
    "    # 6. Create pipelines for different classifiers\n",
    "    rf_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    svm_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', SVC(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    knn_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    # 7. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 8. Hyperparameter tuning with GridSearchCV\n",
    "    rf_grid = GridSearchCV(rf_pipeline, param_grid_rf, cv=3, scoring='f1_weighted')\n",
    "    svm_grid = GridSearchCV(svm_pipeline, param_grid_svm, cv=3, scoring='f1_weighted')\n",
    "    knn_grid = GridSearchCV(knn_pipeline, param_grid_knn, cv=3, scoring='f1_weighted')\n",
    "\n",
    "    # 9. Train models with best parameters and calculate F1 scores\n",
    "    best_models = {}\n",
    "    f1_scores = {}\n",
    "\n",
    "    # Random Forest\n",
    "    rf_grid.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_grid.predict(X_test)\n",
    "    f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "    best_models['RandomForest'] = rf_grid.best_estimator_\n",
    "    f1_scores['RandomForest'] = f1_rf\n",
    "\n",
    "    # SVM\n",
    "    svm_grid.fit(X_train, y_train)\n",
    "    y_pred_svm = svm_grid.predict(X_test)\n",
    "    f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "    best_models['SVM'] = svm_grid.best_estimator_\n",
    "    f1_scores['SVM'] = f1_svm\n",
    "\n",
    "    # KNN\n",
    "    knn_grid.fit(X_train, y_train)\n",
    "    y_pred_knn = knn_grid.predict(X_test)\n",
    "    f1_knn = f1_score(y_test, y_pred_knn, average='weighted')\n",
    "    best_models['KNN'] = knn_grid.best_estimator_\n",
    "    f1_scores['KNN'] = f1_knn\n",
    "\n",
    "    return best_models, f1_scores\n",
    "\n",
    "# Entrenar los modelos con ajuste de hiperparámetros\n",
    "best_models, f1_scores = train_classifiers_with_tuning(df)\n",
    "print(f'Best models: {best_models}')\n",
    "print(f'F1 scores: {f1_scores}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "664ae761-28a0-4ee6-a3b1-0e47a9c6726b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antibiotic</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>mic</th>\n",
       "      <th>3005053</th>\n",
       "      <th>3000830</th>\n",
       "      <th>3003838</th>\n",
       "      <th>3000508</th>\n",
       "      <th>3003890</th>\n",
       "      <th>...</th>\n",
       "      <th>3007751-D87Y</th>\n",
       "      <th>3003926-D87Y</th>\n",
       "      <th>3003709-G46S</th>\n",
       "      <th>3004851-A39T</th>\n",
       "      <th>3004832-A501P</th>\n",
       "      <th>3003381-R20H</th>\n",
       "      <th>3003926-S83I</th>\n",
       "      <th>3003381-G121D</th>\n",
       "      <th>3004832-T483S</th>\n",
       "      <th>3004832-A311V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6704</th>\n",
       "      <td>ciprofloxacin</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>ciprofloxacin</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6706</th>\n",
       "      <td>ciprofloxacin</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6707</th>\n",
       "      <td>ciprofloxacin</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6708</th>\n",
       "      <td>ciprofloxacin</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5952 rows × 880 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         antibiotic          genus    species    phenotype    mic  3005053  \\\n",
       "0         meropenem  Acinetobacter  baumannii    Resistant  8.000      0.0   \n",
       "1         meropenem  Acinetobacter  baumannii    Resistant  8.000      0.0   \n",
       "2         meropenem  Acinetobacter  baumannii    Resistant  8.000      0.0   \n",
       "3         meropenem  Acinetobacter  baumannii    Resistant  8.000      0.0   \n",
       "4         meropenem  Acinetobacter  baumannii    Resistant  8.000      0.0   \n",
       "...             ...            ...        ...          ...    ...      ...   \n",
       "6704  ciprofloxacin     Salmonella   enterica  Susceptible  0.015      1.0   \n",
       "6705  ciprofloxacin     Salmonella   enterica  Susceptible  0.015      1.0   \n",
       "6706  ciprofloxacin     Salmonella   enterica  Susceptible  0.015      1.0   \n",
       "6707  ciprofloxacin     Salmonella   enterica  Susceptible  0.015      1.0   \n",
       "6708  ciprofloxacin     Salmonella   enterica  Susceptible  0.030      1.0   \n",
       "\n",
       "      3000830  3003838  3000508  3003890  ...  3007751-D87Y  3003926-D87Y  \\\n",
       "0         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "1         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "2         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "3         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "4         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "...       ...      ...      ...      ...  ...           ...           ...   \n",
       "6704      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6705      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6706      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6707      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6708      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "\n",
       "      3003709-G46S  3004851-A39T  3004832-A501P  3003381-R20H  3003926-S83I  \\\n",
       "0              0.0           0.0            0.0           0.0           0.0   \n",
       "1              0.0           0.0            0.0           0.0           0.0   \n",
       "2              0.0           0.0            0.0           0.0           0.0   \n",
       "3              0.0           0.0            0.0           0.0           0.0   \n",
       "4              0.0           0.0            0.0           0.0           0.0   \n",
       "...            ...           ...            ...           ...           ...   \n",
       "6704           0.0           0.0            0.0           0.0           0.0   \n",
       "6705           0.0           0.0            0.0           0.0           0.0   \n",
       "6706           0.0           0.0            0.0           0.0           0.0   \n",
       "6707           0.0           0.0            0.0           0.0           0.0   \n",
       "6708           0.0           0.0            0.0           0.0           0.0   \n",
       "\n",
       "      3003381-G121D  3004832-T483S  3004832-A311V  \n",
       "0               0.0            0.0            0.0  \n",
       "1               0.0            0.0            0.0  \n",
       "2               0.0            0.0            0.0  \n",
       "3               0.0            0.0            0.0  \n",
       "4               0.0            0.0            0.0  \n",
       "...             ...            ...            ...  \n",
       "6704            0.0            0.0            0.0  \n",
       "6705            0.0            0.0            0.0  \n",
       "6706            0.0            0.0            0.0  \n",
       "6707            0.0            0.0            0.0  \n",
       "6708            0.0            0.0            0.0  \n",
       "\n",
       "[5952 rows x 880 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e896a0-f4b3-47ab-9138-b6038c4285f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31ba7c66-9526-4965-a4c2-40dc0451afd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking F1 score: 0.9753082705043228\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def stacking_with_pipeline(df):\n",
    "    \"\"\"\n",
    "    Function to perform stacking of classifiers on the 'mic' column.\n",
    "    \n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        stacking_model: Fitted stacking classifier.\n",
    "        f1_score: F1 score on test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic'])  # Drop label columns\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Convert the target variable into categories\n",
    "    y = pd.cut(y, bins=3, labels=False)  # Adjust bins and labels as needed\n",
    "\n",
    "    # 3. Detect binary and multiclass features\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # 5. Define base classifiers for stacking\n",
    "    base_estimators = [\n",
    "        ('rf', RandomForestClassifier(random_state=42)),\n",
    "        ('svm', SVC(probability=True, random_state=42)),  # Set probability=True for stacking\n",
    "        ('knn', KNeighborsClassifier())\n",
    "    ]\n",
    "\n",
    "    # 6. Stacking classifier\n",
    "    stacking_classifier = StackingClassifier(estimators=base_estimators, final_estimator=RandomForestClassifier(random_state=42))\n",
    "\n",
    "    # 7. Create the pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', stacking_classifier)\n",
    "    ])\n",
    "\n",
    "    # 8. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 9. Train the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # 10. Predict and calculate F1 score\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    return pipeline, f1\n",
    "\n",
    "# Train the stacking model\n",
    "stacking_model, f1_stacking = stacking_with_pipeline(df)\n",
    "print(f'Stacking F1 score: {f1_stacking}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac42dee5-a247-4d71-aa26-d3704e1f4c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation F1 Scores: [0.97673517 0.79848855 0.98691791]\n",
      "Mean F1 Score: 0.9207138746782751\n",
      "Stacking F1 score: 0.9753082705043228\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def stacking_with_pipeline(df):\n",
    "    \"\"\"\n",
    "    Function to perform stacking of classifiers on the 'mic' column.\n",
    "    \n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        stacking_model: Fitted stacking classifier.\n",
    "        f1_score: F1 score on test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic'])  # Drop label columns\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Convert the target variable into categories\n",
    "    y = pd.cut(y, bins=3, labels=False)  # Adjust bins and labels as needed\n",
    "\n",
    "    # 3. Detect binary and multiclass features\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # 5. Define base classifiers for stacking\n",
    "    base_estimators = [\n",
    "        ('rf', RandomForestClassifier(random_state=42)),\n",
    "        ('svm', SVC(probability=True, random_state=42)),  # Set probability=True for stacking\n",
    "        ('knn', KNeighborsClassifier())\n",
    "    ]\n",
    "\n",
    "    # 6. Stacking classifier\n",
    "    stacking_classifier = StackingClassifier(estimators=base_estimators, final_estimator=RandomForestClassifier(random_state=42))\n",
    "\n",
    "    # 7. Create the pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', stacking_classifier)\n",
    "    ])\n",
    "\n",
    "    # 8. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 9. Train the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # 10. Predict and calculate F1 score\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Evaluar el modelo con validación cruzada\n",
    "    scores = cross_val_score(pipeline, X, y, cv=3, scoring='f1_weighted')  # Reduce n_splits if necessary\n",
    "    print(f'Cross-Validation F1 Scores: {scores}')\n",
    "    print(f'Mean F1 Score: {scores.mean()}')\n",
    "\n",
    "    return pipeline, f1\n",
    "\n",
    "# Train the stacking model\n",
    "stacking_model, f1_stacking = stacking_with_pipeline(df)\n",
    "print(f'Stacking F1 score: {f1_stacking}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5ce0cf9-a24f-4695-b64b-d9289f66819e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 77\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pipeline, f1\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Train the stacking model\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m stacking_model, f1_stacking \u001b[38;5;241m=\u001b[39m \u001b[43mstacking_with_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStacking F1 score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_stacking\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[36], line 63\u001b[0m, in \u001b[0;36mstacking_with_pipeline\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     60\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# 9. Train the pipeline\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# 10. Predict and calculate F1 score\u001b[39;00m\n\u001b[1;32m     66\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/pipeline.py:476\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    475\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 476\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/ensemble/_stacking.py:658\u001b[0m, in \u001b[0;36mStackingClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the estimators.\u001b[39;00m\n\u001b[1;32m    634\u001b[0m \n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;124;03m    Returns a fitted instance of estimator.\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    657\u001b[0m _raise_for_unsupported_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[0;32m--> 658\u001b[0m \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m type_of_target(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder \u001b[38;5;241m=\u001b[39m [LabelEncoder()\u001b[38;5;241m.\u001b[39mfit(yk) \u001b[38;5;28;01mfor\u001b[39;00m yk \u001b[38;5;129;01min\u001b[39;00m y\u001b[38;5;241m.\u001b[39mT]\n",
      "File \u001b[0;32m/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/multiclass.py:221\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    213\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m ]:\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def stacking_with_pipeline(df):\n",
    "    \"\"\"\n",
    "    Function to perform stacking of classifiers on the 'mic' column.\n",
    "    \n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        stacking_model: Fitted stacking classifier.\n",
    "        f1_score: F1 score on test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic'])  # Drop label columns\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "  # 2. Encode 'mic' (target) using LabelEncoder (since it's multiclass)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Detect binary and multiclass features\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # 5. Define base classifiers for stacking\n",
    "    base_estimators = [\n",
    "        ('rf', RandomForestClassifier(random_state=42)),\n",
    "        ('svm', SVC(probability=True, random_state=42)),  # Set probability=True for stacking\n",
    "        ('knn', KNeighborsClassifier())\n",
    "    ]\n",
    "\n",
    "    # 6. Stacking classifier\n",
    "    stacking_classifier = StackingClassifier(estimators=base_estimators, final_estimator=RandomForestClassifier(random_state=42))\n",
    "\n",
    "    # 7. Create the pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', stacking_classifier)\n",
    "    ])\n",
    "\n",
    "    # 8. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 9. Train the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # 10. Predict and calculate F1 score\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Evaluar el modelo con validación cruzada\n",
    "    scores = cross_val_score(pipeline, X, y, cv=3, scoring='f1_weighted')  # Reduce n_splits if necessary\n",
    "    print(f'Cross-Validation F1 Scores: {scores}')\n",
    "    print(f'Mean F1 Score: {scores.mean()}')\n",
    "\n",
    "    return pipeline, f1\n",
    "\n",
    "# Train the stacking model\n",
    "stacking_model, f1_stacking = stacking_with_pipeline(df)\n",
    "print(f'Stacking F1 score: {f1_stacking}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc51817a-4164-4a73-9757-e24d1490f86f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umap",
   "language": "python",
   "name": "umap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
