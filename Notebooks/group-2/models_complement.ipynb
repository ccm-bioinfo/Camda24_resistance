{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a67742-9e2c-4dec-843b-d1738fbfff61",
   "metadata": {},
   "source": [
    "# Random Forest (Reproducible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066dc26d-04f7-4ff7-bde9-fa2e26c3f6cd",
   "metadata": {},
   "source": [
    "Importamos paqueterías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6840f1f2-d9d0-4ec9-8c77-3d8a8bdb961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6924a1-83a2-471c-b6fd-0c3dadb13670",
   "metadata": {},
   "source": [
    "Importamos la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7447a125-d90f-4f11-8cd9-46041666050e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1421065/1368114445.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "filepath = '/home/jupyter-user7/CAMDA/Camda24_resistance/DataSets/group-2/data/combined_antibiotic_resistance.tsv'\n",
    "df = pd.read_csv(filepath, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f75702-54b5-4fcc-acce-7bf0a8d908fa",
   "metadata": {},
   "source": [
    "Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd7d888a-b924-4d6c-a692-0b32211e88f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antibiotic</th>\n",
       "      <th>accession</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>mic</th>\n",
       "      <th>3005053</th>\n",
       "      <th>3000830</th>\n",
       "      <th>3003838</th>\n",
       "      <th>3000508</th>\n",
       "      <th>...</th>\n",
       "      <th>3007751-D87Y</th>\n",
       "      <th>3003926-D87Y</th>\n",
       "      <th>3003709-G46S</th>\n",
       "      <th>3004851-A39T</th>\n",
       "      <th>3004832-A501P</th>\n",
       "      <th>3003381-R20H</th>\n",
       "      <th>3003926-S83I</th>\n",
       "      <th>3003381-G121D</th>\n",
       "      <th>3004832-T483S</th>\n",
       "      <th>3004832-A311V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_002947415</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_002947845</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_002948925</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_002996805</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_003006035</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 881 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  antibiotic      accession          genus    species  phenotype  mic  \\\n",
       "0  meropenem  GCA_002947415  Acinetobacter  baumannii  Resistant  8.0   \n",
       "1  meropenem  GCA_002947845  Acinetobacter  baumannii  Resistant  8.0   \n",
       "2  meropenem  GCA_002948925  Acinetobacter  baumannii  Resistant  8.0   \n",
       "3  meropenem  GCA_002996805  Acinetobacter  baumannii  Resistant  8.0   \n",
       "4  meropenem  GCA_003006035  Acinetobacter  baumannii  Resistant  8.0   \n",
       "\n",
       "   3005053  3000830  3003838  3000508  ...  3007751-D87Y  3003926-D87Y  \\\n",
       "0      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "1      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "2      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "3      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "4      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "\n",
       "   3003709-G46S  3004851-A39T  3004832-A501P  3003381-R20H  3003926-S83I  \\\n",
       "0           0.0           0.0            0.0           0.0           0.0   \n",
       "1           0.0           0.0            0.0           0.0           0.0   \n",
       "2           0.0           0.0            0.0           0.0           0.0   \n",
       "3           0.0           0.0            0.0           0.0           0.0   \n",
       "4           0.0           0.0            0.0           0.0           0.0   \n",
       "\n",
       "   3003381-G121D  3004832-T483S  3004832-A311V  \n",
       "0            0.0            0.0            0.0  \n",
       "1            0.0            0.0            0.0  \n",
       "2            0.0            0.0            0.0  \n",
       "3            0.0            0.0            0.0  \n",
       "4            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 881 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e102dd8-3412-4d3e-965f-356991f74597",
   "metadata": {},
   "source": [
    "## Modelo de Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e66fce5c-a6fa-4629-b584-2694b1097373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(df):\n",
    "    \"\"\"\n",
    "    Function to train a random forest classifier on the 'mic' column of the dataframe.\n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        model: Trained RandomForestClassifier model.\n",
    "        f1: F1 score of the model on test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic',\"antibiotic\"])  # Drop label columns\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Encode 'mic' (target) using LabelEncoder (since it's multiclass)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Detect binary and multiclass features\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    # Binary columns don't need much processing, multiclass columns need one-hot encoding\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns Con handle_unknown='ignore', el codificador ignorará las categorías desconocidas y no producirá un error durante la predicción.\n",
    "        ], remainder='passthrough')  # Any remaining columns are passed through (if any)\n",
    "\n",
    "    # 5. Create a pipeline that first applies preprocessing, then trains a random forest\n",
    "    model_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "\n",
    "    # 6. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 7. Train the model\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # 8. Make predictions and calculate the F1 score\n",
    "    y_pred = model_pipeline.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')  # Use 'weighted' for multiclass F1\n",
    "\n",
    "    return model_pipeline, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dfbe903-b776-42cb-bc47-2ebc4137309e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model: Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['3000830', '3000206',\n",
      "                                                   '3006880', '3000676',\n",
      "                                                   '3003576', '3001216',\n",
      "                                                   '3000237', '3003548',\n",
      "                                                   '3001889', '3003652',\n",
      "                                                   '3003899', '3006228',\n",
      "                                                   '3003900', '3006881',\n",
      "                                                   '3001866', '3003479',\n",
      "                                                   '3000166', '3006878',\n",
      "                                                   '3006874', '3000168',\n",
      "                                                   '3004290', '3006875',\n",
      "                                                   '3007014', '30050...\n",
      "                                                  ['accession', 'genus',\n",
      "                                                   'species', '3005053',\n",
      "                                                   '3003838', '3000508',\n",
      "                                                   '3003890', '3000491',\n",
      "                                                   '3000833', '3000832',\n",
      "                                                   '3000254', '3000502',\n",
      "                                                   '3000499', '3000656',\n",
      "                                                   '3004039', '3000516',\n",
      "                                                   '3003578', '3000027',\n",
      "                                                   '3000074', '3003378',\n",
      "                                                   '3000263', '3000165',\n",
      "                                                   '3002660', '3002639',\n",
      "                                                   '3000412', '3000410',\n",
      "                                                   '3005010', '3002605',\n",
      "                                                   '3002860', '3000316', ...])])),\n",
      "                ('classifier', RandomForestClassifier(random_state=42))])\n",
      "F1 score: 0.6617684712976223\n"
     ]
    }
   ],
   "source": [
    "model, f1 = train_random_forest(df)\n",
    "print(f'Trained model: {model}')\n",
    "print(f'F1 score: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504ee810-15df-48e8-971f-0614a4a0f21c",
   "metadata": {},
   "source": [
    "## Entrenamiento y evaluación de los clasificadores RandomForest, SVC y KNeighborsC con preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "887bde1f-3a0b-446f-905b-a8a35d872056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def train_classifiers(df):\n",
    "    \"\"\"\n",
    "    Function to train RandomForest, SVM, and KNN classifiers on the 'mic' column of the dataframe.\n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        models: Dictionary containing trained models for each classifier.\n",
    "        f1_scores: Dictionary containing F1 scores for each classifier on test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic', \"antibiotic\"])  # Drop label columns\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Encode 'mic' (target) using LabelEncoder (since it's multiclass)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Detect binary and multiclass features\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    # Binary columns don't need much processing, multiclass columns need one-hot encoding\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough')  # Any remaining columns are passed through (if any)\n",
    "\n",
    "    # 5. Create pipelines for different classifiers\n",
    "    rf_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    svm_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', SVC(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    knn_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    # 6. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 7. Train models and calculate F1 scores\n",
    "    models = {}\n",
    "    f1_scores = {}\n",
    "\n",
    "    # Random Forest\n",
    "    rf_pipeline.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_pipeline.predict(X_test)\n",
    "    f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "    models['RandomForest'] = rf_pipeline\n",
    "    f1_scores['RandomForest'] = f1_rf\n",
    "\n",
    "    # SVM\n",
    "    svm_pipeline.fit(X_train, y_train)\n",
    "    y_pred_svm = svm_pipeline.predict(X_test)\n",
    "    f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "    models['SVM'] = svm_pipeline\n",
    "    f1_scores['SVM'] = f1_svm\n",
    "\n",
    "    # KNN\n",
    "    knn_pipeline.fit(X_train, y_train)\n",
    "    y_pred_knn = knn_pipeline.predict(X_test)\n",
    "    f1_knn = f1_score(y_test, y_pred_knn, average='weighted')\n",
    "    models['KNN'] = knn_pipeline\n",
    "    f1_scores['KNN'] = f1_knn\n",
    "\n",
    "    return models, f1_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c80aac11-f853-4a9b-8363-417a67cef158",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models: {'RandomForest': Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['3000830', '3000206',\n",
      "                                                   '3006880', '3000676',\n",
      "                                                   '3003576', '3001216',\n",
      "                                                   '3000237', '3003548',\n",
      "                                                   '3001889', '3003652',\n",
      "                                                   '3003899', '3006228',\n",
      "                                                   '3003900', '3006881',\n",
      "                                                   '3001866', '3003479',\n",
      "                                                   '3000166', '3002540',\n",
      "                                                   '3006878', '3006874',\n",
      "                                                   '3000168', '3004290',\n",
      "                                                   '3006875', '30070...\n",
      "                                                  ['genus', 'species',\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier', RandomForestClassifier(random_state=42))]), 'SVM': Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['3000830', '3000206',\n",
      "                                                   '3006880', '3000676',\n",
      "                                                   '3003576', '3001216',\n",
      "                                                   '3000237', '3003548',\n",
      "                                                   '3001889', '3003652',\n",
      "                                                   '3003899', '3006228',\n",
      "                                                   '3003900', '3006881',\n",
      "                                                   '3001866', '3003479',\n",
      "                                                   '3000166', '3002540',\n",
      "                                                   '3006878', '3006874',\n",
      "                                                   '3000168', '3004290',\n",
      "                                                   '3006875', '30070...\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['genus', 'species',\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier', SVC(random_state=42))]), 'KNN': Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['3000830', '3000206',\n",
      "                                                   '3006880', '3000676',\n",
      "                                                   '3003576', '3001216',\n",
      "                                                   '3000237', '3003548',\n",
      "                                                   '3001889', '3003652',\n",
      "                                                   '3003899', '3006228',\n",
      "                                                   '3003900', '3006881',\n",
      "                                                   '3001866', '3003479',\n",
      "                                                   '3000166', '3002540',\n",
      "                                                   '3006878', '3006874',\n",
      "                                                   '3000168', '3004290',\n",
      "                                                   '3006875', '30070...\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['genus', 'species',\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier', KNeighborsClassifier())])}\n",
      "F1 scores: {'RandomForest': 0.7135263475674756, 'SVM': 0.6034210105056049, 'KNN': 0.6694039285905631}\n"
     ]
    }
   ],
   "source": [
    "models, f1_scores = train_classifiers(df)\n",
    "print(f'Trained models: {models}')\n",
    "print(f'F1 scores: {f1_scores}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3f9062-c324-4482-be61-fea931dd7970",
   "metadata": {},
   "source": [
    "## Entrenamiento de los tres modelos de clasificación con reajuste de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b90dc20-8f17-4c7b-848b-034e107bb5d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best models: {'RandomForest': Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['antibiotic', '3000830',\n",
      "                                                   '3000206', '3006880',\n",
      "                                                   '3000676', '3003576',\n",
      "                                                   '3001216', '3000237',\n",
      "                                                   '3003548', '3001889',\n",
      "                                                   '3003652', '3003899',\n",
      "                                                   '3006228', '3003900',\n",
      "                                                   '3006881', '3001866',\n",
      "                                                   '3003479', '3000166',\n",
      "                                                   '3002540', '3006878',\n",
      "                                                   '3006874', '3000168',\n",
      "                                                   '3004290', '30...\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier',\n",
      "                 RandomForestClassifier(n_estimators=50, random_state=42))]), 'SVM': Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['antibiotic', '3000830',\n",
      "                                                   '3000206', '3006880',\n",
      "                                                   '3000676', '3003576',\n",
      "                                                   '3001216', '3000237',\n",
      "                                                   '3003548', '3001889',\n",
      "                                                   '3003652', '3003899',\n",
      "                                                   '3006228', '3003900',\n",
      "                                                   '3006881', '3001866',\n",
      "                                                   '3003479', '3000166',\n",
      "                                                   '3002540', '3006878',\n",
      "                                                   '3006874', '3000168',\n",
      "                                                   '3004290', '30...\n",
      "                                                  ['genus', 'species',\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier', SVC(C=1, kernel='linear', random_state=42))]), 'KNN': Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['antibiotic', '3000830',\n",
      "                                                   '3000206', '3006880',\n",
      "                                                   '3000676', '3003576',\n",
      "                                                   '3001216', '3000237',\n",
      "                                                   '3003548', '3001889',\n",
      "                                                   '3003652', '3003899',\n",
      "                                                   '3006228', '3003900',\n",
      "                                                   '3006881', '3001866',\n",
      "                                                   '3003479', '3000166',\n",
      "                                                   '3002540', '3006878',\n",
      "                                                   '3006874', '3000168',\n",
      "                                                   '3004290', '30...\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier',\n",
      "                 KNeighborsClassifier(n_neighbors=7, weights='distance'))])}\n",
      "F1 scores: {'RandomForest': 0.7100475306171872, 'SVM': 0.6921599743102079, 'KNN': 0.6860654616879825}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def train_classifiers_with_tuning(df):\n",
    "    \"\"\"\n",
    "    Function to train RandomForest, SVM, and KNN classifiers with hyperparameter tuning on the 'mic' column.\n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        best_models: Dictionary containing the best tuned models for each classifier.\n",
    "        f1_scores: Dictionary containing F1 scores for each best-tuned classifier on test data.\n",
    "  \n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic'])  # Drop label columns \"antibiotic\"\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Encode 'mic' (target) using LabelEncoder (since it's multiclass)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Detect binary and multiclass features\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # 5. Define parameter grids for hyperparameter tuning\n",
    "    param_grid_rf = {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "\n",
    "    param_grid_svm = {\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__kernel': ['linear', 'rbf'],\n",
    "        'classifier__gamma': ['scale', 'auto']\n",
    "    }\n",
    "\n",
    "    param_grid_knn = {\n",
    "        'classifier__n_neighbors': [3, 5, 7],\n",
    "        'classifier__weights': ['uniform', 'distance']\n",
    "    }\n",
    "\n",
    "    # 6. Create pipelines for different classifiers\n",
    "    rf_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    svm_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', SVC(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    knn_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    # 7. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 8. Hyperparameter tuning with GridSearchCV\n",
    "    rf_grid = GridSearchCV(rf_pipeline, param_grid_rf, cv=3, scoring='f1_weighted')\n",
    "    svm_grid = GridSearchCV(svm_pipeline, param_grid_svm, cv=3, scoring='f1_weighted')\n",
    "    knn_grid = GridSearchCV(knn_pipeline, param_grid_knn, cv=3, scoring='f1_weighted')\n",
    "\n",
    "    # 9. Train models with best parameters and calculate F1 scores\n",
    "    best_models = {}\n",
    "    f1_scores = {}\n",
    "\n",
    "    # Random Forest\n",
    "    rf_grid.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_grid.predict(X_test)\n",
    "    f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "    best_models['RandomForest'] = rf_grid.best_estimator_\n",
    "    f1_scores['RandomForest'] = f1_rf\n",
    "\n",
    "    # SVM\n",
    "    svm_grid.fit(X_train, y_train)\n",
    "    y_pred_svm = svm_grid.predict(X_test)\n",
    "    f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "    best_models['SVM'] = svm_grid.best_estimator_\n",
    "    f1_scores['SVM'] = f1_svm\n",
    "\n",
    "    # KNN\n",
    "    knn_grid.fit(X_train, y_train)\n",
    "    y_pred_knn = knn_grid.predict(X_test)\n",
    "    f1_knn = f1_score(y_test, y_pred_knn, average='weighted')\n",
    "    best_models['KNN'] = knn_grid.best_estimator_\n",
    "    f1_scores['KNN'] = f1_knn\n",
    "\n",
    "    return best_models, f1_scores\n",
    "\n",
    "# Entrenar los modelos con ajuste de hiperparámetros\n",
    "best_models, f1_scores = train_classifiers_with_tuning(df)\n",
    "print(f'Best models: {best_models}')\n",
    "print(f'F1 scores: {f1_scores}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5ea3cd-db8f-4b4a-a658-b95173c4630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros para RandomForestClassifier: Ajusta el número de árboles, la profundidad máxima y el número mínimo de muestras para dividir un nodo.\n",
    "# Parámetros para SVC: Ajusta el parámetro de regularización C, el kernel y el parámetro gamma.\n",
    "# Parámetros para KNeighborsClassifier: Ajusta el número de vecinos y el tipo de ponderación para los vecinos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab32676f-8330-41c7-b213-63c28e3ef017",
   "metadata": {},
   "source": [
    "## Entrenamiento de los tres modelos de clasificación con reajuste de hiperparámetros con distintas métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f895500-0c65-4af2-a1ea-8a60e3d9e0bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "def train_classifiers_with_metrics(df):\n",
    "    \"\"\"\n",
    "    Train and evaluate RandomForest, SVM, and KNN classifiers with hyperparameter tuning on the 'mic' column.\n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        best_models: Dictionary containing the best tuned models for each classifier.\n",
    "        metrics: Dictionary containing metrics for each best-tuned classifier on test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic'])  # Drop label columns\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Encode 'mic' (target) using LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Detect categorical features for encoding\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    numeric_cols = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', 'passthrough', numeric_cols),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 5. Define parameter grids for hyperparameter tuning\n",
    "    param_grids = {\n",
    "        'RandomForest': {\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__max_depth': [None, 10, 20],\n",
    "            'classifier__min_samples_split': [2, 5, 10]\n",
    "        },\n",
    "        'SVM': {\n",
    "            'classifier__C': [0.1, 1, 10],\n",
    "            'classifier__kernel': ['linear', 'rbf'],\n",
    "            'classifier__gamma': ['scale', 'auto']\n",
    "        },\n",
    "        'KNN': {\n",
    "            'classifier__n_neighbors': [3, 5, 7],\n",
    "            'classifier__weights': ['uniform', 'distance']\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 6. Create pipelines for classifiers\n",
    "    pipelines = {\n",
    "        'RandomForest': Pipeline([\n",
    "            ('preprocessing', preprocessor),\n",
    "            ('classifier', RandomForestClassifier(random_state=42))\n",
    "        ]),\n",
    "        'SVM': Pipeline([\n",
    "            ('preprocessing', preprocessor),\n",
    "            ('classifier', SVC(random_state=42))\n",
    "        ]),\n",
    "        'KNN': Pipeline([\n",
    "            ('preprocessing', preprocessor),\n",
    "            ('classifier', KNeighborsClassifier())\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    # 7. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 8. Train models, perform hyperparameter tuning, and calculate metrics\n",
    "    best_models = {}\n",
    "    metrics = {}\n",
    "\n",
    "    for name, pipeline in pipelines.items():\n",
    "        print(f\"Training and tuning {name}...\")\n",
    "\n",
    "        # Hyperparameter tuning\n",
    "        grid_search = GridSearchCV(pipeline, param_grids[name], cv=3, scoring='f1_weighted', error_score='raise')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Get the best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_models[name] = best_model\n",
    "\n",
    "        # Predictions\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        metrics[name] = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "            'recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "            'f1_score': f1_score(y_test, y_pred, average='weighted')\n",
    "            #'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
    "        }\n",
    "\n",
    "    return best_models, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a534783d-0139-49c2-8921-13a90b7ac4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and tuning RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and tuning SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and tuning KNN...\n",
      "\n",
      "Metrics for RandomForest:\n",
      "accuracy: 0.7022508038585209\n",
      "precision: 0.6848024827565329\n",
      "recall: 0.7022508038585209\n",
      "f1_score: 0.6717188255019244\n",
      "\n",
      "Metrics for SVM:\n",
      "accuracy: 0.7022508038585209\n",
      "precision: 0.6694115031871631\n",
      "recall: 0.7022508038585209\n",
      "f1_score: 0.6644823619560657\n",
      "\n",
      "Metrics for KNN:\n",
      "accuracy: 0.6527331189710611\n",
      "precision: 0.6351292916155808\n",
      "recall: 0.6527331189710611\n",
      "f1_score: 0.6341902336519429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "best_models, metrics = train_classifiers_with_metrics(df)\n",
    "for model_name, model_metrics in metrics.items():\n",
    "    print(f\"\\nMetrics for {model_name}:\")\n",
    "    for metric, value in model_metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1893a852-f143-4555-9180-686fa72d021a",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Entrenamiento de los tres modelos de clasificación con reajuste de hiperparámetros con gridsearch, k-fold cross validation con distintas métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "927f33d9-563e-4956-951a-e14d3ff979a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "def train_classifiers_with_metrics(df):\n",
    "    \"\"\"\n",
    "    Train and evaluate RandomForest, SVM, and KNN classifiers with hyperparameter tuning using k-fold cross-validation.\n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        best_models: Dictionary containing the best tuned models for each classifier.\n",
    "        metrics: Dictionary containing metrics for each best-tuned classifier on test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic'])  # Drop label columns\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Encode 'mic' (target) using LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Detect categorical features for encoding\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    numeric_cols = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', 'passthrough', numeric_cols),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 5. Define parameter grids for hyperparameter tuning\n",
    "    param_grids = {\n",
    "        'RandomForest': {\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__max_depth': [None, 10, 20],\n",
    "            'classifier__min_samples_split': [2, 5, 10]\n",
    "        },\n",
    "        'SVM': {\n",
    "            'classifier__C': [0.1, 1, 10],\n",
    "            'classifier__kernel': ['linear', 'rbf'],\n",
    "            'classifier__gamma': ['scale', 'auto']\n",
    "        },\n",
    "        'KNN': {\n",
    "            'classifier__n_neighbors': [3, 5, 7],\n",
    "            'classifier__weights': ['uniform', 'distance']\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 6. Create pipelines for classifiers\n",
    "    pipelines = {\n",
    "        'RandomForest': Pipeline([\n",
    "            ('preprocessing', preprocessor),\n",
    "            ('classifier', RandomForestClassifier(random_state=42))\n",
    "        ]),\n",
    "        'SVM': Pipeline([\n",
    "            ('preprocessing', preprocessor),\n",
    "            ('classifier', SVC(random_state=42))\n",
    "        ]),\n",
    "        'KNN': Pipeline([\n",
    "            ('preprocessing', preprocessor),\n",
    "            ('classifier', KNeighborsClassifier())\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    # 7. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 8. Initialize k-fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # 9. Train models, perform hyperparameter tuning, and calculate metrics\n",
    "    best_models = {}\n",
    "    metrics = {}\n",
    "\n",
    "    for name, pipeline in pipelines.items():\n",
    "        print(f\"Training and tuning {name}...\")\n",
    "\n",
    "        # Hyperparameter tuning using GridSearchCV with k-fold cross-validation\n",
    "        grid_search = GridSearchCV(pipeline, param_grids[name], cv=kf, scoring='f1_weighted', error_score='raise')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Get the best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_models[name] = best_model\n",
    "\n",
    "        # Predictions on the test set\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        metrics[name] = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "            'recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "            'f1_score': f1_score(y_test, y_pred, average='weighted')\n",
    "            #'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
    "        }\n",
    "\n",
    "    return best_models, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ec52d94-cdbe-48b7-88d2-01e21d3236f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and tuning RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and tuning SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and tuning KNN...\n",
      "Best Models:\n",
      "RandomForest: Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(transformers=[('num', 'passthrough',\n",
      "                                                  ['3005053', '3000830',\n",
      "                                                   '3003838', '3000508',\n",
      "                                                   '3003890', '3000491',\n",
      "                                                   '3000833', '3000832',\n",
      "                                                   '3000206', '3000254',\n",
      "                                                   '3006880', '3000502',\n",
      "                                                   '3000499', '3000656',\n",
      "                                                   '3000676', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860', ...]),\n",
      "                                                 ('cat',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['antibiotic', 'accession',\n",
      "                                                   'genus', 'species'])])),\n",
      "                ('classifier',\n",
      "                 RandomForestClassifier(n_estimators=200, random_state=42))])\n",
      "SVM: Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(transformers=[('num', 'passthrough',\n",
      "                                                  ['3005053', '3000830',\n",
      "                                                   '3003838', '3000508',\n",
      "                                                   '3003890', '3000491',\n",
      "                                                   '3000833', '3000832',\n",
      "                                                   '3000206', '3000254',\n",
      "                                                   '3006880', '3000502',\n",
      "                                                   '3000499', '3000656',\n",
      "                                                   '3000676', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860', ...]),\n",
      "                                                 ('cat',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['antibiotic', 'accession',\n",
      "                                                   'genus', 'species'])])),\n",
      "                ('classifier', SVC(C=10, random_state=42))])\n",
      "KNN: Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(transformers=[('num', 'passthrough',\n",
      "                                                  ['3005053', '3000830',\n",
      "                                                   '3003838', '3000508',\n",
      "                                                   '3003890', '3000491',\n",
      "                                                   '3000833', '3000832',\n",
      "                                                   '3000206', '3000254',\n",
      "                                                   '3006880', '3000502',\n",
      "                                                   '3000499', '3000656',\n",
      "                                                   '3000676', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860', ...]),\n",
      "                                                 ('cat',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['antibiotic', 'accession',\n",
      "                                                   'genus', 'species'])])),\n",
      "                ('classifier', KNeighborsClassifier(weights='distance'))])\n",
      "\n",
      "Metrics:\n",
      "RandomForest: {'accuracy': 0.7022508038585209, 'precision': 0.6848024827565329, 'recall': 0.7022508038585209, 'f1_score': 0.6717188255019244}\n",
      "SVM: {'accuracy': 0.7022508038585209, 'precision': 0.6694115031871631, 'recall': 0.7022508038585209, 'f1_score': 0.6644823619560657}\n",
      "KNN: {'accuracy': 0.6527331189710611, 'precision': 0.6351292916155808, 'recall': 0.6527331189710611, 'f1_score': 0.6341902336519429}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "best_models, metrics = train_classifiers_with_metrics(df)\n",
    "\n",
    "print(\"Best Models:\")\n",
    "for model_name, model in best_models.items():\n",
    "    print(f\"{model_name}: {model}\")\n",
    "\n",
    "print(\"\\nMetrics:\")\n",
    "for model_name, metric in metrics.items():\n",
    "    print(f\"{model_name}: {metric}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d68ba-ef63-47f7-8fac-5214dfb5e0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7c4b33-b7db-41f2-8653-72b131f872df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b03c63-1ede-44b8-9da0-0dfcb514d9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664ae761-28a0-4ee6-a3b1-0e47a9c6726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e896a0-f4b3-47ab-9138-b6038c4285f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"mic\"].max(),df[\"mic\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f222959-389e-4c2c-9279-98935dfc15b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['mic'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5b30a-6c4c-4d94-8fba-fd47d097d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"mic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31ba7c66-9526-4965-a4c2-40dc0451afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def train_classifiers_with_stacking(df):\n",
    "    \"\"\"\n",
    "    Function to train RandomForest, SVM, and KNN classifiers with hyperparameter tuning using K-Fold Cross-Validation,\n",
    "    and combine them using StackingClassifier.\n",
    "    \n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        stacking_model: Trained stacking model.\n",
    "        f1_stacking: F1 score of the stacking model on the test data.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic'])  # Drop label columns but keep 'antibiotic'\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Encode 'mic' (target) using LabelEncoder (since it's multiclass)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Detect binary and multiclass features\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # 5. Create base models (without hyperparameter tuning)\n",
    "    rf_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    svm_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', SVC(random_state=42, probability=True))  # We need probability=True for stacking\n",
    "    ])\n",
    "    \n",
    "    knn_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    # 6. Meta-classifier for stacking (Logistic Regression)\n",
    "    meta_classifier = LogisticRegression()\n",
    "\n",
    "    # 7. StackingClassifier: combines base models\n",
    "    stacking_model = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', rf_model),\n",
    "            ('svm', svm_model),\n",
    "            ('knn', knn_model)\n",
    "        ],\n",
    "        final_estimator=meta_classifier,\n",
    "        cv=5  # Cross-validation for stacking\n",
    "    )\n",
    "\n",
    "    # 8. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 9. Train the stacking model\n",
    "    stacking_model.fit(X_train, y_train)\n",
    "\n",
    "    # 10. Make predictions and calculate F1 score\n",
    "    y_pred_stacking = stacking_model.predict(X_test)\n",
    "    f1_stacking = f1_score(y_test, y_pred_stacking, average='weighted')\n",
    "\n",
    "    return stacking_model, f1_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac42dee5-a247-4d71-aa26-d3704e1f4c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (26) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (26) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (25) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (25) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (26) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (26) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (25) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (25) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (26) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (26) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (25) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (25) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Model F1 Score: 0.704428213409905\n"
     ]
    }
   ],
   "source": [
    "stacking_model, f1_stacking = train_classifiers_with_stacking(df)\n",
    "print(f'Stacking Model F1 Score: {f1_stacking}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ce0cf9-a24f-4695-b64b-d9289f66819e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc51817a-4164-4a73-9757-e24d1490f86f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f417c1c4-df7a-4db6-9511-0dccf6c1d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mic_transform(mic_values):\n",
    "    log_mic = np.log2(mic_values)\n",
    "    rounded_mic = np.round(log_mic).clip(-7, 7)  # Limitar a potencias entre -7 y 7\n",
    "    return rounded_mic\n",
    "\n",
    "mic_transformer = FunctionTransformer(mic_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5473b37c-3187-4d96-a3ec-cc4c349e4b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d9dd11-4f25-4250-a9bc-61a5fe4c8412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38b48c63-8664-4cf3-a2f5-cb5f8aa9ab8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Model F1 Score: 0.7101268174047273\n"
     ]
    }
   ],
   "source": [
    "def train_classifiers_with_stacking(df):\n",
    "    \"\"\"\n",
    "    Function to train RandomForest, SVM, and KNN classifiers with hyperparameter tuning using K-Fold Cross-Validation,\n",
    "    and combine them using StackingClassifier.\n",
    "    \n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        stacking_model: Trained stacking model.\n",
    "        f1_stacking: F1 score of the stacking model on the test data.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic'])  # Drop label columns but keep 'antibiotic'\n",
    "    y = df['mic']  # Target label (mic)\n",
    "\n",
    "    # 2. Apply log2 transformation and rounding to `mic` using FunctionTransformer\n",
    "    y_transformed = mic_transformer.fit_transform(y.values.reshape(-1, 1)).ravel()  # Transform `mic` column\n",
    "\n",
    "    # 3. Detect binary and multiclass features in X\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # 5. Create base models (without hyperparameter tuning)\n",
    "    rf_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    svm_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', SVC(random_state=42, probability=True))  # We need probability=True for stacking\n",
    "    ])\n",
    "    \n",
    "    knn_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    # 6. Meta-classifier for stacking (Logistic Regression)\n",
    "    meta_classifier = LogisticRegression()\n",
    "\n",
    "    # 7. StackingClassifier: combines base models\n",
    "    stacking_model = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', rf_model),\n",
    "            ('svm', svm_model),\n",
    "            ('knn', knn_model)\n",
    "        ],\n",
    "        final_estimator=meta_classifier,\n",
    "        cv=5  # Cross-validation for stacking\n",
    "    )\n",
    "\n",
    "    # 8. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_transformed, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 9. Train the stacking model\n",
    "    stacking_model.fit(X_train, y_train)\n",
    "\n",
    "    # 10. Make predictions and calculate F1 score\n",
    "    y_pred_stacking = stacking_model.predict(X_test)\n",
    "    f1_stacking = f1_score(y_test, y_pred_stacking, average='weighted')\n",
    "\n",
    "    return stacking_model, f1_stacking\n",
    "\n",
    "# Entrenar el modelo de stacking con la transformación de mic\n",
    "stacking_model, f1_stacking = train_classifiers_with_stacking(df)\n",
    "print(f'Stacking Model F1 Score: {f1_stacking}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8cf1a851-0e22-4677-a4d0-dc44786fdbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 1. Convert 'phenotype' values (Resistant, Susceptible) into binary labels\n",
    "    df['phenotype'] = df['phenotype'].map({'Resistant': 1, 'Susceptible': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "186dacac-8354-4ede-a742-5592457dc8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multioutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08e2e0dc-939c-4151-a530-99177442f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifiers_with_multioutput(df):\n",
    "    \"\"\"\n",
    "    Function to train RandomForest, SVM, and KNN classifiers for multi-output prediction (predicting both mic and phenotype),\n",
    "    and combine them using StackingClassifier and MultiOutputClassifier.\n",
    "    \n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels (mic and phenotype).\n",
    "        \n",
    "    Returns:\n",
    "        stacking_model: Trained multi-output stacking model.\n",
    "        f1_scores: Dictionary containing F1 scores for mic and phenotype on the test data.\n",
    "    \"\"\"\n",
    "\n",
    "    # 2. Separate features and labels\n",
    "    X = df.drop(columns=['mic', 'phenotype'])  # Features\n",
    "    y_mic = df['mic']  # Target label 1 (mic)\n",
    "    y_phenotype = df['phenotype']  # Target label 2 (phenotype)\n",
    "\n",
    "    # 3. Apply log2 transformation\n",
    "    y_mic_transformed = mic_transformer.fit_transform(y_mic.values.reshape(-1, 1)).ravel()  # Transform `mic` column\n",
    "\n",
    "    # 4. Detect binary and multiclass features in X\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 5. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # 6. Create base models \n",
    "    rf_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    svm_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', SVC(random_state=42, probability=True))  # We need probability=True for stacking\n",
    "    ])\n",
    "    \n",
    "    knn_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    # 7. Meta-classifier for stacking \n",
    "    meta_classifier = LogisticRegression()\n",
    "\n",
    "    # 8. StackingClassifier: combines base models\n",
    "    stacking_model = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', rf_model),\n",
    "            ('svm', svm_model),\n",
    "            ('knn', knn_model)\n",
    "        ],\n",
    "        final_estimator=meta_classifier,\n",
    "        cv=5  \n",
    "    )\n",
    "\n",
    "    # 9. Use MultiOutputClassifier to predict both mic and phenotype\n",
    "    multioutput_model = MultiOutputClassifier(stacking_model)\n",
    "\n",
    "    # 10. Split data into training and testing sets for both mic and phenotype\n",
    "    y_combined = np.column_stack([y_mic_transformed, y_phenotype])  # Combine both target variables\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 11. Train the multi-output model\n",
    "    multioutput_model.fit(X_train, y_train)\n",
    "\n",
    "    # 12. Make predictions and calculate F1 scores for both mic and phenotype\n",
    "    y_pred = multioutput_model.predict(X_test)\n",
    "    f1_mic = f1_score(y_test[:, 0], y_pred[:, 0], average='weighted')  # F1 score for mic\n",
    "    f1_phenotype = f1_score(y_test[:, 1], y_pred[:, 1], average='weighted')  # F1 score for phenotype\n",
    "\n",
    "    f1_scores = {\n",
    "        'mic': f1_mic,\n",
    "        'phenotype': f1_phenotype\n",
    "    }\n",
    "\n",
    "    return multioutput_model, f1_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d224b88-4c5a-469b-925d-6f2f2f7f8b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores: {'mic': 0.7101268174047273, 'phenotype': 0.9396797964022365}\n"
     ]
    }
   ],
   "source": [
    "multioutput_model, f1_scores = train_classifiers_with_multioutput(df)\n",
    "print(f'F1 scores: {f1_scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1caa461f-9f0e-4a34-8511-7ef271879fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antibiotic</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>mic</th>\n",
       "      <th>3005053</th>\n",
       "      <th>3000830</th>\n",
       "      <th>3003838</th>\n",
       "      <th>3000508</th>\n",
       "      <th>3003890</th>\n",
       "      <th>...</th>\n",
       "      <th>3007751-D87Y</th>\n",
       "      <th>3003926-D87Y</th>\n",
       "      <th>3003709-G46S</th>\n",
       "      <th>3004851-A39T</th>\n",
       "      <th>3004832-A501P</th>\n",
       "      <th>3003381-R20H</th>\n",
       "      <th>3003926-S83I</th>\n",
       "      <th>3003381-G121D</th>\n",
       "      <th>3004832-T483S</th>\n",
       "      <th>3004832-A311V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6704</th>\n",
       "      <td>1</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>1</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6706</th>\n",
       "      <td>1</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6707</th>\n",
       "      <td>1</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6708</th>\n",
       "      <td>1</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5952 rows × 880 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      antibiotic          genus    species  phenotype    mic  3005053  \\\n",
       "0              0  Acinetobacter  baumannii          1  8.000      0.0   \n",
       "1              0  Acinetobacter  baumannii          1  8.000      0.0   \n",
       "2              0  Acinetobacter  baumannii          1  8.000      0.0   \n",
       "3              0  Acinetobacter  baumannii          1  8.000      0.0   \n",
       "4              0  Acinetobacter  baumannii          1  8.000      0.0   \n",
       "...          ...            ...        ...        ...    ...      ...   \n",
       "6704           1     Salmonella   enterica          0  0.015      1.0   \n",
       "6705           1     Salmonella   enterica          0  0.015      1.0   \n",
       "6706           1     Salmonella   enterica          0  0.015      1.0   \n",
       "6707           1     Salmonella   enterica          0  0.015      1.0   \n",
       "6708           1     Salmonella   enterica          0  0.030      1.0   \n",
       "\n",
       "      3000830  3003838  3000508  3003890  ...  3007751-D87Y  3003926-D87Y  \\\n",
       "0         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "1         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "2         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "3         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "4         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "...       ...      ...      ...      ...  ...           ...           ...   \n",
       "6704      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6705      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6706      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6707      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6708      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "\n",
       "      3003709-G46S  3004851-A39T  3004832-A501P  3003381-R20H  3003926-S83I  \\\n",
       "0              0.0           0.0            0.0           0.0           0.0   \n",
       "1              0.0           0.0            0.0           0.0           0.0   \n",
       "2              0.0           0.0            0.0           0.0           0.0   \n",
       "3              0.0           0.0            0.0           0.0           0.0   \n",
       "4              0.0           0.0            0.0           0.0           0.0   \n",
       "...            ...           ...            ...           ...           ...   \n",
       "6704           0.0           0.0            0.0           0.0           0.0   \n",
       "6705           0.0           0.0            0.0           0.0           0.0   \n",
       "6706           0.0           0.0            0.0           0.0           0.0   \n",
       "6707           0.0           0.0            0.0           0.0           0.0   \n",
       "6708           0.0           0.0            0.0           0.0           0.0   \n",
       "\n",
       "      3003381-G121D  3004832-T483S  3004832-A311V  \n",
       "0               0.0            0.0            0.0  \n",
       "1               0.0            0.0            0.0  \n",
       "2               0.0            0.0            0.0  \n",
       "3               0.0            0.0            0.0  \n",
       "4               0.0            0.0            0.0  \n",
       "...             ...            ...            ...  \n",
       "6704            0.0            0.0            0.0  \n",
       "6705            0.0            0.0            0.0  \n",
       "6706            0.0            0.0            0.0  \n",
       "6707            0.0            0.0            0.0  \n",
       "6708            0.0            0.0            0.0  \n",
       "\n",
       "[5952 rows x 880 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c16dd545-7c83-4485-9e3b-944631289077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest_multioutput(df):\n",
    "    \"\"\"\n",
    "    Function to train a random forest classifier for multi-output prediction of 'mic' and 'phenotype' columns.\n",
    "    \n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels ('mic' and 'phenotype').\n",
    "        \n",
    "    Returns:\n",
    "        model: Trained MultiOutput RandomForestClassifier model.\n",
    "        f1_scores: F1 scores for both 'mic' and 'phenotype' on test data.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # 2. Separate features and labels\n",
    "    X = df.drop(columns=['mic', 'phenotype', 'antibiotic'])  \n",
    "    y_mic = df['mic']  \n",
    "    y_phenotype = df['phenotype']\n",
    "\n",
    "    # 3. Encode 'mic' using LabelEncoder \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_mic_encoded = label_encoder.fit_transform(y_mic)\n",
    "\n",
    "    # 4. Detect binary and multiclass features in X\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 5. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols), \n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  \n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # 6. Create a RandomForest pipeline for multi-output classification\n",
    "    rf_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', MultiOutputClassifier(RandomForestClassifier(random_state=42)))\n",
    "    ])\n",
    "\n",
    "    # 7. Combine both mic and phenotype into a single target array\n",
    "    y_combined = np.column_stack([y_mic_encoded, y_phenotype])\n",
    "\n",
    "    # 8. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 9. Train the multi-output model\n",
    "    rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # 10. Make predictions and calculate the F1 scores for both mic and phenotype\n",
    "    y_pred = rf_pipeline.predict(X_test)\n",
    "    f1_mic = f1_score(y_test[:, 0], y_pred[:, 0], average='weighted')  # F1 score for mic\n",
    "    f1_phenotype = f1_score(y_test[:, 1], y_pred[:, 1], average='weighted')  # F1 score for phenotype\n",
    "\n",
    "    f1_scores = {\n",
    "        'mic': f1_mic,\n",
    "        'phenotype': f1_phenotype\n",
    "    }\n",
    "\n",
    "    return rf_pipeline, f1_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7321dd7-269c-4cbe-bddf-552bc830fac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores: {'mic': 0.7135263475674756, 'phenotype': 0.9338607851184337}\n"
     ]
    }
   ],
   "source": [
    "rf_model, f1_scores = train_random_forest_multioutput(df)\n",
    "print(f'F1 scores: {f1_scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a7677a-4bb7-40a0-bd34-19c0a4a90297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf38be5-41c7-45e8-8520-a4d7377975d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f34fbf2-f4cd-412e-a42e-6ec4ac185a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e450d78-fd25-4388-8a93-3d3f6464ff35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umap",
   "language": "python",
   "name": "umap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
