{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a67742-9e2c-4dec-843b-d1738fbfff61",
   "metadata": {},
   "source": [
    "# Random Forest (Reproducible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6840f1f2-d9d0-4ec9-8c77-3d8a8bdb961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7447a125-d90f-4f11-8cd9-46041666050e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3647110/104550336.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(filepath, sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "filepath = '/home/jupyter-user5/Camda24_resistance/DataSets/group-2/data/combined_antibiotic_resistance.tsv'\n",
    "df1 = pd.read_csv(filepath, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7d888a-b924-4d6c-a692-0b32211e88f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antibiotic</th>\n",
       "      <th>accession</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>mic</th>\n",
       "      <th>3005053</th>\n",
       "      <th>3000830</th>\n",
       "      <th>3003838</th>\n",
       "      <th>3000508</th>\n",
       "      <th>...</th>\n",
       "      <th>3007751-D87Y</th>\n",
       "      <th>3003926-D87Y</th>\n",
       "      <th>3003709-G46S</th>\n",
       "      <th>3004851-A39T</th>\n",
       "      <th>3004832-A501P</th>\n",
       "      <th>3003381-R20H</th>\n",
       "      <th>3003926-S83I</th>\n",
       "      <th>3003381-G121D</th>\n",
       "      <th>3004832-T483S</th>\n",
       "      <th>3004832-A311V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_002947415</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_002947845</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_002948925</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_002996805</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_003006035</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 881 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  antibiotic      accession          genus    species  phenotype  mic  \\\n",
       "0  meropenem  GCA_002947415  Acinetobacter  baumannii  Resistant  8.0   \n",
       "1  meropenem  GCA_002947845  Acinetobacter  baumannii  Resistant  8.0   \n",
       "2  meropenem  GCA_002948925  Acinetobacter  baumannii  Resistant  8.0   \n",
       "3  meropenem  GCA_002996805  Acinetobacter  baumannii  Resistant  8.0   \n",
       "4  meropenem  GCA_003006035  Acinetobacter  baumannii  Resistant  8.0   \n",
       "\n",
       "   3005053  3000830  3003838  3000508  ...  3007751-D87Y  3003926-D87Y  \\\n",
       "0      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "1      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "2      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "3      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "4      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "\n",
       "   3003709-G46S  3004851-A39T  3004832-A501P  3003381-R20H  3003926-S83I  \\\n",
       "0           0.0           0.0            0.0           0.0           0.0   \n",
       "1           0.0           0.0            0.0           0.0           0.0   \n",
       "2           0.0           0.0            0.0           0.0           0.0   \n",
       "3           0.0           0.0            0.0           0.0           0.0   \n",
       "4           0.0           0.0            0.0           0.0           0.0   \n",
       "\n",
       "   3003381-G121D  3004832-T483S  3004832-A311V  \n",
       "0            0.0            0.0            0.0  \n",
       "1            0.0            0.0            0.0  \n",
       "2            0.0            0.0            0.0  \n",
       "3            0.0            0.0            0.0  \n",
       "4            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 881 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1.dropna()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffacfbb-6527-4896-b483-3646e9eab2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeabe508-c873-4581-a01c-732c5247a7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8814554c-0b19-448d-912d-9d4aeb1d546a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5952, 881)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "281b54ae-fb31-4548-a9af-713217a401fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antibiotic</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>mic</th>\n",
       "      <th>3005053</th>\n",
       "      <th>3000830</th>\n",
       "      <th>3003838</th>\n",
       "      <th>3000508</th>\n",
       "      <th>3003890</th>\n",
       "      <th>...</th>\n",
       "      <th>3007751-D87Y</th>\n",
       "      <th>3003926-D87Y</th>\n",
       "      <th>3003709-G46S</th>\n",
       "      <th>3004851-A39T</th>\n",
       "      <th>3004832-A501P</th>\n",
       "      <th>3003381-R20H</th>\n",
       "      <th>3003926-S83I</th>\n",
       "      <th>3003381-G121D</th>\n",
       "      <th>3004832-T483S</th>\n",
       "      <th>3004832-A311V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 880 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  antibiotic          genus    species  phenotype  mic  3005053  3000830  \\\n",
       "0  meropenem  Acinetobacter  baumannii  Resistant  8.0      0.0      0.0   \n",
       "1  meropenem  Acinetobacter  baumannii  Resistant  8.0      0.0      0.0   \n",
       "2  meropenem  Acinetobacter  baumannii  Resistant  8.0      0.0      0.0   \n",
       "3  meropenem  Acinetobacter  baumannii  Resistant  8.0      0.0      0.0   \n",
       "4  meropenem  Acinetobacter  baumannii  Resistant  8.0      0.0      0.0   \n",
       "\n",
       "   3003838  3000508  3003890  ...  3007751-D87Y  3003926-D87Y  3003709-G46S  \\\n",
       "0      0.0      0.0      0.0  ...           0.0           0.0           0.0   \n",
       "1      0.0      0.0      0.0  ...           0.0           0.0           0.0   \n",
       "2      0.0      0.0      0.0  ...           0.0           0.0           0.0   \n",
       "3      0.0      0.0      0.0  ...           0.0           0.0           0.0   \n",
       "4      0.0      0.0      0.0  ...           0.0           0.0           0.0   \n",
       "\n",
       "   3004851-A39T  3004832-A501P  3003381-R20H  3003926-S83I  3003381-G121D  \\\n",
       "0           0.0            0.0           0.0           0.0            0.0   \n",
       "1           0.0            0.0           0.0           0.0            0.0   \n",
       "2           0.0            0.0           0.0           0.0            0.0   \n",
       "3           0.0            0.0           0.0           0.0            0.0   \n",
       "4           0.0            0.0           0.0           0.0            0.0   \n",
       "\n",
       "   3004832-T483S  3004832-A311V  \n",
       "0            0.0            0.0  \n",
       "1            0.0            0.0  \n",
       "2            0.0            0.0  \n",
       "3            0.0            0.0  \n",
       "4            0.0            0.0  \n",
       "\n",
       "[5 rows x 880 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1.drop('accession', axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cee850b6-8a29-40c4-ac25-43a72b68ff47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5952, 880)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4459b7-7425-4ef4-a4f2-842e6a56c160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f4ba2a-8a60-4e0e-87c6-18ad70f03f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f27800-3a84-445d-9580-2a4568a5b52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e9a510-9ef5-4004-8cde-93b68684ad28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e66fce5c-a6fa-4629-b584-2694b1097373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(df):\n",
    "    \"\"\"\n",
    "    Function to train a random forest classifier on the 'mic' column of the dataframe.\n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        model: Trained RandomForestClassifier model.\n",
    "        f1: F1 score of the model on test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic',\"antibiotic\"])  # Drop label columns\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Encode 'mic' (target) using LabelEncoder (since it's multiclass)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Detect binary and multiclass features\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    # Binary columns don't need much processing, multiclass columns need one-hot encoding\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns Con handle_unknown='ignore', el codificador ignorarÃ¡ las categorÃ­as desconocidas y no producirÃ¡ un error durante la predicciÃ³n.\n",
    "        ], remainder='passthrough')  # Any remaining columns are passed through (if any)\n",
    "\n",
    "    # 5. Create a pipeline that first applies preprocessing, then trains a random forest\n",
    "    model_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "\n",
    "    # 6. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 7. Train the model\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # 8. Make predictions and calculate the F1 score\n",
    "    y_pred = model_pipeline.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')  # Use 'weighted' for multiclass F1\n",
    "\n",
    "    return model_pipeline, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dfbe903-b776-42cb-bc47-2ebc4137309e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model: Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['3000830', '3000206',\n",
      "                                                   '3006880', '3000676',\n",
      "                                                   '3003576', '3001216',\n",
      "                                                   '3000237', '3003548',\n",
      "                                                   '3001889', '3003652',\n",
      "                                                   '3003899', '3006228',\n",
      "                                                   '3003900', '3006881',\n",
      "                                                   '3001866', '3003479',\n",
      "                                                   '3000166', '3002540',\n",
      "                                                   '3006878', '3006874',\n",
      "                                                   '3000168', '3004290',\n",
      "                                                   '3006875', '30070...\n",
      "                                                  ['genus', 'species',\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier', RandomForestClassifier(random_state=42))])\n",
      "F1 score: 0.7135263475674756\n"
     ]
    }
   ],
   "source": [
    "model, f1 = train_random_forest(df1)\n",
    "print(f'Trained model: {model}')\n",
    "print(f'F1 score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8118dae4-8443-4353-8e87-b9a4f5da4c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13215c4e-802a-442b-a5ae-9ff7117b6269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94520033-9a50-480c-8008-d608576f639e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd7b17c-4713-455e-abfc-e81cfb800f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "887bde1f-3a0b-446f-905b-a8a35d872056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models: {'RandomForest': Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['3000830', '3000206',\n",
      "                                                   '3006880', '3000676',\n",
      "                                                   '3003576', '3001216',\n",
      "                                                   '3000237', '3003548',\n",
      "                                                   '3001889', '3003652',\n",
      "                                                   '3003899', '3006228',\n",
      "                                                   '3003900', '3006881',\n",
      "                                                   '3001866', '3003479',\n",
      "                                                   '3000166', '3002540',\n",
      "                                                   '3006878', '3006874',\n",
      "                                                   '3000168', '3004290',\n",
      "                                                   '3006875', '30070...\n",
      "                                                  ['genus', 'species',\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier', RandomForestClassifier(random_state=42))]), 'SVM': Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['3000830', '3000206',\n",
      "                                                   '3006880', '3000676',\n",
      "                                                   '3003576', '3001216',\n",
      "                                                   '3000237', '3003548',\n",
      "                                                   '3001889', '3003652',\n",
      "                                                   '3003899', '3006228',\n",
      "                                                   '3003900', '3006881',\n",
      "                                                   '3001866', '3003479',\n",
      "                                                   '3000166', '3002540',\n",
      "                                                   '3006878', '3006874',\n",
      "                                                   '3000168', '3004290',\n",
      "                                                   '3006875', '30070...\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['genus', 'species',\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier', SVC(random_state=42))]), 'KNN': Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['3000830', '3000206',\n",
      "                                                   '3006880', '3000676',\n",
      "                                                   '3003576', '3001216',\n",
      "                                                   '3000237', '3003548',\n",
      "                                                   '3001889', '3003652',\n",
      "                                                   '3003899', '3006228',\n",
      "                                                   '3003900', '3006881',\n",
      "                                                   '3001866', '3003479',\n",
      "                                                   '3000166', '3002540',\n",
      "                                                   '3006878', '3006874',\n",
      "                                                   '3000168', '3004290',\n",
      "                                                   '3006875', '30070...\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['genus', 'species',\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier', KNeighborsClassifier())])}\n",
      "F1 scores: {'RandomForest': 0.7135263475674756, 'SVM': 0.6034210105056049, 'KNN': 0.6694039285905631}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def train_classifiers(df):\n",
    "    \"\"\"\n",
    "    Function to train RandomForest, SVM, and KNN classifiers on the 'mic' column of the dataframe.\n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        models: Dictionary containing trained models for each classifier.\n",
    "        f1_scores: Dictionary containing F1 scores for each classifier on test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic', \"antibiotic\"])  # Drop label columns\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Encode 'mic' (target) using LabelEncoder (since it's multiclass)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Detect binary and multiclass features\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    # Binary columns don't need much processing, multiclass columns need one-hot encoding\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough')  # Any remaining columns are passed through (if any)\n",
    "\n",
    "    # 5. Create pipelines for different classifiers\n",
    "    rf_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    svm_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', SVC(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    knn_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    # 6. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 7. Train models and calculate F1 scores\n",
    "    models = {}\n",
    "    f1_scores = {}\n",
    "\n",
    "    # Random Forest\n",
    "    rf_pipeline.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_pipeline.predict(X_test)\n",
    "    f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "    models['RandomForest'] = rf_pipeline\n",
    "    f1_scores['RandomForest'] = f1_rf\n",
    "\n",
    "    # SVM\n",
    "    svm_pipeline.fit(X_train, y_train)\n",
    "    y_pred_svm = svm_pipeline.predict(X_test)\n",
    "    f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "    models['SVM'] = svm_pipeline\n",
    "    f1_scores['SVM'] = f1_svm\n",
    "\n",
    "    # KNN\n",
    "    knn_pipeline.fit(X_train, y_train)\n",
    "    y_pred_knn = knn_pipeline.predict(X_test)\n",
    "    f1_knn = f1_score(y_test, y_pred_knn, average='weighted')\n",
    "    models['KNN'] = knn_pipeline\n",
    "    f1_scores['KNN'] = f1_knn\n",
    "\n",
    "    return models, f1_scores\n",
    "\n",
    "# Entrenar los modelos\n",
    "models, f1_scores = train_classifiers(df1)\n",
    "print(f'Trained models: {models}')\n",
    "print(f'F1 scores: {f1_scores}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b90dc20-8f17-4c7b-848b-034e107bb5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 81 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n27 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/pipeline.py\", line 476, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 363, in fit\n    X, y = self._validate_data(\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1273, in check_X_y\n    X = check_array(\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1007, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/_array_api.py\", line 746, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'meropenem'\n\n--------------------------------------------------------------------------------\n54 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/pipeline.py\", line 476, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 363, in fit\n    X, y = self._validate_data(\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1273, in check_X_y\n    X = check_array(\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1007, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/_array_api.py\", line 746, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'ciprofloxacin'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 110\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_models, f1_scores\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# Entrenar los modelos con ajuste de hiperparÃ¡metros\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m best_models, f1_scores \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_classifiers_with_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest models: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_models\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1 scores: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_scores\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 87\u001b[0m, in \u001b[0;36mtrain_classifiers_with_tuning\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     84\u001b[0m f1_scores \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Random Forest\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m \u001b[43mrf_grid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m y_pred_rf \u001b[38;5;241m=\u001b[39m rf_grid\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     89\u001b[0m f1_rf \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_pred_rf, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_search.py:968\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    962\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    963\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    964\u001b[0m     )\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 968\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    972\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1543\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1542\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1543\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_search.py:945\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    940\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    941\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    943\u001b[0m     )\n\u001b[0;32m--> 945\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 81 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n27 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/pipeline.py\", line 476, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 363, in fit\n    X, y = self._validate_data(\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1273, in check_X_y\n    X = check_array(\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1007, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/_array_api.py\", line 746, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'meropenem'\n\n--------------------------------------------------------------------------------\n54 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/pipeline.py\", line 476, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 363, in fit\n    X, y = self._validate_data(\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1273, in check_X_y\n    X = check_array(\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1007, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/utils/_array_api.py\", line 746, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'ciprofloxacin'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def train_classifiers_with_tuning(df):\n",
    "    \"\"\"\n",
    "    Function to train RandomForest, SVM, and KNN classifiers with hyperparameter tuning on the 'mic' column.\n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        best_models: Dictionary containing the best tuned models for each classifier.\n",
    "        f1_scores: Dictionary containing F1 scores for each best-tuned classifier on test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic'])  # Drop label columns \"antibiotic\"\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Encode 'mic' (target) using LabelEncoder (since it's multiclass)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Detect binary and multiclass features\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # 5. Define parameter grids for hyperparameter tuning\n",
    "    param_grid_rf = {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "\n",
    "    param_grid_svm = {\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__kernel': ['linear', 'rbf'],\n",
    "        'classifier__gamma': ['scale', 'auto']\n",
    "    }\n",
    "\n",
    "    param_grid_knn = {\n",
    "        'classifier__n_neighbors': [3, 5, 7],\n",
    "        'classifier__weights': ['uniform', 'distance']\n",
    "    }\n",
    "\n",
    "    # 6. Create pipelines for different classifiers\n",
    "    rf_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    svm_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', SVC(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    knn_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    # 7. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 8. Hyperparameter tuning with GridSearchCV\n",
    "    rf_grid = GridSearchCV(rf_pipeline, param_grid_rf, cv=3, scoring='f1_weighted')\n",
    "    svm_grid = GridSearchCV(svm_pipeline, param_grid_svm, cv=3, scoring='f1_weighted')\n",
    "    knn_grid = GridSearchCV(knn_pipeline, param_grid_knn, cv=3, scoring='f1_weighted')\n",
    "\n",
    "    # 9. Train models with best parameters and calculate F1 scores\n",
    "    best_models = {}\n",
    "    f1_scores = {}\n",
    "\n",
    "    # Random Forest\n",
    "    rf_grid.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_grid.predict(X_test)\n",
    "    f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "    best_models['RandomForest'] = rf_grid.best_estimator_\n",
    "    f1_scores['RandomForest'] = f1_rf\n",
    "\n",
    "    # SVM\n",
    "    svm_grid.fit(X_train, y_train)\n",
    "    y_pred_svm = svm_grid.predict(X_test)\n",
    "    f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "    best_models['SVM'] = svm_grid.best_estimator_\n",
    "    f1_scores['SVM'] = f1_svm\n",
    "\n",
    "    # KNN\n",
    "    knn_grid.fit(X_train, y_train)\n",
    "    y_pred_knn = knn_grid.predict(X_test)\n",
    "    f1_knn = f1_score(y_test, y_pred_knn, average='weighted')\n",
    "    best_models['KNN'] = knn_grid.best_estimator_\n",
    "    f1_scores['KNN'] = f1_knn\n",
    "\n",
    "    return best_models, f1_scores\n",
    "\n",
    "# Entrenar los modelos con ajuste de hiperparÃ¡metros\n",
    "best_models, f1_scores = train_classifiers_with_tuning(df1)\n",
    "print(f'Best models: {best_models}')\n",
    "print(f'F1 scores: {f1_scores}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf5ea3cd-db8f-4b4a-a658-b95173c4630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ParÃ¡metros para RandomForestClassifier: Ajusta el nÃºmero de Ã¡rboles, la profundidad mÃ¡xima y el nÃºmero mÃ­nimo de muestras para dividir un nodo.\n",
    "# ParÃ¡metros para SVC: Ajusta el parÃ¡metro de regularizaciÃ³n C, el kernel y el parÃ¡metro gamma.\n",
    "# ParÃ¡metros para KNeighborsClassifier: Ajusta el nÃºmero de vecinos y el tipo de ponderaciÃ³n para los vecinos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b8846d-1b97-4b7d-8365-6dc609b32df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umap",
   "language": "python",
   "name": "umap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
