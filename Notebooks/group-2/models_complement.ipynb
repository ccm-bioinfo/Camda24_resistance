{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a67742-9e2c-4dec-843b-d1738fbfff61",
   "metadata": {},
   "source": [
    "# Random Forest (Reproducible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6840f1f2-d9d0-4ec9-8c77-3d8a8bdb961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7447a125-d90f-4f11-8cd9-46041666050e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4128509/3163463394.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "filepath = '/home/jupyter-user5/Camda24_resistance/DataSets/group-2/data/combined_antibiotic_resistance.tsv'\n",
    "df = pd.read_csv(filepath, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd7d888a-b924-4d6c-a692-0b32211e88f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antibiotic</th>\n",
       "      <th>accession</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>mic</th>\n",
       "      <th>3005053</th>\n",
       "      <th>3000830</th>\n",
       "      <th>3003838</th>\n",
       "      <th>3000508</th>\n",
       "      <th>...</th>\n",
       "      <th>3007751-D87Y</th>\n",
       "      <th>3003926-D87Y</th>\n",
       "      <th>3003709-G46S</th>\n",
       "      <th>3004851-A39T</th>\n",
       "      <th>3004832-A501P</th>\n",
       "      <th>3003381-R20H</th>\n",
       "      <th>3003926-S83I</th>\n",
       "      <th>3003381-G121D</th>\n",
       "      <th>3004832-T483S</th>\n",
       "      <th>3004832-A311V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_002947415</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_002947845</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_002948925</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_002996805</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>GCA_003006035</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 881 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  antibiotic      accession          genus    species  phenotype  mic  \\\n",
       "0  meropenem  GCA_002947415  Acinetobacter  baumannii  Resistant  8.0   \n",
       "1  meropenem  GCA_002947845  Acinetobacter  baumannii  Resistant  8.0   \n",
       "2  meropenem  GCA_002948925  Acinetobacter  baumannii  Resistant  8.0   \n",
       "3  meropenem  GCA_002996805  Acinetobacter  baumannii  Resistant  8.0   \n",
       "4  meropenem  GCA_003006035  Acinetobacter  baumannii  Resistant  8.0   \n",
       "\n",
       "   3005053  3000830  3003838  3000508  ...  3007751-D87Y  3003926-D87Y  \\\n",
       "0      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "1      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "2      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "3      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "4      0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "\n",
       "   3003709-G46S  3004851-A39T  3004832-A501P  3003381-R20H  3003926-S83I  \\\n",
       "0           0.0           0.0            0.0           0.0           0.0   \n",
       "1           0.0           0.0            0.0           0.0           0.0   \n",
       "2           0.0           0.0            0.0           0.0           0.0   \n",
       "3           0.0           0.0            0.0           0.0           0.0   \n",
       "4           0.0           0.0            0.0           0.0           0.0   \n",
       "\n",
       "   3003381-G121D  3004832-T483S  3004832-A311V  \n",
       "0            0.0            0.0            0.0  \n",
       "1            0.0            0.0            0.0  \n",
       "2            0.0            0.0            0.0  \n",
       "3            0.0            0.0            0.0  \n",
       "4            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 881 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeabe508-c873-4581-a01c-732c5247a7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8814554c-0b19-448d-912d-9d4aeb1d546a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5952, 881)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "281b54ae-fb31-4548-a9af-713217a401fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antibiotic</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>mic</th>\n",
       "      <th>3005053</th>\n",
       "      <th>3000830</th>\n",
       "      <th>3003838</th>\n",
       "      <th>3000508</th>\n",
       "      <th>3003890</th>\n",
       "      <th>...</th>\n",
       "      <th>3007751-D87Y</th>\n",
       "      <th>3003926-D87Y</th>\n",
       "      <th>3003709-G46S</th>\n",
       "      <th>3004851-A39T</th>\n",
       "      <th>3004832-A501P</th>\n",
       "      <th>3003381-R20H</th>\n",
       "      <th>3003926-S83I</th>\n",
       "      <th>3003381-G121D</th>\n",
       "      <th>3004832-T483S</th>\n",
       "      <th>3004832-A311V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 880 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  antibiotic          genus    species  phenotype  mic  3005053  3000830  \\\n",
       "0  meropenem  Acinetobacter  baumannii  Resistant  8.0      0.0      0.0   \n",
       "1  meropenem  Acinetobacter  baumannii  Resistant  8.0      0.0      0.0   \n",
       "2  meropenem  Acinetobacter  baumannii  Resistant  8.0      0.0      0.0   \n",
       "3  meropenem  Acinetobacter  baumannii  Resistant  8.0      0.0      0.0   \n",
       "4  meropenem  Acinetobacter  baumannii  Resistant  8.0      0.0      0.0   \n",
       "\n",
       "   3003838  3000508  3003890  ...  3007751-D87Y  3003926-D87Y  3003709-G46S  \\\n",
       "0      0.0      0.0      0.0  ...           0.0           0.0           0.0   \n",
       "1      0.0      0.0      0.0  ...           0.0           0.0           0.0   \n",
       "2      0.0      0.0      0.0  ...           0.0           0.0           0.0   \n",
       "3      0.0      0.0      0.0  ...           0.0           0.0           0.0   \n",
       "4      0.0      0.0      0.0  ...           0.0           0.0           0.0   \n",
       "\n",
       "   3004851-A39T  3004832-A501P  3003381-R20H  3003926-S83I  3003381-G121D  \\\n",
       "0           0.0            0.0           0.0           0.0            0.0   \n",
       "1           0.0            0.0           0.0           0.0            0.0   \n",
       "2           0.0            0.0           0.0           0.0            0.0   \n",
       "3           0.0            0.0           0.0           0.0            0.0   \n",
       "4           0.0            0.0           0.0           0.0            0.0   \n",
       "\n",
       "   3004832-T483S  3004832-A311V  \n",
       "0            0.0            0.0  \n",
       "1            0.0            0.0  \n",
       "2            0.0            0.0  \n",
       "3            0.0            0.0  \n",
       "4            0.0            0.0  \n",
       "\n",
       "[5 rows x 880 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('accession', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cee850b6-8a29-40c4-ac25-43a72b68ff47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5952, 880)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7138133a-d726-49b0-9393-a5641db21680",
   "metadata": {},
   "outputs": [],
   "source": [
    "  df['antibiotic'] = df['antibiotic'].map({'meropenem': 0, 'ciprofloxacin': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "838cf523-181b-4d5c-87fd-a6b4766ad9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antibiotic</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>mic</th>\n",
       "      <th>3005053</th>\n",
       "      <th>3000830</th>\n",
       "      <th>3003838</th>\n",
       "      <th>3000508</th>\n",
       "      <th>3003890</th>\n",
       "      <th>...</th>\n",
       "      <th>3007751-D87Y</th>\n",
       "      <th>3003926-D87Y</th>\n",
       "      <th>3003709-G46S</th>\n",
       "      <th>3004851-A39T</th>\n",
       "      <th>3004832-A501P</th>\n",
       "      <th>3003381-R20H</th>\n",
       "      <th>3003926-S83I</th>\n",
       "      <th>3003381-G121D</th>\n",
       "      <th>3004832-T483S</th>\n",
       "      <th>3004832-A311V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6704</th>\n",
       "      <td>1</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>1</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6706</th>\n",
       "      <td>1</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6707</th>\n",
       "      <td>1</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6708</th>\n",
       "      <td>1</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5952 rows Ã— 880 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      antibiotic          genus    species    phenotype    mic  3005053  \\\n",
       "0              0  Acinetobacter  baumannii    Resistant  8.000      0.0   \n",
       "1              0  Acinetobacter  baumannii    Resistant  8.000      0.0   \n",
       "2              0  Acinetobacter  baumannii    Resistant  8.000      0.0   \n",
       "3              0  Acinetobacter  baumannii    Resistant  8.000      0.0   \n",
       "4              0  Acinetobacter  baumannii    Resistant  8.000      0.0   \n",
       "...          ...            ...        ...          ...    ...      ...   \n",
       "6704           1     Salmonella   enterica  Susceptible  0.015      1.0   \n",
       "6705           1     Salmonella   enterica  Susceptible  0.015      1.0   \n",
       "6706           1     Salmonella   enterica  Susceptible  0.015      1.0   \n",
       "6707           1     Salmonella   enterica  Susceptible  0.015      1.0   \n",
       "6708           1     Salmonella   enterica  Susceptible  0.030      1.0   \n",
       "\n",
       "      3000830  3003838  3000508  3003890  ...  3007751-D87Y  3003926-D87Y  \\\n",
       "0         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "1         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "2         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "3         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "4         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "...       ...      ...      ...      ...  ...           ...           ...   \n",
       "6704      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6705      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6706      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6707      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6708      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "\n",
       "      3003709-G46S  3004851-A39T  3004832-A501P  3003381-R20H  3003926-S83I  \\\n",
       "0              0.0           0.0            0.0           0.0           0.0   \n",
       "1              0.0           0.0            0.0           0.0           0.0   \n",
       "2              0.0           0.0            0.0           0.0           0.0   \n",
       "3              0.0           0.0            0.0           0.0           0.0   \n",
       "4              0.0           0.0            0.0           0.0           0.0   \n",
       "...            ...           ...            ...           ...           ...   \n",
       "6704           0.0           0.0            0.0           0.0           0.0   \n",
       "6705           0.0           0.0            0.0           0.0           0.0   \n",
       "6706           0.0           0.0            0.0           0.0           0.0   \n",
       "6707           0.0           0.0            0.0           0.0           0.0   \n",
       "6708           0.0           0.0            0.0           0.0           0.0   \n",
       "\n",
       "      3003381-G121D  3004832-T483S  3004832-A311V  \n",
       "0               0.0            0.0            0.0  \n",
       "1               0.0            0.0            0.0  \n",
       "2               0.0            0.0            0.0  \n",
       "3               0.0            0.0            0.0  \n",
       "4               0.0            0.0            0.0  \n",
       "...             ...            ...            ...  \n",
       "6704            0.0            0.0            0.0  \n",
       "6705            0.0            0.0            0.0  \n",
       "6706            0.0            0.0            0.0  \n",
       "6707            0.0            0.0            0.0  \n",
       "6708            0.0            0.0            0.0  \n",
       "\n",
       "[5952 rows x 880 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e66fce5c-a6fa-4629-b584-2694b1097373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(df):\n",
    "    \"\"\"\n",
    "    Function to train a random forest classifier on the 'mic' column of the dataframe.\n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        model: Trained RandomForestClassifier model.\n",
    "        f1: F1 score of the model on test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic',\"antibiotic\"])  # Drop label columns\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Encode 'mic' (target) using LabelEncoder (since it's multiclass)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Detect binary and multiclass features\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    # Binary columns don't need much processing, multiclass columns need one-hot encoding\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns Con handle_unknown='ignore', el codificador ignorarÃ¡ las categorÃ­as desconocidas y no producirÃ¡ un error durante la predicciÃ³n.\n",
    "        ], remainder='passthrough')  # Any remaining columns are passed through (if any)\n",
    "\n",
    "    # 5. Create a pipeline that first applies preprocessing, then trains a random forest\n",
    "    model_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "\n",
    "    # 6. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 7. Train the model\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # 8. Make predictions and calculate the F1 score\n",
    "    y_pred = model_pipeline.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')  # Use 'weighted' for multiclass F1\n",
    "\n",
    "    return model_pipeline, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dfbe903-b776-42cb-bc47-2ebc4137309e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model: Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['3000830', '3000206',\n",
      "                                                   '3006880', '3000676',\n",
      "                                                   '3003576', '3001216',\n",
      "                                                   '3000237', '3003548',\n",
      "                                                   '3001889', '3003652',\n",
      "                                                   '3003899', '3006228',\n",
      "                                                   '3003900', '3006881',\n",
      "                                                   '3001866', '3003479',\n",
      "                                                   '3000166', '3002540',\n",
      "                                                   '3006878', '3006874',\n",
      "                                                   '3000168', '3004290',\n",
      "                                                   '3006875', '30070...\n",
      "                                                  ['genus', 'species',\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier', RandomForestClassifier(random_state=42))])\n",
      "F1 score: 0.7135263475674756\n"
     ]
    }
   ],
   "source": [
    "model, f1 = train_random_forest(df)\n",
    "print(f'Trained model: {model}')\n",
    "print(f'F1 score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cd7b17c-4713-455e-abfc-e81cfb800f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antibiotic</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>mic</th>\n",
       "      <th>3005053</th>\n",
       "      <th>3000830</th>\n",
       "      <th>3003838</th>\n",
       "      <th>3000508</th>\n",
       "      <th>3003890</th>\n",
       "      <th>...</th>\n",
       "      <th>3007751-D87Y</th>\n",
       "      <th>3003926-D87Y</th>\n",
       "      <th>3003709-G46S</th>\n",
       "      <th>3004851-A39T</th>\n",
       "      <th>3004832-A501P</th>\n",
       "      <th>3003381-R20H</th>\n",
       "      <th>3003926-S83I</th>\n",
       "      <th>3003381-G121D</th>\n",
       "      <th>3004832-T483S</th>\n",
       "      <th>3004832-A311V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meropenem</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6704</th>\n",
       "      <td>ciprofloxacin</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>ciprofloxacin</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6706</th>\n",
       "      <td>ciprofloxacin</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6707</th>\n",
       "      <td>ciprofloxacin</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6708</th>\n",
       "      <td>ciprofloxacin</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5952 rows Ã— 880 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         antibiotic          genus    species    phenotype    mic  3005053  \\\n",
       "0         meropenem  Acinetobacter  baumannii    Resistant  8.000      0.0   \n",
       "1         meropenem  Acinetobacter  baumannii    Resistant  8.000      0.0   \n",
       "2         meropenem  Acinetobacter  baumannii    Resistant  8.000      0.0   \n",
       "3         meropenem  Acinetobacter  baumannii    Resistant  8.000      0.0   \n",
       "4         meropenem  Acinetobacter  baumannii    Resistant  8.000      0.0   \n",
       "...             ...            ...        ...          ...    ...      ...   \n",
       "6704  ciprofloxacin     Salmonella   enterica  Susceptible  0.015      1.0   \n",
       "6705  ciprofloxacin     Salmonella   enterica  Susceptible  0.015      1.0   \n",
       "6706  ciprofloxacin     Salmonella   enterica  Susceptible  0.015      1.0   \n",
       "6707  ciprofloxacin     Salmonella   enterica  Susceptible  0.015      1.0   \n",
       "6708  ciprofloxacin     Salmonella   enterica  Susceptible  0.030      1.0   \n",
       "\n",
       "      3000830  3003838  3000508  3003890  ...  3007751-D87Y  3003926-D87Y  \\\n",
       "0         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "1         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "2         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "3         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "4         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "...       ...      ...      ...      ...  ...           ...           ...   \n",
       "6704      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6705      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6706      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6707      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6708      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "\n",
       "      3003709-G46S  3004851-A39T  3004832-A501P  3003381-R20H  3003926-S83I  \\\n",
       "0              0.0           0.0            0.0           0.0           0.0   \n",
       "1              0.0           0.0            0.0           0.0           0.0   \n",
       "2              0.0           0.0            0.0           0.0           0.0   \n",
       "3              0.0           0.0            0.0           0.0           0.0   \n",
       "4              0.0           0.0            0.0           0.0           0.0   \n",
       "...            ...           ...            ...           ...           ...   \n",
       "6704           0.0           0.0            0.0           0.0           0.0   \n",
       "6705           0.0           0.0            0.0           0.0           0.0   \n",
       "6706           0.0           0.0            0.0           0.0           0.0   \n",
       "6707           0.0           0.0            0.0           0.0           0.0   \n",
       "6708           0.0           0.0            0.0           0.0           0.0   \n",
       "\n",
       "      3003381-G121D  3004832-T483S  3004832-A311V  \n",
       "0               0.0            0.0            0.0  \n",
       "1               0.0            0.0            0.0  \n",
       "2               0.0            0.0            0.0  \n",
       "3               0.0            0.0            0.0  \n",
       "4               0.0            0.0            0.0  \n",
       "...             ...            ...            ...  \n",
       "6704            0.0            0.0            0.0  \n",
       "6705            0.0            0.0            0.0  \n",
       "6706            0.0            0.0            0.0  \n",
       "6707            0.0            0.0            0.0  \n",
       "6708            0.0            0.0            0.0  \n",
       "\n",
       "[5952 rows x 880 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "887bde1f-3a0b-446f-905b-a8a35d872056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def train_classifiers(df):\n",
    "    \"\"\"\n",
    "    Function to train RandomForest, SVM, and KNN classifiers on the 'mic' column of the dataframe.\n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        models: Dictionary containing trained models for each classifier.\n",
    "        f1_scores: Dictionary containing F1 scores for each classifier on test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic', \"antibiotic\"])  # Drop label columns\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Encode 'mic' (target) using LabelEncoder (since it's multiclass)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Detect binary and multiclass features\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    # Binary columns don't need much processing, multiclass columns need one-hot encoding\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough')  # Any remaining columns are passed through (if any)\n",
    "\n",
    "    # 5. Create pipelines for different classifiers\n",
    "    rf_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    svm_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', SVC(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    knn_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    # 6. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 7. Train models and calculate F1 scores\n",
    "    models = {}\n",
    "    f1_scores = {}\n",
    "\n",
    "    # Random Forest\n",
    "    rf_pipeline.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_pipeline.predict(X_test)\n",
    "    f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "    models['RandomForest'] = rf_pipeline\n",
    "    f1_scores['RandomForest'] = f1_rf\n",
    "\n",
    "    # SVM\n",
    "    svm_pipeline.fit(X_train, y_train)\n",
    "    y_pred_svm = svm_pipeline.predict(X_test)\n",
    "    f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "    models['SVM'] = svm_pipeline\n",
    "    f1_scores['SVM'] = f1_svm\n",
    "\n",
    "    # KNN\n",
    "    knn_pipeline.fit(X_train, y_train)\n",
    "    y_pred_knn = knn_pipeline.predict(X_test)\n",
    "    f1_knn = f1_score(y_test, y_pred_knn, average='weighted')\n",
    "    models['KNN'] = knn_pipeline\n",
    "    f1_scores['KNN'] = f1_knn\n",
    "\n",
    "    return models, f1_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c80aac11-f853-4a9b-8363-417a67cef158",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models: {'RandomForest': Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['3000830', '3000206',\n",
      "                                                   '3006880', '3000676',\n",
      "                                                   '3003576', '3001216',\n",
      "                                                   '3000237', '3003548',\n",
      "                                                   '3001889', '3003652',\n",
      "                                                   '3003899', '3006228',\n",
      "                                                   '3003900', '3006881',\n",
      "                                                   '3001866', '3003479',\n",
      "                                                   '3000166', '3002540',\n",
      "                                                   '3006878', '3006874',\n",
      "                                                   '3000168', '3004290',\n",
      "                                                   '3006875', '30070...\n",
      "                                                  ['genus', 'species',\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier', RandomForestClassifier(random_state=42))]), 'SVM': Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['3000830', '3000206',\n",
      "                                                   '3006880', '3000676',\n",
      "                                                   '3003576', '3001216',\n",
      "                                                   '3000237', '3003548',\n",
      "                                                   '3001889', '3003652',\n",
      "                                                   '3003899', '3006228',\n",
      "                                                   '3003900', '3006881',\n",
      "                                                   '3001866', '3003479',\n",
      "                                                   '3000166', '3002540',\n",
      "                                                   '3006878', '3006874',\n",
      "                                                   '3000168', '3004290',\n",
      "                                                   '3006875', '30070...\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['genus', 'species',\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier', SVC(random_state=42))]), 'KNN': Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['3000830', '3000206',\n",
      "                                                   '3006880', '3000676',\n",
      "                                                   '3003576', '3001216',\n",
      "                                                   '3000237', '3003548',\n",
      "                                                   '3001889', '3003652',\n",
      "                                                   '3003899', '3006228',\n",
      "                                                   '3003900', '3006881',\n",
      "                                                   '3001866', '3003479',\n",
      "                                                   '3000166', '3002540',\n",
      "                                                   '3006878', '3006874',\n",
      "                                                   '3000168', '3004290',\n",
      "                                                   '3006875', '30070...\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['genus', 'species',\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier', KNeighborsClassifier())])}\n",
      "F1 scores: {'RandomForest': 0.7135263475674756, 'SVM': 0.6034210105056049, 'KNN': 0.6694039285905631}\n"
     ]
    }
   ],
   "source": [
    "models, f1_scores = train_classifiers(df)\n",
    "print(f'Trained models: {models}')\n",
    "print(f'F1 scores: {f1_scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca2b64ab-f32c-4707-8f1d-6ada991904b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antibiotic</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>mic</th>\n",
       "      <th>3005053</th>\n",
       "      <th>3000830</th>\n",
       "      <th>3003838</th>\n",
       "      <th>3000508</th>\n",
       "      <th>3003890</th>\n",
       "      <th>...</th>\n",
       "      <th>3007751-D87Y</th>\n",
       "      <th>3003926-D87Y</th>\n",
       "      <th>3003709-G46S</th>\n",
       "      <th>3004851-A39T</th>\n",
       "      <th>3004832-A501P</th>\n",
       "      <th>3003381-R20H</th>\n",
       "      <th>3003926-S83I</th>\n",
       "      <th>3003381-G121D</th>\n",
       "      <th>3004832-T483S</th>\n",
       "      <th>3004832-A311V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>Resistant</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6704</th>\n",
       "      <td>1</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>1</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6706</th>\n",
       "      <td>1</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6707</th>\n",
       "      <td>1</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6708</th>\n",
       "      <td>1</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>Susceptible</td>\n",
       "      <td>0.030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5952 rows Ã— 880 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      antibiotic          genus    species    phenotype    mic  3005053  \\\n",
       "0              0  Acinetobacter  baumannii    Resistant  8.000      0.0   \n",
       "1              0  Acinetobacter  baumannii    Resistant  8.000      0.0   \n",
       "2              0  Acinetobacter  baumannii    Resistant  8.000      0.0   \n",
       "3              0  Acinetobacter  baumannii    Resistant  8.000      0.0   \n",
       "4              0  Acinetobacter  baumannii    Resistant  8.000      0.0   \n",
       "...          ...            ...        ...          ...    ...      ...   \n",
       "6704           1     Salmonella   enterica  Susceptible  0.015      1.0   \n",
       "6705           1     Salmonella   enterica  Susceptible  0.015      1.0   \n",
       "6706           1     Salmonella   enterica  Susceptible  0.015      1.0   \n",
       "6707           1     Salmonella   enterica  Susceptible  0.015      1.0   \n",
       "6708           1     Salmonella   enterica  Susceptible  0.030      1.0   \n",
       "\n",
       "      3000830  3003838  3000508  3003890  ...  3007751-D87Y  3003926-D87Y  \\\n",
       "0         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "1         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "2         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "3         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "4         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "...       ...      ...      ...      ...  ...           ...           ...   \n",
       "6704      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6705      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6706      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6707      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6708      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "\n",
       "      3003709-G46S  3004851-A39T  3004832-A501P  3003381-R20H  3003926-S83I  \\\n",
       "0              0.0           0.0            0.0           0.0           0.0   \n",
       "1              0.0           0.0            0.0           0.0           0.0   \n",
       "2              0.0           0.0            0.0           0.0           0.0   \n",
       "3              0.0           0.0            0.0           0.0           0.0   \n",
       "4              0.0           0.0            0.0           0.0           0.0   \n",
       "...            ...           ...            ...           ...           ...   \n",
       "6704           0.0           0.0            0.0           0.0           0.0   \n",
       "6705           0.0           0.0            0.0           0.0           0.0   \n",
       "6706           0.0           0.0            0.0           0.0           0.0   \n",
       "6707           0.0           0.0            0.0           0.0           0.0   \n",
       "6708           0.0           0.0            0.0           0.0           0.0   \n",
       "\n",
       "      3003381-G121D  3004832-T483S  3004832-A311V  \n",
       "0               0.0            0.0            0.0  \n",
       "1               0.0            0.0            0.0  \n",
       "2               0.0            0.0            0.0  \n",
       "3               0.0            0.0            0.0  \n",
       "4               0.0            0.0            0.0  \n",
       "...             ...            ...            ...  \n",
       "6704            0.0            0.0            0.0  \n",
       "6705            0.0            0.0            0.0  \n",
       "6706            0.0            0.0            0.0  \n",
       "6707            0.0            0.0            0.0  \n",
       "6708            0.0            0.0            0.0  \n",
       "\n",
       "[5952 rows x 880 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b90dc20-8f17-4c7b-848b-034e107bb5d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best models: {'RandomForest': Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['antibiotic', '3000830',\n",
      "                                                   '3000206', '3006880',\n",
      "                                                   '3000676', '3003576',\n",
      "                                                   '3001216', '3000237',\n",
      "                                                   '3003548', '3001889',\n",
      "                                                   '3003652', '3003899',\n",
      "                                                   '3006228', '3003900',\n",
      "                                                   '3006881', '3001866',\n",
      "                                                   '3003479', '3000166',\n",
      "                                                   '3002540', '3006878',\n",
      "                                                   '3006874', '3000168',\n",
      "                                                   '3004290', '30...\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier',\n",
      "                 RandomForestClassifier(n_estimators=50, random_state=42))]), 'SVM': Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['antibiotic', '3000830',\n",
      "                                                   '3000206', '3006880',\n",
      "                                                   '3000676', '3003576',\n",
      "                                                   '3001216', '3000237',\n",
      "                                                   '3003548', '3001889',\n",
      "                                                   '3003652', '3003899',\n",
      "                                                   '3006228', '3003900',\n",
      "                                                   '3006881', '3001866',\n",
      "                                                   '3003479', '3000166',\n",
      "                                                   '3002540', '3006878',\n",
      "                                                   '3006874', '3000168',\n",
      "                                                   '3004290', '30...\n",
      "                                                  ['genus', 'species',\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier', SVC(C=1, kernel='linear', random_state=42))]), 'KNN': Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['antibiotic', '3000830',\n",
      "                                                   '3000206', '3006880',\n",
      "                                                   '3000676', '3003576',\n",
      "                                                   '3001216', '3000237',\n",
      "                                                   '3003548', '3001889',\n",
      "                                                   '3003652', '3003899',\n",
      "                                                   '3006228', '3003900',\n",
      "                                                   '3006881', '3001866',\n",
      "                                                   '3003479', '3000166',\n",
      "                                                   '3002540', '3006878',\n",
      "                                                   '3006874', '3000168',\n",
      "                                                   '3004290', '30...\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier',\n",
      "                 KNeighborsClassifier(n_neighbors=7, weights='distance'))])}\n",
      "F1 scores: {'RandomForest': 0.7100475306171872, 'SVM': 0.6921599743102079, 'KNN': 0.6860654616879825}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def train_classifiers_with_tuning(df):\n",
    "    \"\"\"\n",
    "    Function to train RandomForest, SVM, and KNN classifiers with hyperparameter tuning on the 'mic' column.\n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        best_models: Dictionary containing the best tuned models for each classifier.\n",
    "        f1_scores: Dictionary containing F1 scores for each best-tuned classifier on test data.\n",
    "  \n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic'])  # Drop label columns \"antibiotic\"\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Encode 'mic' (target) using LabelEncoder (since it's multiclass)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Detect binary and multiclass features\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # 5. Define parameter grids for hyperparameter tuning\n",
    "    param_grid_rf = {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "\n",
    "    param_grid_svm = {\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__kernel': ['linear', 'rbf'],\n",
    "        'classifier__gamma': ['scale', 'auto']\n",
    "    }\n",
    "\n",
    "    param_grid_knn = {\n",
    "        'classifier__n_neighbors': [3, 5, 7],\n",
    "        'classifier__weights': ['uniform', 'distance']\n",
    "    }\n",
    "\n",
    "    # 6. Create pipelines for different classifiers\n",
    "    rf_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    svm_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', SVC(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    knn_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    # 7. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 8. Hyperparameter tuning with GridSearchCV\n",
    "    rf_grid = GridSearchCV(rf_pipeline, param_grid_rf, cv=3, scoring='f1_weighted')\n",
    "    svm_grid = GridSearchCV(svm_pipeline, param_grid_svm, cv=3, scoring='f1_weighted')\n",
    "    knn_grid = GridSearchCV(knn_pipeline, param_grid_knn, cv=3, scoring='f1_weighted')\n",
    "\n",
    "    # 9. Train models with best parameters and calculate F1 scores\n",
    "    best_models = {}\n",
    "    f1_scores = {}\n",
    "\n",
    "    # Random Forest\n",
    "    rf_grid.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_grid.predict(X_test)\n",
    "    f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "    best_models['RandomForest'] = rf_grid.best_estimator_\n",
    "    f1_scores['RandomForest'] = f1_rf\n",
    "\n",
    "    # SVM\n",
    "    svm_grid.fit(X_train, y_train)\n",
    "    y_pred_svm = svm_grid.predict(X_test)\n",
    "    f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "    best_models['SVM'] = svm_grid.best_estimator_\n",
    "    f1_scores['SVM'] = f1_svm\n",
    "\n",
    "    # KNN\n",
    "    knn_grid.fit(X_train, y_train)\n",
    "    y_pred_knn = knn_grid.predict(X_test)\n",
    "    f1_knn = f1_score(y_test, y_pred_knn, average='weighted')\n",
    "    best_models['KNN'] = knn_grid.best_estimator_\n",
    "    f1_scores['KNN'] = f1_knn\n",
    "\n",
    "    return best_models, f1_scores\n",
    "\n",
    "# Entrenar los modelos con ajuste de hiperparÃ¡metros\n",
    "best_models, f1_scores = train_classifiers_with_tuning(df)\n",
    "print(f'Best models: {best_models}')\n",
    "print(f'F1 scores: {f1_scores}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5ea3cd-db8f-4b4a-a658-b95173c4630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ParÃ¡metros para RandomForestClassifier: Ajusta el nÃºmero de Ã¡rboles, la profundidad mÃ¡xima y el nÃºmero mÃ­nimo de muestras para dividir un nodo.\n",
    "# ParÃ¡metros para SVC: Ajusta el parÃ¡metro de regularizaciÃ³n C, el kernel y el parÃ¡metro gamma.\n",
    "# ParÃ¡metros para KNeighborsClassifier: Ajusta el nÃºmero de vecinos y el tipo de ponderaciÃ³n para los vecinos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b8846d-1b97-4b7d-8365-6dc609b32df0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f895500-0c65-4af2-a1ea-8a60e3d9e0bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a534783d-0139-49c2-8921-13a90b7ac4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593a1ce3-1f5b-4d6f-9e4a-0c2aeaf415fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "927f33d9-563e-4956-951a-e14d3ff979a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (659143255.py, line 121)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[48], line 121\u001b[0;36m\u001b[0m\n\u001b[0;31m    best_models['RandomForest'] = rf_grid.best_estimator_\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def train_classifiers_with_kfold_tuning(df):\n",
    "    \"\"\"\n",
    "    Function to train RandomForest, SVM, and KNN classifiers with hyperparameter tuning using K-Fold Cross-Validation.\n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        best_models: Dictionary containing the best tuned models for each classifier.\n",
    "        f1_scores: Dictionary containing F1 scores for each best-tuned classifier on test data.\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic'])  # Drop label columns but keep 'antibiotic'\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Encode 'mic' (target) using LabelEncoder (since it's multiclass)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Detect binary and multiclass features\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # 5. Define parameter grids for hyperparameter tuning\n",
    "    param_grid_rf = {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "\n",
    "    param_grid_svm = {\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__kernel': ['linear', 'rbf'],\n",
    "        'classifier__gamma': ['scale', 'auto']\n",
    "    }\n",
    "\n",
    "    param_grid_knn = {\n",
    "        'classifier__n_neighbors': [3, 5, 7],\n",
    "        'classifier__weights': ['uniform', 'distance']\n",
    "    }\n",
    "\n",
    "    # 6. Create pipelines for different classifiers\n",
    "    rf_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    svm_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', SVC(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    knn_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    # 7. Split data into training and testing sets\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 8. Hyperparameter tuning with KFold cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42) \n",
    "    \n",
    "    rf_grid = GridSearchCV(rf_pipeline, param_grid_rf, cv=kf, scoring='f1_weighted')\n",
    "    svm_grid = GridSearchCV(svm_pipeline, param_grid_svm, cv=kf, scoring='f1_weighted')\n",
    "    knn_grid = GridSearchCV(knn_pipeline, param_grid_knn, cv=kf, scoring='f1_weighted')\n",
    "\n",
    "    # 9. Train models with best parameters and calculate F1 scores\n",
    "    best_models = {}\n",
    "    f1_scores = {}\n",
    "\n",
    "#     # Random Forest\n",
    "#     rf_grid.fit(X_train, y_train)\n",
    "#     y_pred_rf = rf_grid.predict(X_test)\n",
    "#     f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "#     best_models['RandomForest'] = rf_grid.best_estimator_\n",
    "#     f1_scores['RandomForest'] = f1_rf\n",
    "\n",
    "#     # SVM\n",
    "#     svm_grid.fit(X_train, y_train)\n",
    "#     y_pred_svm = svm_grid.predict(X_test)\n",
    "#     f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "#     best_models['SVM'] = svm_grid.best_estimator_\n",
    "#     f1_scores['SVM'] = f1_svm\n",
    "\n",
    "#     # KNN\n",
    "#     knn_grid.fit(X_train, y_train)\n",
    "#     y_pred_knn = knn_grid.predict(X_test)\n",
    "#     f1_knn = f1_score(y_test, y_pred_knn, average='weighted')\n",
    "#     best_models['KNN'] = knn_grid.best_estimator_\n",
    "#     f1_scores['KNN'] = f1_knn\n",
    "\n",
    "#     return best_models, f1_scores\n",
    "\n",
    "# # Entrenar los modelos con ajuste de hiperparÃ¡metros usando K-Fold Cross-Validation\n",
    "# best_models, f1_scores = train_classifiers_with_kfold_tuning(df)\n",
    "# print(f'Best models: {best_models}')\n",
    "# print(f'F1 scores: {f1_scores}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e497b2be-7224-49a2-8c83-a5ac9b6f52e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best models: {'RandomForest': Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['antibiotic', '3000830',\n",
      "                                                   '3000206', '3006880',\n",
      "                                                   '3000676', '3003576',\n",
      "                                                   '3001216', '3000237',\n",
      "                                                   '3003548', '3001889',\n",
      "                                                   '3003652', '3003899',\n",
      "                                                   '3006228', '3003900',\n",
      "                                                   '3006881', '3001866',\n",
      "                                                   '3003479', '3000166',\n",
      "                                                   '3002540', '3006878',\n",
      "                                                   '3006874', '3000168',\n",
      "                                                   '3004290', '30...\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier',\n",
      "                 RandomForestClassifier(min_samples_split=5, n_estimators=200,\n",
      "                                        random_state=42))]), 'SVM': Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['antibiotic', '3000830',\n",
      "                                                   '3000206', '3006880',\n",
      "                                                   '3000676', '3003576',\n",
      "                                                   '3001216', '3000237',\n",
      "                                                   '3003548', '3001889',\n",
      "                                                   '3003652', '3003899',\n",
      "                                                   '3006228', '3003900',\n",
      "                                                   '3006881', '3001866',\n",
      "                                                   '3003479', '3000166',\n",
      "                                                   '3002540', '3006878',\n",
      "                                                   '3006874', '3000168',\n",
      "                                                   '3004290', '30...\n",
      "                                                  ['genus', 'species',\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier', SVC(C=10, random_state=42))]), 'KNN': Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('binary', 'passthrough',\n",
      "                                                  ['antibiotic', '3000830',\n",
      "                                                   '3000206', '3006880',\n",
      "                                                   '3000676', '3003576',\n",
      "                                                   '3001216', '3000237',\n",
      "                                                   '3003548', '3001889',\n",
      "                                                   '3003652', '3003899',\n",
      "                                                   '3006228', '3003900',\n",
      "                                                   '3006881', '3001866',\n",
      "                                                   '3003479', '3000166',\n",
      "                                                   '3002540', '3006878',\n",
      "                                                   '3006874', '3000168',\n",
      "                                                   '3004290', '30...\n",
      "                                                   '3005053', '3003838',\n",
      "                                                   '3000508', '3003890',\n",
      "                                                   '3000491', '3000833',\n",
      "                                                   '3000832', '3000254',\n",
      "                                                   '3000502', '3000499',\n",
      "                                                   '3000656', '3004039',\n",
      "                                                   '3000516', '3003578',\n",
      "                                                   '3000027', '3000074',\n",
      "                                                   '3003378', '3000263',\n",
      "                                                   '3000165', '3002660',\n",
      "                                                   '3002639', '3000412',\n",
      "                                                   '3000410', '3005010',\n",
      "                                                   '3002605', '3002860',\n",
      "                                                   '3000316', '3003839', ...])])),\n",
      "                ('classifier',\n",
      "                 KNeighborsClassifier(n_neighbors=7, weights='distance'))])}\n",
      "F1 scores: {'RandomForest': 0.7015878320438558, 'SVM': 0.6838762132303604, 'KNN': 0.6804936323082103}\n"
     ]
    }
   ],
   "source": [
    "def train_classifiers_with_kfold_tuning(df):\n",
    "    \"\"\"\n",
    "    Function to train RandomForest, SVM, and KNN classifiers with hyperparameter tuning using K-Fold Cross-Validation.\n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        best_models: Dictionary containing the best tuned models for each classifier.\n",
    "        f1_scores: Dictionary containing F1 scores for each best-tuned classifier on test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic'])  # Drop label columns but keep 'antibiotic'\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Encode 'mic' (target) using LabelEncoder (since it's multiclass)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Detect binary and multiclass features\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # 5. Define parameter grids for hyperparameter tuning\n",
    "    param_grid_rf = {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "\n",
    "    param_grid_svm = {\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__kernel': ['linear', 'rbf'],\n",
    "        'classifier__gamma': ['scale', 'auto']\n",
    "    }\n",
    "\n",
    "    param_grid_knn = {\n",
    "        'classifier__n_neighbors': [3, 5, 7],\n",
    "        'classifier__weights': ['uniform', 'distance']\n",
    "    }\n",
    "\n",
    "    # 6. Create pipelines for different classifiers\n",
    "    rf_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    svm_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', SVC(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    knn_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    # 7. Hyperparameter tuning with KFold cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42) \n",
    "    \n",
    "    rf_grid = GridSearchCV(rf_pipeline, param_grid_rf, cv=kf, scoring='f1_weighted')\n",
    "    svm_grid = GridSearchCV(svm_pipeline, param_grid_svm, cv=kf, scoring='f1_weighted')\n",
    "    knn_grid = GridSearchCV(knn_pipeline, param_grid_knn, cv=kf, scoring='f1_weighted')\n",
    "\n",
    "    # 8. Train models with best parameters and get the best estimator (no manual train/test split)\n",
    "    best_models = {}\n",
    "    f1_scores = {}\n",
    "\n",
    "    # Random Forest\n",
    "    rf_grid.fit(X, y_encoded)\n",
    "    best_models['RandomForest'] = rf_grid.best_estimator_\n",
    "    f1_scores['RandomForest'] = rf_grid.best_score_  # Use the best F1 score from cross-validation\n",
    "\n",
    "    # SVM\n",
    "    svm_grid.fit(X, y_encoded)\n",
    "    best_models['SVM'] = svm_grid.best_estimator_\n",
    "    f1_scores['SVM'] = svm_grid.best_score_\n",
    "\n",
    "    # KNN\n",
    "    knn_grid.fit(X, y_encoded)\n",
    "    best_models['KNN'] = knn_grid.best_estimator_\n",
    "    f1_scores['KNN'] = knn_grid.best_score_\n",
    "\n",
    "    return best_models, f1_scores\n",
    "\n",
    "# Entrenar los modelos con ajuste de hiperparÃ¡metros usando K-Fold Cross-Validation\n",
    "best_models, f1_scores = train_classifiers_with_kfold_tuning(df)\n",
    "print(f'Best models: {best_models}')\n",
    "print(f'F1 scores: {f1_scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664ae761-28a0-4ee6-a3b1-0e47a9c6726b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "607db714-98d2-4583-9df9-f80cd613179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "def train_stacking_classifier(X, y1, y2):\n",
    "    \"\"\"\n",
    "    Train a stacking classifier for binary and multiclass outputs using RF, SVM, and KNN as base estimators\n",
    "    and Random Forest as meta-estimator.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : pandas DataFrame\n",
    "        Features\n",
    "    y1 : array-like\n",
    "        Binary target\n",
    "    y2 : array-like\n",
    "        Multiclass target\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Trained stacking classifiers for both targets with their respective scores\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Preprocessing\n",
    "    binary_cols = [col for col in X.columns if X[col].nunique() <= 2]\n",
    "    multiclass_cols = [col for col in X.columns if X[col].nunique() > 2]\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)\n",
    "        ], remainder='passthrough')\n",
    "    \n",
    "    # 2. Define base estimators with their parameter grids\n",
    "    estimators = [\n",
    "        ('rf', RandomForestClassifier(random_state=42)),\n",
    "        ('svm', SVC(probability=True, random_state=42)),\n",
    "        ('knn', KNeighborsClassifier())\n",
    "    ]\n",
    "    \n",
    "    param_grids = {\n",
    "        'rf': {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'min_samples_split': [2, 5]\n",
    "        },\n",
    "        'svm': {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'kernel': ['rbf', 'linear'],\n",
    "            'gamma': ['scale', 'auto']\n",
    "        },\n",
    "        'knn': {\n",
    "            'n_neighbors': [3, 5, 7],\n",
    "            'weights': ['uniform', 'distance']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 3. Define meta-estimator (Random Forest) parameters\n",
    "    meta_param_grid = {\n",
    "        'final_estimator__n_estimators': [100, 200],\n",
    "        'final_estimator__max_depth': [None, 10],\n",
    "        'final_estimator__min_samples_split': [2, 5]\n",
    "    }\n",
    "    \n",
    "    # 4. Create stacking classifiers for both targets\n",
    "    def create_stacking_pipeline():\n",
    "        stacking = StackingClassifier(\n",
    "            estimators=estimators,\n",
    "            final_estimator=RandomForestClassifier(random_state=42),\n",
    "            cv=5,  # Internal cross-validation for stacking\n",
    "            stack_method='predict_proba'\n",
    "        )\n",
    "        \n",
    "        return Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('stacking', stacking)\n",
    "        ])\n",
    "    \n",
    "    # 5. Create and train models for both targets\n",
    "    models = {}\n",
    "    scores = {}\n",
    "    \n",
    "    # 6. Define cross-validation strategy\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # 7. Train binary classifier\n",
    "    binary_stack = create_stacking_pipeline()\n",
    "    binary_grid = GridSearchCV(\n",
    "        binary_stack,\n",
    "        param_grid=meta_param_grid,\n",
    "        cv=cv,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    binary_grid.fit(X, y1)\n",
    "    models['binary'] = binary_grid.best_estimator_\n",
    "    scores['binary'] = binary_grid.best_score_\n",
    "    \n",
    "    # 8. Train multiclass classifier\n",
    "    multiclass_stack = create_stacking_pipeline()\n",
    "    multiclass_grid = GridSearchCV(\n",
    "        multiclass_stack,\n",
    "        param_grid=meta_param_grid,\n",
    "        cv=cv,\n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    multiclass_grid.fit(X, y2)\n",
    "    models['multiclass'] = multiclass_grid.best_estimator_\n",
    "    scores['multiclass'] = multiclass_grid.best_score_\n",
    "    \n",
    "    return {\n",
    "        'models': models,\n",
    "        'scores': scores,\n",
    "        'binary_best_params': binary_grid.best_params_,\n",
    "        'multiclass_best_params': multiclass_grid.best_params_\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecfd9f0-d48b-4332-ad8a-dd6911a1124d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e896a0-f4b3-47ab-9138-b6038c4285f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"mic\"].max(),df[\"mic\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f222959-389e-4c2c-9279-98935dfc15b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['mic'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5b30a-6c4c-4d94-8fba-fd47d097d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"mic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31ba7c66-9526-4965-a4c2-40dc0451afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def train_classifiers_with_stacking(df):\n",
    "    \"\"\"\n",
    "    Function to train RandomForest, SVM, and KNN classifiers with hyperparameter tuning using K-Fold Cross-Validation,\n",
    "    and combine them using StackingClassifier.\n",
    "    \n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        stacking_model: Trained stacking model.\n",
    "        f1_stacking: F1 score of the stacking model on the test data.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic'])  # Drop label columns but keep 'antibiotic'\n",
    "    y = df['mic']  # Target label\n",
    "\n",
    "    # 2. Encode 'mic' (target) using LabelEncoder (since it's multiclass)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Detect binary and multiclass features\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # 5. Create base models (without hyperparameter tuning)\n",
    "    rf_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    svm_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', SVC(random_state=42, probability=True))  # We need probability=True for stacking\n",
    "    ])\n",
    "    \n",
    "    knn_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    # 6. Meta-classifier for stacking (Logistic Regression)\n",
    "    meta_classifier = LogisticRegression() # usar ota distinta \n",
    "\n",
    "    # 7. StackingClassifier: combines base models\n",
    "    stacking_model = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', rf_model),\n",
    "            ('svm', svm_model),\n",
    "            ('knn', knn_model)\n",
    "        ],\n",
    "        final_estimator=meta_classifier,\n",
    "        cv=5  # Cross-validation for stacking\n",
    "    )\n",
    "\n",
    "    # 8. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 9. Train the stacking model\n",
    "    stacking_model.fit(X_train, y_train)\n",
    "\n",
    "    # 10. Make predictions and calculate F1 score\n",
    "    y_pred_stacking = stacking_model.predict(X_test)\n",
    "    f1_stacking = f1_score(y_test, y_pred_stacking, average='weighted')\n",
    "\n",
    "    return stacking_model, f1_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac42dee5-a247-4d71-aa26-d3704e1f4c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (26) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (26) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (25) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (25) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (26) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (26) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (25) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (25) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (26) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (26) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (25) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (25) does not match total number of classes (27). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Model F1 Score: 0.704428213409905\n"
     ]
    }
   ],
   "source": [
    "stacking_model, f1_stacking = train_classifiers_with_stacking(df)\n",
    "print(f'Stacking Model F1 Score: {f1_stacking}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ce0cf9-a24f-4695-b64b-d9289f66819e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc51817a-4164-4a73-9757-e24d1490f86f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f417c1c4-df7a-4db6-9511-0dccf6c1d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mic_transform(mic_values):\n",
    "    log_mic = np.log2(mic_values)\n",
    "    rounded_mic = np.round(log_mic).clip(-7, 7)  # Limitar a potencias entre -7 y 7\n",
    "    return rounded_mic\n",
    "\n",
    "mic_transformer = FunctionTransformer(mic_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5473b37c-3187-4d96-a3ec-cc4c349e4b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d9dd11-4f25-4250-a9bc-61a5fe4c8412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38b48c63-8664-4cf3-a2f5-cb5f8aa9ab8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Model F1 Score: 0.7101268174047273\n"
     ]
    }
   ],
   "source": [
    "def train_classifiers_with_stacking(df):\n",
    "    \"\"\"\n",
    "    Function to train RandomForest, SVM, and KNN classifiers with hyperparameter tuning using K-Fold Cross-Validation,\n",
    "    and combine them using StackingClassifier.\n",
    "    \n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        stacking_model: Trained stacking model.\n",
    "        f1_stacking: F1 score of the stacking model on the test data.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic'])  # Drop label columns but keep 'antibiotic'\n",
    "    y = df['mic']  # Target label (mic)\n",
    "\n",
    "    # 2. Apply log2 transformation and rounding to `mic` using FunctionTransformer\n",
    "    y_transformed = mic_transformer.fit_transform(y.values.reshape(-1, 1)).ravel()  # Transform `mic` column\n",
    "\n",
    "    # 3. Detect binary and multiclass features in X\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # 5. Create base models (without hyperparameter tuning)\n",
    "    rf_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    svm_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', SVC(random_state=42, probability=True))  # We need probability=True for stacking\n",
    "    ])\n",
    "    \n",
    "    knn_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    # 6. Meta-classifier for stacking (Logistic Regression)\n",
    "    meta_classifier = LogisticRegression()\n",
    "\n",
    "    # 7. StackingClassifier: combines base models\n",
    "    stacking_model = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', rf_model),\n",
    "            ('svm', svm_model),\n",
    "            ('knn', knn_model)\n",
    "        ],\n",
    "        final_estimator=meta_classifier,\n",
    "        cv=5  # Cross-validation for stacking\n",
    "    )\n",
    "\n",
    "    # 8. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_transformed, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 9. Train the stacking model\n",
    "    stacking_model.fit(X_train, y_train)\n",
    "\n",
    "    # 10. Make predictions and calculate F1 score\n",
    "    y_pred_stacking = stacking_model.predict(X_test)\n",
    "    f1_stacking = f1_score(y_test, y_pred_stacking, average='weighted')\n",
    "\n",
    "    return stacking_model, f1_stacking\n",
    "\n",
    "# Entrenar el modelo de stacking con la transformaciÃ³n de mic\n",
    "stacking_model, f1_stacking = train_classifiers_with_stacking(df)\n",
    "print(f'Stacking Model F1 Score: {f1_stacking}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "40410a73-4633-4c0c-aea6-b002c2e7c66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Model F1 Score: 0.7071406850175487\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_classifiers_with_stacking(df):\n",
    "    \"\"\"\n",
    "    Function to train RandomForest, SVM, and KNN classifiers with hyperparameter tuning using K-Fold Cross-Validation,\n",
    "    and combine them using StackingClassifier with a neural network as the meta-classifier.\n",
    "    \n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        stacking_model: Trained stacking model.\n",
    "        f1_stacking: F1 score of the stacking model on the test data.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic'])  # Drop label columns but keep 'antibiotic'\n",
    "    y = df['mic']  # Target label (mic)\n",
    "\n",
    "    # 2. Apply log2 transformation and rounding to `mic` using FunctionTransformer\n",
    "    y_transformed = mic_transformer.fit_transform(y.values.reshape(-1, 1)).ravel()  # Transform `mic` column\n",
    "\n",
    "    # 3. Detect binary and multiclass features in X\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # 5. Create base models (without hyperparameter tuning)\n",
    "    rf_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    svm_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', SVC(random_state=42, probability=True))  # We need probability=True for stacking\n",
    "    ])\n",
    "    \n",
    "    knn_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    # 6. Meta-classifier for stacking (Neural Network)\n",
    "    meta_classifier = MLPClassifier(\n",
    "        hidden_layer_sizes=(64, 32),  # Define the structure of the neural network\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=200,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # 7. StackingClassifier: combines base models\n",
    "    stacking_model = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', rf_model),\n",
    "            ('svm', svm_model),\n",
    "            ('knn', knn_model)\n",
    "        ],\n",
    "        final_estimator=meta_classifier,\n",
    "        cv=5  # Cross-validation for stacking\n",
    "    )\n",
    "\n",
    "    # 8. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_transformed, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 9. Train the stacking model\n",
    "    stacking_model.fit(X_train, y_train)\n",
    "\n",
    "    # 10. Make predictions and calculate F1 score\n",
    "    y_pred_stacking = stacking_model.predict(X_test)\n",
    "    f1_stacking = f1_score(y_test, y_pred_stacking, average='weighted')\n",
    "\n",
    "    return stacking_model, f1_stacking\n",
    "\n",
    "# Entrenar el modelo de stacking con la transformaciÃ³n de mic\n",
    "stacking_model, f1_stacking = train_classifiers_with_stacking(df)\n",
    "print(f'Stacking Model F1 Score: {f1_stacking}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c456ac4b-5836-44c4-a372-d6eaa7ee7678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Model F1 Score: 0.7125041899797098\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier, BaggingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_classifiers_with_stacking(df):\n",
    "    \"\"\"\n",
    "    Function to train RandomForest, SVM, and KNN classifiers with hyperparameter tuning using GridSearchCV,\n",
    "    and combine them using StackingClassifier with a neural network and BaggingClassifier as the meta-classifier.\n",
    "    \n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels.\n",
    "        \n",
    "    Returns:\n",
    "        stacking_model: Trained stacking model.\n",
    "        f1_stacking: F1 score of the stacking model on the test data.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Separate features and labels\n",
    "    X = df.drop(columns=['phenotype', 'mic'])  # Drop label columns but keep 'antibiotic'\n",
    "    y = df['mic']  # Target label (mic)\n",
    "\n",
    "    # 2. Apply log2 transformation and rounding to `mic` using FunctionTransformer\n",
    "    y_transformed = mic_transformer.fit_transform(y.values.reshape(-1, 1)).ravel()  # Transform `mic` column\n",
    "\n",
    "    # 3. Detect binary and multiclass features in X\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 4. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # 5. Define hyperparameters for each model\n",
    "    rf_params = {\n",
    "        'classifier__n_estimators': [100, 200, 300],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5, 10],\n",
    "    }\n",
    "    svm_params = {\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__kernel': ['linear', 'rbf'],\n",
    "    }\n",
    "    knn_params = {\n",
    "        'classifier__n_neighbors': [3, 5, 7, 9],\n",
    "        'classifier__weights': ['uniform', 'distance'],\n",
    "    }\n",
    "\n",
    "    # 6. Create base models with GridSearchCV\n",
    "    rf_model = GridSearchCV(\n",
    "        Pipeline(steps=[\n",
    "            ('preprocessing', preprocessor),\n",
    "            ('classifier', RandomForestClassifier(random_state=42))\n",
    "        ]),\n",
    "        rf_params, cv=5, scoring='f1_weighted'\n",
    "    )\n",
    "    \n",
    "    svm_model = GridSearchCV(\n",
    "        Pipeline(steps=[\n",
    "            ('preprocessing', preprocessor),\n",
    "            ('classifier', SVC(random_state=42, probability=True))\n",
    "        ]),\n",
    "        svm_params, cv=5, scoring='f1_weighted'\n",
    "    )\n",
    "    \n",
    "    knn_model = GridSearchCV(\n",
    "        Pipeline(steps=[\n",
    "            ('preprocessing', preprocessor),\n",
    "            ('classifier', KNeighborsClassifier())\n",
    "        ]),\n",
    "        knn_params, cv=5, scoring='f1_weighted'\n",
    "    )\n",
    "\n",
    "    # 7. Meta-classifier for stacking: Neural Network inside BaggingClassifier\n",
    "    neural_net = MLPClassifier(\n",
    "        hidden_layer_sizes=(64, 32),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=200,\n",
    "        random_state=42\n",
    "    )\n",
    "    meta_classifier = BaggingClassifier(\n",
    "        estimator=neural_net,  # Replace base_estimator with estimator\n",
    "        n_estimators=10,  # Number of models in bagging ensemble\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # 8. StackingClassifier: combines base models with tuned parameters\n",
    "    stacking_model = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', rf_model),\n",
    "            ('svm', svm_model),\n",
    "            ('knn', knn_model)\n",
    "        ],\n",
    "        final_estimator=meta_classifier,\n",
    "        cv=5  # Cross-validation for stacking\n",
    "    )\n",
    "\n",
    "    # 9. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_transformed, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 10. Train the stacking model with best hyperparameters\n",
    "    stacking_model.fit(X_train, y_train)\n",
    "\n",
    "    # 11. Make predictions and calculate F1 score\n",
    "    y_pred_stacking = stacking_model.predict(X_test)\n",
    "    f1_stacking = f1_score(y_test, y_pred_stacking, average='weighted')\n",
    "\n",
    "    return stacking_model, f1_stacking\n",
    "\n",
    "# Entrenar el modelo de stacking con la transformaciÃ³n de mic\n",
    "stacking_model, f1_stacking = train_classifiers_with_stacking(df)\n",
    "print(f'Stacking Model F1 Score: {f1_stacking}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f362fe78-90c2-49ba-8bc1-00dcaf59ffac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fa8cf2-89e9-497a-ab19-7c3e0963a5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8cf1a851-0e22-4677-a4d0-dc44786fdbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 1. Convert 'phenotype' values (Resistant, Susceptible) into binary labels\n",
    "    df['phenotype'] = df['phenotype'].map({'Resistant': 1, 'Susceptible': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "186dacac-8354-4ede-a742-5592457dc8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multioutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08e2e0dc-939c-4151-a530-99177442f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifiers_with_multioutput(df):\n",
    "    \"\"\"\n",
    "    Function to train RandomForest, SVM, and KNN classifiers for multi-output prediction (predicting both mic and phenotype),\n",
    "    and combine them using StackingClassifier and MultiOutputClassifier.\n",
    "    \n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels (mic and phenotype).\n",
    "        \n",
    "    Returns:\n",
    "        stacking_model: Trained multi-output stacking model.\n",
    "        f1_scores: Dictionary containing F1 scores for mic and phenotype on the test data.\n",
    "    \"\"\"\n",
    "\n",
    "    # 2. Separate features and labels\n",
    "    X = df.drop(columns=['mic', 'phenotype'])  # Features\n",
    "    y_mic = df['mic']  # Target label 1 (mic)\n",
    "    y_phenotype = df['phenotype']  # Target label 2 (phenotype)\n",
    "\n",
    "    # 3. Apply log2 transformation\n",
    "    y_mic_transformed = mic_transformer.fit_transform(y_mic.values.reshape(-1, 1)).ravel()  # Transform `mic` column\n",
    "\n",
    "    # 4. Detect binary and multiclass features in X\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 5. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols),  # Pass through binary columns\n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  # One-hot encode multiclass columns\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # 6. Create base models \n",
    "    rf_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    svm_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', SVC(random_state=42, probability=True))  # We need probability=True for stacking\n",
    "    ])\n",
    "    \n",
    "    knn_model = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    # 7. Meta-classifier for stacking \n",
    "    meta_classifier = LogisticRegression()\n",
    "\n",
    "    # 8. StackingClassifier: combines base models\n",
    "    stacking_model = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', rf_model),\n",
    "            ('svm', svm_model),\n",
    "            ('knn', knn_model)\n",
    "        ],\n",
    "        final_estimator=meta_classifier,\n",
    "        cv=5  \n",
    "    )\n",
    "\n",
    "    # 9. Use MultiOutputClassifier to predict both mic and phenotype\n",
    "    multioutput_model = MultiOutputClassifier(stacking_model)\n",
    "\n",
    "    # 10. Split data into training and testing sets for both mic and phenotype\n",
    "    y_combined = np.column_stack([y_mic_transformed, y_phenotype])  # Combine both target variables\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 11. Train the multi-output model\n",
    "    multioutput_model.fit(X_train, y_train)\n",
    "\n",
    "    # 12. Make predictions and calculate F1 scores for both mic and phenotype\n",
    "    y_pred = multioutput_model.predict(X_test)\n",
    "    f1_mic = f1_score(y_test[:, 0], y_pred[:, 0], average='weighted')  # F1 score for mic\n",
    "    f1_phenotype = f1_score(y_test[:, 1], y_pred[:, 1], average='weighted')  # F1 score for phenotype\n",
    "\n",
    "    f1_scores = {\n",
    "        'mic': f1_mic,\n",
    "        'phenotype': f1_phenotype\n",
    "    }\n",
    "\n",
    "    return multioutput_model, f1_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d224b88-4c5a-469b-925d-6f2f2f7f8b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/umap/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores: {'mic': 0.7101268174047273, 'phenotype': 0.9396797964022365}\n"
     ]
    }
   ],
   "source": [
    "multioutput_model, f1_scores = train_classifiers_with_multioutput(df)\n",
    "print(f'F1 scores: {f1_scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1caa461f-9f0e-4a34-8511-7ef271879fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antibiotic</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>mic</th>\n",
       "      <th>3005053</th>\n",
       "      <th>3000830</th>\n",
       "      <th>3003838</th>\n",
       "      <th>3000508</th>\n",
       "      <th>3003890</th>\n",
       "      <th>...</th>\n",
       "      <th>3007751-D87Y</th>\n",
       "      <th>3003926-D87Y</th>\n",
       "      <th>3003709-G46S</th>\n",
       "      <th>3004851-A39T</th>\n",
       "      <th>3004832-A501P</th>\n",
       "      <th>3003381-R20H</th>\n",
       "      <th>3003926-S83I</th>\n",
       "      <th>3003381-G121D</th>\n",
       "      <th>3004832-T483S</th>\n",
       "      <th>3004832-A311V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>baumannii</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6704</th>\n",
       "      <td>1</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>1</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6706</th>\n",
       "      <td>1</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6707</th>\n",
       "      <td>1</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6708</th>\n",
       "      <td>1</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>enterica</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5952 rows Ã— 880 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      antibiotic          genus    species  phenotype    mic  3005053  \\\n",
       "0              0  Acinetobacter  baumannii          1  8.000      0.0   \n",
       "1              0  Acinetobacter  baumannii          1  8.000      0.0   \n",
       "2              0  Acinetobacter  baumannii          1  8.000      0.0   \n",
       "3              0  Acinetobacter  baumannii          1  8.000      0.0   \n",
       "4              0  Acinetobacter  baumannii          1  8.000      0.0   \n",
       "...          ...            ...        ...        ...    ...      ...   \n",
       "6704           1     Salmonella   enterica          0  0.015      1.0   \n",
       "6705           1     Salmonella   enterica          0  0.015      1.0   \n",
       "6706           1     Salmonella   enterica          0  0.015      1.0   \n",
       "6707           1     Salmonella   enterica          0  0.015      1.0   \n",
       "6708           1     Salmonella   enterica          0  0.030      1.0   \n",
       "\n",
       "      3000830  3003838  3000508  3003890  ...  3007751-D87Y  3003926-D87Y  \\\n",
       "0         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "1         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "2         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "3         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "4         0.0      0.0      0.0      0.0  ...           0.0           0.0   \n",
       "...       ...      ...      ...      ...  ...           ...           ...   \n",
       "6704      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6705      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6706      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6707      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "6708      1.0      0.0      0.0      1.0  ...           0.0           0.0   \n",
       "\n",
       "      3003709-G46S  3004851-A39T  3004832-A501P  3003381-R20H  3003926-S83I  \\\n",
       "0              0.0           0.0            0.0           0.0           0.0   \n",
       "1              0.0           0.0            0.0           0.0           0.0   \n",
       "2              0.0           0.0            0.0           0.0           0.0   \n",
       "3              0.0           0.0            0.0           0.0           0.0   \n",
       "4              0.0           0.0            0.0           0.0           0.0   \n",
       "...            ...           ...            ...           ...           ...   \n",
       "6704           0.0           0.0            0.0           0.0           0.0   \n",
       "6705           0.0           0.0            0.0           0.0           0.0   \n",
       "6706           0.0           0.0            0.0           0.0           0.0   \n",
       "6707           0.0           0.0            0.0           0.0           0.0   \n",
       "6708           0.0           0.0            0.0           0.0           0.0   \n",
       "\n",
       "      3003381-G121D  3004832-T483S  3004832-A311V  \n",
       "0               0.0            0.0            0.0  \n",
       "1               0.0            0.0            0.0  \n",
       "2               0.0            0.0            0.0  \n",
       "3               0.0            0.0            0.0  \n",
       "4               0.0            0.0            0.0  \n",
       "...             ...            ...            ...  \n",
       "6704            0.0            0.0            0.0  \n",
       "6705            0.0            0.0            0.0  \n",
       "6706            0.0            0.0            0.0  \n",
       "6707            0.0            0.0            0.0  \n",
       "6708            0.0            0.0            0.0  \n",
       "\n",
       "[5952 rows x 880 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c16dd545-7c83-4485-9e3b-944631289077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest_multioutput(df):\n",
    "    \"\"\"\n",
    "    Function to train a random forest classifier for multi-output prediction of 'mic' and 'phenotype' columns.\n",
    "    \n",
    "    Args:\n",
    "        df: Input pandas DataFrame with features and labels ('mic' and 'phenotype').\n",
    "        \n",
    "    Returns:\n",
    "        model: Trained MultiOutput RandomForestClassifier model.\n",
    "        f1_scores: F1 scores for both 'mic' and 'phenotype' on test data.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # 2. Separate features and labels\n",
    "    X = df.drop(columns=['mic', 'phenotype', 'antibiotic'])  \n",
    "    y_mic = df['mic']  \n",
    "    y_phenotype = df['phenotype']\n",
    "\n",
    "    # 3. Encode 'mic' using LabelEncoder \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_mic_encoded = label_encoder.fit_transform(y_mic)\n",
    "\n",
    "    # 4. Detect binary and multiclass features in X\n",
    "    binary_cols = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]  # Binary features\n",
    "    multiclass_cols = [col for col in X.columns if len(X[col].unique()) > 2]  # Multiclass features\n",
    "\n",
    "    # 5. Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('binary', 'passthrough', binary_cols), \n",
    "            ('multiclass', OneHotEncoder(handle_unknown='ignore'), multiclass_cols)  \n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # 6. Create a RandomForest pipeline for multi-output classification\n",
    "    rf_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', MultiOutputClassifier(RandomForestClassifier(random_state=42)))\n",
    "    ])\n",
    "\n",
    "    # 7. Combine both mic and phenotype into a single target array\n",
    "    y_combined = np.column_stack([y_mic_encoded, y_phenotype])\n",
    "\n",
    "    # 8. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 9. Train the multi-output model\n",
    "    rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # 10. Make predictions and calculate the F1 scores for both mic and phenotype\n",
    "    y_pred = rf_pipeline.predict(X_test)\n",
    "    f1_mic = f1_score(y_test[:, 0], y_pred[:, 0], average='weighted')  # F1 score for mic\n",
    "    f1_phenotype = f1_score(y_test[:, 1], y_pred[:, 1], average='weighted')  # F1 score for phenotype\n",
    "\n",
    "    f1_scores = {\n",
    "        'mic': f1_mic,\n",
    "        'phenotype': f1_phenotype\n",
    "    }\n",
    "\n",
    "    return rf_pipeline, f1_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7321dd7-269c-4cbe-bddf-552bc830fac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores: {'mic': 0.7135263475674756, 'phenotype': 0.9338607851184337}\n"
     ]
    }
   ],
   "source": [
    "rf_model, f1_scores = train_random_forest_multioutput(df)\n",
    "print(f'F1 scores: {f1_scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a7677a-4bb7-40a0-bd34-19c0a4a90297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf38be5-41c7-45e8-8520-a4d7377975d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f34fbf2-f4cd-412e-a42e-6ec4ac185a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e450d78-fd25-4388-8a93-3d3f6464ff35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umap",
   "language": "python",
   "name": "umap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
