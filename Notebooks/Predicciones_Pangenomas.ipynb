{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3637049",
   "metadata": {},
   "source": [
    "# Instalar polar para cargar las bases de pangenomas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1492297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install polar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af91aa8",
   "metadata": {},
   "source": [
    "# Librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f13fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import polars as pl\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a34424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee el archivo TSV\n",
    "df_polar = pl.read_csv(\"PangenomeCountCiprofloxacin.tsv\", separator='\\t')\n",
    "\n",
    "# Muestra el DataFrame\n",
    "df_polar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5523df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a pandas\n",
    "df = df_polar.to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b0165a",
   "metadata": {},
   "source": [
    "# Todos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "687d8503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: Random Forest (1200 trees)\n",
      "Accuracy: 0.9590\n",
      "F1 Score: 0.9526\n",
      "Confusion Matrix:\n",
      "[[ 20  22]\n",
      " [  1 518]]\n",
      "\n",
      "Algorithm: Random Forest (500 trees)\n",
      "Accuracy: 0.9590\n",
      "F1 Score: 0.9526\n",
      "Confusion Matrix:\n",
      "[[ 20  22]\n",
      " [  1 518]]\n",
      "\n",
      "Algorithm: KNN (k=1)\n",
      "Accuracy: 0.9501\n",
      "F1 Score: 0.9446\n",
      "Confusion Matrix:\n",
      "[[ 20  22]\n",
      " [  6 513]]\n",
      "\n",
      "Algorithm: KNN (k=3)\n",
      "Accuracy: 0.9394\n",
      "F1 Score: 0.9400\n",
      "Confusion Matrix:\n",
      "[[ 26  16]\n",
      " [ 18 501]]\n",
      "\n",
      "Algorithm: KNN (k=5)\n",
      "Accuracy: 0.9554\n",
      "F1 Score: 0.9536\n",
      "Confusion Matrix:\n",
      "[[ 26  16]\n",
      " [  9 510]]\n",
      "\n",
      "Algorithm: SVM (RBF Kernel)\n",
      "Accuracy: 0.9447\n",
      "F1 Score: 0.9424\n",
      "Confusion Matrix:\n",
      "[[ 23  19]\n",
      " [ 12 507]]\n",
      "\n",
      "Algorithm: SVM (Linear Kernel)\n",
      "Accuracy: 0.9483\n",
      "F1 Score: 0.9431\n",
      "Confusion Matrix:\n",
      "[[ 20  22]\n",
      " [  7 512]]\n",
      "\n",
      "Algorithm: SVM (Polynomial Kernel)\n",
      "Accuracy: 0.9269\n",
      "F1 Score: 0.8935\n",
      "Confusion Matrix:\n",
      "[[  1  41]\n",
      " [  0 519]]\n",
      "\n",
      "Algorithm: MLP (1 Hidden Layer, 200 neurons)\n",
      "Accuracy: 0.9483\n",
      "F1 Score: 0.9439\n",
      "Confusion Matrix:\n",
      "[[ 21  21]\n",
      " [  8 511]]\n",
      "\n",
      "Algorithm: Logistic Regression\n",
      "Accuracy: 0.9537\n",
      "F1 Score: 0.9477\n",
      "Confusion Matrix:\n",
      "[[ 20  22]\n",
      " [  4 515]]\n",
      "\n",
      "Algorithm: Gaussian NB\n",
      "Accuracy: 0.8467\n",
      "F1 Score: 0.8783\n",
      "Confusion Matrix:\n",
      "[[ 41   1]\n",
      " [ 85 434]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define your algorithms\n",
    "algorithms = {\n",
    "        \"Random Forest (1200 trees)\": RandomForestClassifier(n_estimators=1200, random_state=42),\n",
    "        \"Random Forest (500 trees)\": RandomForestClassifier(n_estimators=500, random_state=42),\n",
    "        \"KNN (k=1)\": KNeighborsClassifier(n_neighbors=1),\n",
    "        \"KNN (k=3)\": KNeighborsClassifier(n_neighbors=3),\n",
    "        \"KNN (k=5)\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"SVM (RBF Kernel)\": SVC(kernel='rbf', gamma='auto', C=1, random_state=42),\n",
    "        \"SVM (Linear Kernel)\": SVC(kernel='linear', gamma='auto', C=1, random_state=42),\n",
    "        \"SVM (Polynomial Kernel)\": SVC(kernel='poly', gamma='auto', C=1, random_state=42),\n",
    "        \"MLP (1 Hidden Layer, 200 neurons)\": MLPClassifier(hidden_layer_sizes=(200,), max_iter=1000, random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "        \"Gaussian NB\": GaussianNB()\n",
    "}\n",
    "# Train and evaluate each algorithm\n",
    "results = {}\n",
    "for algo_name, algo in algorithms.items():\n",
    "    # Train the model\n",
    "    # Filtra el DataFrame por la columna 'phenotype'\n",
    "    #df_training = df[df['phenotype'].isin(['Susceptible', 'Resistant']) & df['genus'].isin(['Your_Genus_Filter'])]\n",
    "    df_training = df[df['phenotype'].isin(['Susceptible', 'Resistant'])]\n",
    "    df_test = df[df['phenotype'].isna()]\n",
    "\n",
    "    # Filtra el DataFrame por cada etiqueta\n",
    "    df_res = df[df['phenotype'] == 'Resistant']\n",
    "    df_sus = df[df['phenotype'] == 'Susceptible']\n",
    "\n",
    "    # Calcula la proporción de 1 y 0 para cada etiqueta en cada columna\n",
    "    proporcion_res = df_res.iloc[:,6:].mean()\n",
    "    proporcion_sus = df_sus.iloc[:,6:].mean()\n",
    "\n",
    "    # Calcula la diferencia en la proporción entre las dos etiquetas para cada columna\n",
    "    diferencia = abs(proporcion_res - proporcion_sus)\n",
    "\n",
    "    # Ordena las columnas por la diferencia en orden descendente\n",
    "    columnas_ordenadas = diferencia.sort_values(ascending=False)\n",
    "\n",
    "    # Selecciona las N primeras columnas con la mayor diferencia\n",
    "    # OBSERVACION: FUE UN NUMERO ALEATORIO SIN SENTIDO\n",
    "    columns_subset_size = 4000\n",
    "    subset = columnas_ordenadas.head(columns_subset_size)\n",
    "\n",
    "    nombres_columnas_seleccionadas = subset.index\n",
    "\n",
    "    # Filtra el DataFrame original para seleccionar solo las columnas deseadas\n",
    "    df_filtrado = df_training[nombres_columnas_seleccionadas]\n",
    "    df_filtrado_test = df_test[nombres_columnas_seleccionadas]\n",
    "\n",
    "    labels = df_training['phenotype']\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Fit and transform the labels\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    \n",
    "    # Dividir los datos codificados en conjunto de entrenamiento y conjunto de prueba\n",
    "    test_size = 0.2\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_filtrado, encoded_labels, stratify=encoded_labels, test_size=test_size, random_state=50)\n",
    "    \n",
    "       \n",
    "    algo.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = algo.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')  # Weighted F1-score for multiclass classification\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Store results\n",
    "    results[algo_name] = {'accuracy': accuracy, 'f1_score': f1, 'confusion_matrix': cm}\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.ylabel('Etiqueta verdadera')\n",
    "    plt.xticks(ticks=[0.5, 1.5], labels=['Resistant', 'Susceptible'])\n",
    "    plt.yticks(ticks=[0.5, 1.5], labels=['Resistant', 'Susceptible'])\n",
    "    plt.title('Matriz de Confusión - ' + algo_name)\n",
    "    \n",
    "    # Save confusion matrix plot\n",
    "    output_folder = \"confusion_matrix_plots\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    plt.savefig(os.path.join(output_folder, algo_name + \"_confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "results_df.to_csv(\"results.csv\")\n",
    "\n",
    "# Print results\n",
    "for algo_name, result in results.items():\n",
    "    print(f\"Algorithm: {algo_name}\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(f\"F1 Score: {result['f1_score']:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{result['confusion_matrix']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373721d7",
   "metadata": {},
   "source": [
    "# Campylobacter y Neisseria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03d5b759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: Random Forest (1200 trees)\n",
      "Accuracy: 0.8308\n",
      "F1 Score: 0.8231\n",
      "Confusion Matrix:\n",
      "[[24 16]\n",
      " [ 6 84]]\n",
      "\n",
      "Algorithm: Random Forest (500 trees)\n",
      "Accuracy: 0.8385\n",
      "F1 Score: 0.8302\n",
      "Confusion Matrix:\n",
      "[[24 16]\n",
      " [ 5 85]]\n",
      "\n",
      "Algorithm: KNN (k=1)\n",
      "Accuracy: 0.8000\n",
      "F1 Score: 0.8025\n",
      "Confusion Matrix:\n",
      "[[29 11]\n",
      " [15 75]]\n",
      "\n",
      "Algorithm: KNN (k=3)\n",
      "Accuracy: 0.8154\n",
      "F1 Score: 0.8109\n",
      "Confusion Matrix:\n",
      "[[25 15]\n",
      " [ 9 81]]\n",
      "\n",
      "Algorithm: KNN (k=5)\n",
      "Accuracy: 0.7769\n",
      "F1 Score: 0.7791\n",
      "Confusion Matrix:\n",
      "[[27 13]\n",
      " [16 74]]\n",
      "\n",
      "Algorithm: SVM (RBF Kernel)\n",
      "Accuracy: 0.7769\n",
      "F1 Score: 0.7704\n",
      "Confusion Matrix:\n",
      "[[22 18]\n",
      " [11 79]]\n",
      "\n",
      "Algorithm: SVM (Linear Kernel)\n",
      "Accuracy: 0.8308\n",
      "F1 Score: 0.8189\n",
      "Confusion Matrix:\n",
      "[[22 18]\n",
      " [ 4 86]]\n",
      "\n",
      "Algorithm: SVM (Polynomial Kernel)\n",
      "Accuracy: 0.7000\n",
      "F1 Score: 0.5840\n",
      "Confusion Matrix:\n",
      "[[ 1 39]\n",
      " [ 0 90]]\n",
      "\n",
      "Algorithm: MLP (1 Hidden Layer, 200 neurons)\n",
      "Accuracy: 0.8308\n",
      "F1 Score: 0.8189\n",
      "Confusion Matrix:\n",
      "[[22 18]\n",
      " [ 4 86]]\n",
      "\n",
      "Algorithm: Logistic Regression\n",
      "Accuracy: 0.8231\n",
      "F1 Score: 0.8095\n",
      "Confusion Matrix:\n",
      "[[21 19]\n",
      " [ 4 86]]\n",
      "\n",
      "Algorithm: Gaussian NB\n",
      "Accuracy: 0.7692\n",
      "F1 Score: 0.7657\n",
      "Confusion Matrix:\n",
      "[[23 17]\n",
      " [13 77]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define your algorithms\n",
    "algorithms = {\n",
    "        \"Random Forest (1200 trees)\": RandomForestClassifier(n_estimators=1200, random_state=42),\n",
    "        \"Random Forest (500 trees)\": RandomForestClassifier(n_estimators=500, random_state=42),\n",
    "        \"KNN (k=1)\": KNeighborsClassifier(n_neighbors=1),\n",
    "        \"KNN (k=3)\": KNeighborsClassifier(n_neighbors=3),\n",
    "        \"KNN (k=5)\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"SVM (RBF Kernel)\": SVC(kernel='rbf', gamma='auto', C=1, random_state=42),\n",
    "        \"SVM (Linear Kernel)\": SVC(kernel='linear', gamma='auto', C=1, random_state=42),\n",
    "        \"SVM (Polynomial Kernel)\": SVC(kernel='poly', gamma='auto', C=1, random_state=42),\n",
    "        \"MLP (1 Hidden Layer, 200 neurons)\": MLPClassifier(hidden_layer_sizes=(200,), max_iter=1000, random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "        \"Gaussian NB\": GaussianNB()\n",
    "    }\n",
    "\n",
    "# Train and evaluate each algorithm\n",
    "results = {}\n",
    "for algo_name, algo in algorithms.items():\n",
    "    # Train the model\n",
    "    # Filtra el DataFrame por la columna 'phenotype'\n",
    "    df_training = df[df['phenotype'].isin(['Susceptible', 'Resistant']) & df['genus'].isin(['Campylobacter', 'Neisseria'])]\n",
    "    #df_training = df[df['phenotype'].isin(['Susceptible', 'Resistant'])]\n",
    "    df_test = df[df['phenotype'].isna()& df['genus'].isin(['Campylobacter', 'Neisseria', 'Escherichia'])]\n",
    "\n",
    "    # Filtra el DataFrame por cada etiqueta\n",
    "    df_res = df[df['phenotype'] == 'Resistant']\n",
    "    df_sus = df[df['phenotype'] == 'Susceptible']\n",
    "\n",
    "    # Calcula la proporción de 1 y 0 para cada etiqueta en cada columna\n",
    "    proporcion_res = df_res.iloc[:,6:].mean()\n",
    "    proporcion_sus = df_sus.iloc[:,6:].mean()\n",
    "\n",
    "    # Calcula la diferencia en la proporción entre las dos etiquetas para cada columna\n",
    "    diferencia = abs(proporcion_res - proporcion_sus)\n",
    "\n",
    "    # Ordena las columnas por la diferencia en orden descendente\n",
    "    columnas_ordenadas = diferencia.sort_values(ascending=False)\n",
    "\n",
    "    # Selecciona las N primeras columnas con la mayor diferencia\n",
    "    columns_subset_size = 4000\n",
    "    subset = columnas_ordenadas.head(columns_subset_size)\n",
    "\n",
    "    nombres_columnas_seleccionadas = subset.index\n",
    "\n",
    "    # Filtra el DataFrame original para seleccionar solo las columnas deseadas\n",
    "    df_filtrado = df_training[nombres_columnas_seleccionadas]\n",
    "    #df_filtrado_test = df_test[nombres_columnas_seleccionadas]\n",
    "\n",
    "    labels = df_training['phenotype']\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Fit and transform the labels\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    \n",
    "    # Dividir los datos codificados en conjunto de entrenamiento y conjunto de prueba\n",
    "    test_size = 0.2\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_filtrado, encoded_labels, stratify=encoded_labels, test_size=test_size, random_state=50)\n",
    "    \n",
    "    #X_train = df.drop(columns=['phenotype'])  # Assuming 'phenotype' is the target column\n",
    "    #y_train = df['phenotype']\n",
    "    \n",
    "    algo.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = algo.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')  # Weighted F1-score for multiclass classification\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Store results\n",
    "    results[algo_name] = {'accuracy': accuracy, 'f1_score': f1, 'confusion_matrix': cm}\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.ylabel('Etiqueta verdadera')\n",
    "    plt.xticks(ticks=[0.5, 1.5], labels=['Resistant', 'Susceptible'])\n",
    "    plt.yticks(ticks=[0.5, 1.5], labels=['Resistant', 'Susceptible'])\n",
    "    plt.title('Matriz de Confusión - ' + algo_name)\n",
    "    \n",
    "    # Save confusion matrix plot\n",
    "    output_folder = \"confusion_matrix_plots_CNE\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    plt.savefig(os.path.join(output_folder, algo_name + \"_confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "results_df.to_csv(\"results_CNE.csv\")\n",
    "\n",
    "# Print results\n",
    "for algo_name, result in results.items():\n",
    "    print(f\"Algorithm: {algo_name}\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(f\"F1 Score: {result['f1_score']:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{result['confusion_matrix']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e8ab40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a6f38d9",
   "metadata": {},
   "source": [
    "# Salmonella"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31785b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: Random Forest (1200 trees)\n",
      "Accuracy: 0.9954\n",
      "F1 Score: 0.9931\n",
      "Confusion Matrix:\n",
      "[[  0   2]\n",
      " [  0 430]]\n",
      "\n",
      "Algorithm: Random Forest (500 trees)\n",
      "Accuracy: 0.9954\n",
      "F1 Score: 0.9931\n",
      "Confusion Matrix:\n",
      "[[  0   2]\n",
      " [  0 430]]\n",
      "\n",
      "Algorithm: KNN (k=1)\n",
      "Accuracy: 0.9954\n",
      "F1 Score: 0.9931\n",
      "Confusion Matrix:\n",
      "[[  0   2]\n",
      " [  0 430]]\n",
      "\n",
      "Algorithm: KNN (k=3)\n",
      "Accuracy: 0.9954\n",
      "F1 Score: 0.9931\n",
      "Confusion Matrix:\n",
      "[[  0   2]\n",
      " [  0 430]]\n",
      "\n",
      "Algorithm: KNN (k=5)\n",
      "Accuracy: 0.9954\n",
      "F1 Score: 0.9931\n",
      "Confusion Matrix:\n",
      "[[  0   2]\n",
      " [  0 430]]\n",
      "\n",
      "Algorithm: SVM (RBF Kernel)\n",
      "Accuracy: 0.9954\n",
      "F1 Score: 0.9931\n",
      "Confusion Matrix:\n",
      "[[  0   2]\n",
      " [  0 430]]\n",
      "\n",
      "Algorithm: SVM (Linear Kernel)\n",
      "Accuracy: 0.9954\n",
      "F1 Score: 0.9931\n",
      "Confusion Matrix:\n",
      "[[  0   2]\n",
      " [  0 430]]\n",
      "\n",
      "Algorithm: SVM (Polynomial Kernel)\n",
      "Accuracy: 0.9954\n",
      "F1 Score: 0.9931\n",
      "Confusion Matrix:\n",
      "[[  0   2]\n",
      " [  0 430]]\n",
      "\n",
      "Algorithm: MLP (1 Hidden Layer, 200 neurons)\n",
      "Accuracy: 0.9954\n",
      "F1 Score: 0.9931\n",
      "Confusion Matrix:\n",
      "[[  0   2]\n",
      " [  0 430]]\n",
      "\n",
      "Algorithm: Logistic Regression\n",
      "Accuracy: 0.9954\n",
      "F1 Score: 0.9931\n",
      "Confusion Matrix:\n",
      "[[  0   2]\n",
      " [  0 430]]\n",
      "\n",
      "Algorithm: Gaussian NB\n",
      "Accuracy: 0.9954\n",
      "F1 Score: 0.9931\n",
      "Confusion Matrix:\n",
      "[[  0   2]\n",
      " [  0 430]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define your algorithms\n",
    "algorithms = {\n",
    "        \"Random Forest (1200 trees)\": RandomForestClassifier(n_estimators=1200, random_state=42),\n",
    "        \"Random Forest (500 trees)\": RandomForestClassifier(n_estimators=500, random_state=42),\n",
    "        \"KNN (k=1)\": KNeighborsClassifier(n_neighbors=1),\n",
    "        \"KNN (k=3)\": KNeighborsClassifier(n_neighbors=3),\n",
    "        \"KNN (k=5)\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"SVM (RBF Kernel)\": SVC(kernel='rbf', gamma='auto', C=1, random_state=42),\n",
    "        \"SVM (Linear Kernel)\": SVC(kernel='linear', gamma='auto', C=1, random_state=42),\n",
    "        \"SVM (Polynomial Kernel)\": SVC(kernel='poly', gamma='auto', C=1, random_state=42),\n",
    "        \"MLP (1 Hidden Layer, 200 neurons)\": MLPClassifier(hidden_layer_sizes=(200,), max_iter=1000, random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "        \"Gaussian NB\": GaussianNB()\n",
    "    }\n",
    "\n",
    "# Train and evaluate each algorithm\n",
    "results = {}\n",
    "for algo_name, algo in algorithms.items():\n",
    "    # Train the model\n",
    "    # Filtra el DataFrame por la columna 'phenotype'\n",
    "    df_training = df[df['phenotype'].isin(['Susceptible', 'Resistant']) & df['genus'].isin(['Salmonella'])]\n",
    "    #df_training = df[df['phenotype'].isin(['Susceptible', 'Resistant'])]\n",
    "    df_test = df[df['phenotype'].isna()& df['genus'].isin(['Salmonella'])]\n",
    "\n",
    "    # Filtra el DataFrame por cada etiqueta\n",
    "    df_res = df[df['phenotype'] == 'Resistant']\n",
    "    df_sus = df[df['phenotype'] == 'Susceptible']\n",
    "\n",
    "    # Calcula la proporción de 1 y 0 para cada etiqueta en cada columna\n",
    "    proporcion_res = df_res.iloc[:,6:].mean()\n",
    "    proporcion_sus = df_sus.iloc[:,6:].mean()\n",
    "\n",
    "    # Calcula la diferencia en la proporción entre las dos etiquetas para cada columna\n",
    "    diferencia = abs(proporcion_res - proporcion_sus)\n",
    "\n",
    "    # Ordena las columnas por la diferencia en orden descendente\n",
    "    columnas_ordenadas = diferencia.sort_values(ascending=False)\n",
    "\n",
    "    # Selecciona las N primeras columnas con la mayor diferencia\n",
    "    columns_subset_size = 5000\n",
    "    subset = columnas_ordenadas.head(columns_subset_size)\n",
    "\n",
    "    nombres_columnas_seleccionadas = subset.index\n",
    "\n",
    "    # Filtra el DataFrame original para seleccionar solo las columnas deseadas\n",
    "    df_filtrado = df_training[nombres_columnas_seleccionadas]\n",
    "    #df_filtrado_test = df_test[nombres_columnas_seleccionadas]\n",
    "\n",
    "    labels = df_training['phenotype']\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Fit and transform the labels\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    \n",
    "    # Dividir los datos codificados en conjunto de entrenamiento y conjunto de prueba\n",
    "    test_size = 0.2\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_filtrado, encoded_labels, stratify=encoded_labels, test_size=test_size, random_state=50)\n",
    "    \n",
    "    #X_train = df.drop(columns=['phenotype'])  # Assuming 'phenotype' is the target column\n",
    "    #y_train = df['phenotype']\n",
    "    \n",
    "    algo.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = algo.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')  # Weighted F1-score for multiclass classification\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Store results\n",
    "    results[algo_name] = {'accuracy': accuracy, 'f1_score': f1, 'confusion_matrix': cm}\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.ylabel('Etiqueta verdadera')\n",
    "    plt.xticks(ticks=[0.5, 1.5], labels=['Resistant', 'Susceptible'])\n",
    "    plt.yticks(ticks=[0.5, 1.5], labels=['Resistant', 'Susceptible'])\n",
    "    plt.title('Matriz de Confusión - ' + algo_name)\n",
    "    \n",
    "    # Save confusion matrix plot\n",
    "    output_folder = \"confusion_matrix_plots_Salmonella\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    plt.savefig(os.path.join(output_folder, algo_name + \"_confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "results_df.to_csv(\"results_Salmonella.csv\")\n",
    "\n",
    "# Print results\n",
    "for algo_name, result in results.items():\n",
    "    print(f\"Algorithm: {algo_name}\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(f\"F1 Score: {result['f1_score']:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{result['confusion_matrix']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151d6048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
